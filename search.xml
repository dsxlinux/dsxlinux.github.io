<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[自动化运维之SaltStack实践]]></title>
    <url>%2F2018%2F08%2F22%2FSaltStack%2F</url>
    <content type="text"><![CDATA[本文主要介绍自动化运维工具SaltStack的使用方法。 1.saltstack简介saltstack是基于python开发的一套C/S架构配置管理工具，它的底层使用ZeroMQ消息队列pub/sub方式通信，使用SSL证书签发的方式进行认证管理。ZeroMQ使SaltStack能快速在成千上万台机器上进行各种操作，之前已经介绍过了puppet mco的框架，比较类似。而且采用RSA Key方式确认身份，传输采用AES加密，使传输的安全性得到保障。 2.SaltStack安装在SaltsStack架构中服务端叫作Master，客户端叫作Minion。我们使用2台服务器来来实验。配置主机名123# cat /etc/hosts192.168.0.213 rzx213192.168.0.214 rzx214 服务端安装 12# yum install -y epel-release# yum install -y salt-master salt-minion 客户端安装 12# yum install -y epel-release# yum install -y salt-minion 3.SaltStack配置分别在服务端和客户端中打开/etc/salt/minion文件，做如下修改：12# vim /etc/salt/minionmaster: 192.168.0.213 //在文件第16行，打开注释，指定master的ip地址。 4.启动服务 服务端启动 12# salt-master start &amp;# salt-minion start &amp; 客户端启动 1# salt-minion start &amp; minion在第一次启动时，会在/etc/salt/pki/minion/（该路径在/etc/salt/minion里面设置）下自动生成minion.pem（private key）和 minion.pub（public key），然后将 minion.pub发送给master。master在接收到minion的public key后，通过salt-key命令accept minion public key，这样在master的/etc/salt/pki/master/minions下的将会存放以minion id命名的 public key，然后master就能对minion发送指令了。 5.配置认证在服务端进行如下操作：12345678910# salt-key -a rzx213# salt-key -a rzx214# salt-keyAccepted Keys:rzx213rzx214Denied Keys:Unaccepted Keys:Rejected Keys: 上面操作是手动配置认证，大规模部署Minion的时候，可以自动接受指定等待认证的 key。123# cp /etc/salt/master /etc/salt/master.bak# vim /etc/salt/masterauto_accept: True //215行，注释打开，修改为True 测试验证先重新启动salt服务端和客户端，再执行：1# salt '*' cmd.run 'df -h' //在服务端执行，其中*表示认证过的服务器 6.管理对象 正则匹配 12345# salt 'rzx*' network.ip_addrsrzx214: - 192.168.0.214rzx213: - 192.168.0.213 列表匹配 12345# salt -L rzx213,rzx214 test.ping //-L, –list 列表匹配rzx213: Truerzx214: True Grians匹配 1# salt -G 'os:CentOS' test.ping //os:CentOS，这里的对象是一组键值对， 这里用到了Minion的Grains的键值对。 组匹配 12345678# vim /etc/salt/master##### Node Groups ################################################ Node groups allow for logical groupings of minion nodes. A group consists of a group# name and a compound target.#nodegroups:# group1: 'L@foo.domain.com,bar.domain.com,baz.domain.com and bl*.domain.com'# group2: 'G@os:Debian and foo.domain.com' L@ 和G@ 分别表示minion和grain信息 L@开通的是指定的以逗号分隔的多个minionId Letter Match Type Example Alt Delimiter? G Grains glob G@os:Ubuntu Yes E PCRE Minion ID `E@web\d+.(dev qa P Grains PCRE P@os:(RedHat Fedora L List of minions L@minion1.example.com,minion3.domain.com or bl*.domain.com No I Pillar glob I@pdata:foobar Yes J Pillar PCRE `J@pdata:^(foo bar)$` S Subnet/IP address S@192.168.1.0/24 or S@192.168.1.100 No R Range cluster R@%foo.bar No 修改group1为:nodegroups: //打开注释 group1: ‘L@rzx213,rzx214’ //修改配置，注意前面有空格 1# salt -N group1 test.ping //-N, –nodegroup 组匹配 7.管理对象属性 通过Minion配置文件定义Grains1234567# vim /etc/salt/minionrzx213: role: - webserver # salt 'rzx213' grains.item role# salt -G role:webserver cmd.run 'hostname' 8.pillar在服务端配置：123456789101112131415161718192021# vim /etc/salt/master //打开注释pillar_roots: base: - /srv/pillar # mkdir /srv/pillar# vim /srv/pillar/test.slsconf: /etc/test123.confmyname: hadron# vim /srv/pillar/top.slsbase: 'rzx213': - test# /etc/init.d/salt-master restart# salt 'rzx213' pillar.items# salt -I 'conf:/etc/test123.conf' test.ping# salt -I 'conf:/etc/test123.conf' cmd.run 'w' 名称 存储位置 数据类型 数据采集更新方式 应用 Grains minion端 静态数据 minion启动时收集，也可以使用saltutil.sync_grains进行刷新。 存储minion基本数据，比如用于匹配minion,自身数据可以用来做资产管理等。 Pillar master端 动态数据 在master端定义，指定给对应的minion，可以使用saltutil.refresh_pillar刷新 存储Master指定的数据，只有指定的minion可以看到，用于敏感数据保存。 9.配置管理安装Apache123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# vim /etc/salt/masterfile_roots: base: - /srv/salt # mkdir /srv/salt# vim /srv/salt/top.slsbase: 'rzx213': - apache# vim /srv/salt/apache.slsapache-service: pkg.installed: - names: - httpd - httpd-devel service.running: - name: httpd - enable: True# /etc/init.d/salt-minion restart# salt 'rzx213' state.highstaterzx213:---------- ID: apache-service Function: pkg.installed Name: httpd Result: True Comment: Package httpd is already installed. Started: 15:50:59.361911 Duration: 2092.768 ms Changes: ---------- ID: apache-service Function: pkg.installed Name: httpd-devel Result: True Comment: Package httpd-devel is already installed. Started: 15:51:01.454917 Duration: 0.615 ms Changes: ---------- ID: apache-service Function: service.running Name: httpd Result: True Comment: Service httpd is already enabled, and is in the desired state Started: 15:51:01.456326 Duration: 43.071 ms Changes: Summary------------Succeeded: 3Failed: 0------------Total states run: 3 9.states文件salt states的核心是sls文件，该文件使用YAML语法定义了一些k/v的数据。sls文件存放根路径在master配置文件中定义，默认为/srv/salt,该目录在操作系统上不存在，需要手动创建。在salt中可以通过salt://代替根路径，例如你可以通过salt://top.sls访问/srv/salt/top.sls。在states中top文件也由master配置文件定义，默认为top.sls，该文件为states的入口文件。 一个简单的sls文件如下：12345apache: pkg.installed service.running - require: - pkg: apache 说明：此SLS数据确保叫做”apache”的软件包(package)已经安装,并且”apache”服务(service)正在运行中。 10.文件目录管理 文件管理 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647服务端配置：# vim /srv/salt/top.slsbase: 'rzx213': - apache 'rzx214': - filetest# vim /srv/salt/filetest.slsfile-test: file.managed: - name: /tmp/filetest.txt - source: salt://test/123/1.txt - user: root - group: root - mode: 644# mkdir -p /srv/salt/test/123/# echo "file test" &gt; /srv/salt/test/123/1.txt# salt 'rzx214' state.highstaterzx214:---------- ID: file-test Function: file.managed Name: /tmp/filetest.txt Result: True Comment: File /tmp/filetest.txt updated Started: 15:59:04.959125 Duration: 65.433 ms Changes: ---------- diff: New file mode: 0644Summary------------Succeeded: 1 (changed=1)Failed: 0------------Total states run: 1客户端验证：# cat /tmp/filetest.txt file test 目录管理 123456789101112131415161718192021222324服务端配置：# vim /srv/salt/top.slsbase: 'rzx213': - apache 'rzx214': - filedir # vim /srv/salt/filedir.slsfile-dir: file.recurse: - name: /tmp/testdir - source: salt://test/123 - user: root - file_mode: 644 - dir_mode: 755 - mkdir: True - clean: True# ls /srv/salt/test/123# salt 'rzx214' state.highstate客户端验证:# ls /tmp/testdir/ 测试增删功能 123456789服务端配置：# cd /srv/salt/test/123# mkdir newDir# echo "Hello" &gt; newDir/a# rm -rf 1.txt# salt 'rzx214' state.highstate客户端验证:# ls /tmp/testdir/ 11.远程执行 远程执行命令 1234567891011121314151617181920# vim /srv/salt/top.slsbase: 'rzx213': - cmdtest 'rzx214': - filedir# vim /srv/salt/cmdtest.slscmd-test: cmd.run: - onlyif: test -f /tmp/1.txt - names: - touch /tmp/cmdtest.txt - mkdir /tmp/cmdtest - user: root # echo "hello" &gt; /tmp/1.txt# salt 'rzx123' state.highstate# ll /tmp|grep cmd 远程执行脚本 123456789101112131415161718192021222324252627服务端配置：# vim /srv/salt/top.slsbase: 'rzx213': - cmdtest 'rzx214': - shelltest# vim /srv/salt/shelltest.slsshell-test: cmd.script: - source: salt://test/1.sh - user: root# vim /srv/salt/test/1.sh#!/bin/bashtouch /tmp/shelltest.txtif [ -d /tmp/shelltest ]then rm -rf /tmp/shelltestelse mkdir /tmp/shelltestfi# salt 'rzx214' state.highstate客户端验证:# ll /tmp|grep shell 12.管理任务计划 建立 cron 1234567891011121314151617181920212223服务端配置：# vim /srv/salt/top.slsbase: 'rzx213': - crontest 'rzx214': - shelltest# vim /srv/salt/crontest.slscron-test: cron.present: - name: /bin/touch /tmp/111.txt - user: root - minute: '*' - hour: 20 - daymonth: 1-10 - month: '3,5' - dayweek: '*' # salt 'rzx213' state.highstate客户端验证：# crontab -l 删除cron 12345678910111213141516 服务端配置：# vim /srv/salt/crontest.slscron-test: cron.absent: - name: /bin/touch /tmp/111.txt - user: root - minute: '*' - hour: 20 - daymonth: 1-10 - month: '3,5' - dayweek: '*'# salt 'rzx213' state.highstate客户端验证:# crontab -l 13.Saltstack常用命令 拷贝文件到客户端 1# salt 'rzx213' cp.get_file salt://apache.sls /tmp/cp.txt 拷贝目录到客户端 1# salt 'rzx213' cp.get_dir salt://test /tmp 显示存活的客户端 1# salt-run manage.up 命令下执行服务端的脚本 12345# vim /srv/salt/test/shell.sh#! /bin/bashecho "hadron.cn" &gt; /tmp/shell.txt# salt 'rzx214' cmd.script salt://test/shell.sh]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS下搭建Jenkins服务器]]></title>
    <url>%2F2018%2F08%2F20%2Fjenkins%2F</url>
    <content type="text"><![CDATA[本文主要介绍Centos6.x搭建Jenkins服务器。 1.卸载OpenJDK123456# rpm -qa|grep javatzdata-java-2018d-1.el6.noarchjavassist-3.9.0-6.el6.noarchjava-1.7.0-openjdk-1.7.0.171-2.6.13.0.el6_9.x86_64# yum remove java java-* -y 2.安装JDK下载地址：http://www.oracle.com/technetwork/java/javase/downloads/index.html12345678910111213# rpm -ivh jdk-8u101-linux-x64.rpm# vim /etc/profileexport JAVA_HOME=/usr/java/jdk1.8.0_101export CLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/libexport PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH# source /etc/profile# java -versionjava version "1.8.0_101"Java(TM) SE Runtime Environment (build 1.8.0_101-b13)Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode) 3.安装TomcatTomcat下载地址：http://tomcat.apache.org/12345678910111213141516171819202122232425# tar xf apache-tomcat-9.0.10.tar.gz -C /usr/local/# cd /usr/local/# mv apache-tomcat-9.0.10 tomcat# ls -l bin --启动命令目录 conf --配置文件目录 lib --库文件目录 logs --日志文件目录 temp --临时缓存文件 webapps --web应用家目录 work --工作缓存目录环境变量# vim /usr/local/tomcat/bin/startup.sh --tomcat的启动程序# vim /usr/local/tomcat/bin/shutdown.sh --tomcat的关闭程序加入如下内容：export JAVA_HOME=/usr/java/jdk1.8.0_101export TOMCAT_HOME=/usr/local/tomcatexport CATALINA_HOME=/usr/local/tomcatexport CLASS_PATH=$JAVA_HOME/bin/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tool.jarexport PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$TOMCAT_HOME/bin:$PATH启动Tomcat# /usr/local/tomcat/bin/startup.sh 4.安装Jenkins从官网下载jenkins的war包，地址https://jenkins.io/下载后可以直接运行：1java -jar jenkins.war --httpPort=8080 把下载的包放到如下目录：1# ls /usr/local/tomcat/webapps/ROOT 解压war包1# jar xf jenkins.war 使用浏览器访问：http://ip:8080/ 进入安装界面即可完成安装。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS下搭建http代理服务器(TinyProxy)]]></title>
    <url>%2F2018%2F08%2F20%2Ftiny-proxy%2F</url>
    <content type="text"><![CDATA[本文主要介绍Centos6.x搭建TinyProxy服务器。 1.安装12# yum install epel-release -y# yum install tinyproxy -y 2.配置配置文件：/etc/opt/ss5/ss5.conf1234567891011121314151617181920212223# egrep -v '#|^$' /etc/tinyproxy/tinyproxy.conf //默认配置内容如下User tinyproxyGroup tinyproxyPort 8888Timeout 600DefaultErrorFile "/usr/share/tinyproxy/default.html"StatFile "/usr/share/tinyproxy/stats.html"LogFile "/var/log/tinyproxy/tinyproxy.log"LogLevel InfoPidFile "/var/run/tinyproxy/tinyproxy.pid"MaxClients 100MinSpareServers 5MaxSpareServers 20StartServers 10MaxRequestsPerChild 0Allow 127.0.0.1ViaProxyName "tinyproxy"ConnectPort 443ConnectPort 563参数：Port是监听的端口Allow IP服务限制。如果不想限制，可以注释掉 3.启动12345# service tinyproxy start# chkconfig --level 35 tinyproxy on# netstat -ntlp | grep tinyproxy]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS下搭建SS5(SOCKS5)代理服务器]]></title>
    <url>%2F2018%2F08%2F20%2Fsocks5-proxy%2F</url>
    <content type="text"><![CDATA[本文主要介绍Centos6.x搭建SOCKS5代理服务器。 1.从官网下载源码官网：http://ss5.sourceforge.net/software.htm1# wget https://nchc.dl.sourceforge.net/project/ss5/ss5/3.8.9-8/ss5-3.8.9-8.tar.gz 2.解决依赖12# yum -y install gcc automake make# yum -y install pam-devel openldap-devel cyrus-sasl-devel openssl-devel 3.编译安装123# tar xvf ss5-3.8.9-8.tar.gz# cd ss5-3.8.9/# ./configure &amp;&amp; make &amp;&amp; make install 4.配置配置文件：/etc/opt/ss5/ss5.conf第一步：修改认证方式123# vim /etc/opt/ss5/ss5.conf87 auth 0.0.0.0/0 - u //将第87行注释打开，最后修改成u203 permit u 0.0.0.0/0 - 0.0.0.0/0 - - - - - //将第203行注释打开，中间加一个u，表示用户认证 第二步：添加用户名及密码12# vim /etc/opt/ss5/ss5.passwdrzx rzx@1218 第三步：修改端口1234# vim /etc/sysconfig/ss5SS5_OPTS=" -u root -b 0.0.0.0:10808" //默认是1080端口，修改成10808# chmod 755 /etc/rc.d/init.d/ss5 5.启动1234567# chmod +x /etc/rc.d/init.d/ss5# /etc/rc.d/init.d/ss5 restart# netstat -an | grep 10808# more /var/log/ss5/ss5.log# chkconfig --add ss5# chkconfig --level 345 ss5 on]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[inotify-tools使用方法介绍]]></title>
    <url>%2F2018%2F08%2F15%2Finotify%2F</url>
    <content type="text"><![CDATA[本文主要介绍inotify-tools工具套件的使用方法。 1.关于inotifyInotify是一种文件变化通知机制，Linux内核从2.6.13开始引入。inotify-tools提供两种工具，一是inotifywait，它是用来监控文件或目录的变化，二是inotifywatch，它是用来统计文件系统访问的次数。1# grep INOTIFY_USER /boot/config-$(uname -r) 如果输出(‘CONFIG_INOTIFY_USER=y’)，表示支持Inotify机制。 2.安装inotify-tools12# yum install epel-release -y# yum install inotify-tools -y 3.inotifywait使用1234567891011121314151617181920212223242526272829303132333435363738394041# inotifywait -h参数说明:inotifywait [-hcmrq] [-e ] [-t ] [–format ] [–timefmt ] [ … ]-h,–help输出帮助信息@排除不需要监视的文件，可以是相对路径，也可以是绝对路径。–fromfile从文件读取需要监视的文件或排除的文件，一个文件一行，排除的文件以@开头。-m, –monitor接收到一个事情而不退出，无限期地执行。默认的行为是接收到一个事情后立即退出。-d, –daemon跟–monitor一样，除了是在后台运行，需要指定–outfile把事情输出到一个文件。也意味着使用了–syslog。-o, –outfile输出事情到一个文件而不是标准输出。-s, –syslog输出错误信息到系统日志-r, –recursive监视一个目录下的所有子目录。-q, –quiet指定一次，不会输出详细信息，指定二次，除了致命错误，不会输出任何信息。–exclude正则匹配需要排除的文件，大小写敏感。–excludei正则匹配需要排除的文件，忽略大小写。-t , –timeout设置超时时间，如果为0，则无限期地执行下去。-e , –event指定监视的事件。-c, –csv输出csv格式。–timefmt指定时间格式，用于–format选项中的%T格式。–format指定输出格式。%w 表示发生事件的目录%f 表示发生事件的文件%e 表示发生的事件%Xe 事件以“X”分隔%T 使用由–timefmt定义的时间格式 可监听事件 access 文件读取 modify 文件更改。 attrib 文件属性更改，如权限，时间戳等。 close_write 以可写模式打开的文件被关闭，不代表此文件一定已经写入数据。 close_nowrite 以只读模式打开的文件被关闭。 close 文件被关闭，不管它是如何打开的。 open 文件打开。 moved_to 一个文件或目录移动到监听的目录，即使是在同一目录内移动，此事件也触发。 moved_from 一个文件或目录移出监听的目录，即使是在同一目录内移动，此事件也触发。 move 包括moved_to和 moved_from move_self 文件或目录被移除，之后不再监听此文件或目录。 create 文件或目录创建 delete 文件或目录删除 delete_self 文件或目录移除，之后不再监听此文件或目录 unmount 文件系统取消挂载，之后不再监听此文件系统。 案例： 通过ftp上传了两种不同的文件（ftp一直在工作中），比如：xxx.zip文件和xxx.dat文件，需要将xxx.dat文件移动到其他目录进行单独处理。 1234567# cat inotify.sh #!/bin/bash/usr/bin/inotifywait -mrq -e modify,attrib,close,moved_to,create,delete /test/ |while read filesdomv /test/*.dat /test2/ &amp;&gt;/dev/nulldone 4.inotifywatch使用12345678910111213141516171819202122232425262728# inotifywatch -hinotifywatch [-hvzrqf] [-e ] [-t ] [-a ] [-d ] [ … ]参数说明：-h, –help输出帮助信息-v, –verbose输出详细信息@排除不需要监视的文件，可以是相对路径，也可以是绝对路径。–fromfile从文件读取需要监视的文件或排除的文件，一个文件一行，排除的文件以@开头。-z, –zero输出表格的行和列，即使元素为空–exclude正则匹配需要排除的文件，大小写敏感。–excludei正则匹配需要排除的文件，忽略大小写。-r, –recursive监视一个目录下的所有子目录。-t , –timeout设置超时时间-e , –event只监听指定的事件。-a , –ascending以指定事件升序排列。-d , –descending以指定事件降序排列。 1# inotifywatch -r -v -e modify,attrib,close,moved_to,create,delete /test/]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL主键和外键]]></title>
    <url>%2F2018%2F08%2F12%2Fmysql-key%2F</url>
    <content type="text"><![CDATA[本文主要介绍MySQL主键和外键。 1.主键 什么是主键主键是能确定一条记录的唯一标识。比如：一条记录包括身份正号，姓名，年龄。身份证号是唯一能确定你这个人的，其他都可能有重复，所以身份证号是主键。 声明主键的方法不设置主键 1234mysql&gt; CREATE TABLE t1( id int not null, name char(20)); 带主键的 1234mysql&gt; CREATE TABLE t1( id int not null primary key, name char(20)); 复合主键 1234567891011121314mysql&gt; CREATE TABLE t1( id int not null, name char(20), primary key (id,name));``` 主键自增的 ```mysqlmysql&gt; create table dd( id int primary key not null auto_increment, name varchar(20), time timestamp default current_timestamp ); 创建完后再决定主键 1234567mysql&gt; create table t( id int not null, name varchar(200) not null, time timestamp default current_timestamp);mysql&gt; alter table t add primary key (id);mysql&gt; alter table t drop primary key (id); 2.外键 什么是外键一张表中有一个非主键的字段指向了别一张表中的主键，该字段叫做外键。一张表中可以有多个外键。 外键作用对子表(外键所在的表)的作用：子表在进行写操作的时候，如果外键字段在父表中找不到对应的匹配，操作就会失败。对父表的作用：对父表的主键字段进行删和改时，如果对应的主键在子表中被引用，操作就会失败。 外键条件表储存引擎必须是innodb，否则创建的外键无约束效果。外键的列类型必须与父表的主键类型完全一致。外键的名字不能重复。已经存在数据的字段被设为外键时，必须保证字段中的数据与父表的主键数据对应起来。 新增外键在创建时增加 12345678910111213141516mysql&gt; create table province( pId int primary key auto_increment, pName varchar(20) ); mysql&gt; create table user( userId int primary key auto_increment, userName varchar(40), pid int, foreign key(pid) references province(pId));mysql&gt; create table city( cityId int primary key auto_increment, cName varchar(20)); 在创建好的表中增加 12345mysql&gt; alter table user add cityId int;mysql&gt; alter table user add foreign key(cityId) references city(cityId);mysql&gt; alter table city add pid int;mysql&gt; alter table city add foreign key(pid) references province(pId); 删除外键1mysql&gt; alter table tablename drop foreign key 外键名字;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据类型]]></title>
    <url>%2F2018%2F08%2F12%2Fmysql-datatype%2F</url>
    <content type="text"><![CDATA[本文主要介绍MySQL各数据类型的、大小及长度。 1.数字型 类型 大小 范围（有符号） 范围（无符号） 用途 TINYINT 1 字节 (-128，127) (0，255) 小整数值 SMALLINT 2 字节 (-32 768，32 767) (0，65 535) 大整数值 MEDIUMINT 3 字节 (-8 388 608，8 388 607) (0，16 777 215) 大整数值 INT或INTEGER 4 字节 (-2 147 483 648，2 147 483 647) (0，4 294 967 295) 大整数值 BIGINT 8 字节 (-9 233 372 036 854 775 808，9 223 372 036 854 775 807) (0，18 446 744 073 709 551 615) 极大整数值 FLOAT 4 字节 (-3.402 823 466 E+38，1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38) 0，(1.175 494 351 E-38，3.402 823 466 E+38) 单精度 浮点数值 DOUBLE 8 字节 (1.797 693 134 862 315 7 E+308，2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 双精度 浮点数值 DECIMAL 对DECIMAL(M,D) ，如果M&gt;D，为M+2否则为D+2 依赖于M和D的值 依赖于M和D的值 小数值 2.字符类型 CHAR 0-255字节 定长字符串 VARCHAR 0-255字节 变长字符串 TINYBLOB 0-255字节 不超过 255 个字符的二进制字符串 TINYTEXT 0-255字节 短文本字符串 BLOB 0-65 535字节 二进制形式的长文本数据 TEXT 0-65 535字节 长文本数据 MEDIUMBLOB 0-16 777 215字节 二进制形式的中等长度文本数据 MEDIUMTEXT 0-16 777 215字节 中等长度文本数据 LOGNGBLOB 0-4 294 967 295字节 二进制形式的极大文本数据 LONGTEXT 0-4 294 967 295字节 极大文本数据 3.时间类型 类型 大小(字节) 范围 格式 用途 DATE 3 1000-01-01/9999-12-31 YYYY-MM-DD 日期值 TIME 3 ‘-838:59:59’/‘838:59:59’ HH:MM:SS 时间值或持续时间 YEAR 1 1901/2155 YYYY 年份值 DATETIME 8 1000-01-01 00:00:00/9999-12-31 23:59:59 YYYY-MM-DD HH:MM:SS 混合日期和时间值 TIMESTAMP 8 1970-01-01 00:00:00/2037 年某时 YYYYMMDD HHMMSS 混合日期和时间值，时间戳 4.枚举集合 类型 范围 大小 ENUM 最多65535个成员 64KB SET 最多64个成员 64KB]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据库备份]]></title>
    <url>%2F2018%2F08%2F10%2Fmysql-backup%2F</url>
    <content type="text"><![CDATA[本文主要介绍MySQL数据库备份的方法。 mysqldump备份方法mysqldump备份提供三种级别的备份：表级，库级和全库级。 123456789101112131415161718192021222324252627282930313233建立一个存放备份的目录shell&gt; mkdir /tmp/mysqlbackup改权限shell&gt; mysql.mysql /tmp/mysqlbackup/shell&gt; man mysqldumpshell&gt; mysqldump [options] db_name [tables] # 表级shell&gt; mysqldump [options] --database DB1 [DB2 DB3...] # 库级shell&gt; mysqldump [options] --all-databases # 全库级全库备份：shell&gt; mysqldump -uroot -p123456 --all-databases &gt; /tmp/mysqlbackup/all.sql全库还原：shell&gt; mysql_install_db --datadir=/data --user=mysql # 可能需要重新初始化，具体的要看情况shell&gt; mysql &lt; /tmp/mysqlbackup/all.sql库级备份：shell&gt; mysqldump -uroot -p123456 --database db1 &gt; /tmp/mysqlbackup/db1.sql表级备份：shell&gt; mysqldump -uroot -p123456 db1 emp&gt; /tmp/mysqlbackup/emp.sql表级还原：shell&gt; mysqldump -uroot -p123456 db1 emp&gt; /tmp/mysqlbackup/emp.sql只备份表结构：shell&gt; mysqldump -uroot -p123456 --no-data db1 emp&gt; /tmp/mysqlbackup/emp.sql某些表不备份shell&gt; mysqldump -uroot -p123456 --ignore-table=db1.emp1 --ignore-table=db1.emp1 db1 emp&gt; /tmp/mysqlbackup/emp.sql跨主机备份:shell&gt; mysqldump -uroot -p123456 --opt --database db1 | mysql -h 192.168.0.214 -uroot -p123456 -C db1# 远程数据库上要存在db1这个库才能备份过去，否则会报错。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL语法之DQL]]></title>
    <url>%2F2018%2F08%2F10%2Fmysql-dql%2F</url>
    <content type="text"><![CDATA[本文主要介绍MySQL语法之DML(data query language)操作。 1.数据查询语言用户能够查询数据库以及操作已有数据库中的数据。主要是SELECT。 2.SELECT查询 常规查询123456789101112131415161718192021222324252627# 准备好2个表格：mysql&gt; create table emp (empno int ,ename varchar(20), sex char(1),birthday date , hiredate date, sal decimal(10,2), deptno tinyint(1), managerno int) engine=memory default charset=utf8;mysql&gt; create table dept (deptno tinyint(1),deptname varchar(30),location varchar(50)); mysql&gt; insert into emp values (1,&apos;boss&apos;,&apos;m&apos;,&apos;1964-08-08&apos;,&apos;1995-01-01&apos;,&apos;20000&apos;,&apos;1&apos;,&apos;1&apos;),(2,&apos;zhangsan&apos;,&apos;m&apos;,&apos;1967-04-05&apos;,&apos;1995-04-11&apos;,&apos;15000&apos;,&apos;2&apos;,&apos;1&apos;),(3,&apos;lisi&apos;,&apos;f&apos;,&apos;1973-01-28&apos;,&apos;1998-11-21&apos;,&apos;13000&apos;,&apos;3&apos;,&apos;1&apos;),(4,&apos;wangwu&apos;,&apos;f&apos;,&apos;1975-06-03&apos;,&apos;1999-12-12&apos;,&apos;12000&apos;,&apos;4&apos;,&apos;1&apos;),(5,&apos;maliu&apos;,&apos;m&apos;,&apos;1982-08-18&apos;,&apos;2001-07-03&apos;,&apos;8000&apos;,&apos;2&apos;,&apos;2&apos;),(6,&apos;tianqi&apos;,&apos;f&apos;,&apos;1983-02-15&apos;,&apos;2002-11-01&apos;,&apos;7000&apos;,&apos;2&apos;,&apos;2&apos;),(7,&apos;mark&apos;,&apos;m&apos;,&apos;1984-08-12&apos;,&apos;2003-10-02&apos;,&apos;6500&apos;,&apos;3&apos;,&apos;3&apos;),(8,&apos;john&apos;,&apos;m&apos;,&apos;1985-09-14&apos;,&apos;2005-04-03&apos;,&apos;6000&apos;,&apos;3&apos;,&apos;3&apos;),(9,&apos;mm&apos;,&apos;f&apos;,&apos;1990-06-08&apos;,&apos;2008-09-13&apos;,&apos;4000&apos;,&apos;4&apos;,&apos;4&apos;);mysql&gt; insert into dept values (1,&apos;manager&apos;,&apos;beijing&apos;),(2,&apos;it&apos;,&apos;shenzhen&apos;), (3,&apos;sale&apos;,&apos;shanghai&apos;), (4,&apos;services&apos;,&apos;guangzhou&apos;);# 查看所有列，不推荐这么查询mysql&gt; select * from emp;# 查看其中几列mysql&gt; select ename,sal from emp limit 3;# 去除重复行mysql&gt; select distinct deptno from emp;# 查询所有男员工的姓名和工资mysql&gt; select ename,sal from emp where sex=&apos;m&apos;;# 查询工资大于8000的员工的所有信息mysql&gt; select * from emp where sal&gt;8000;# 查询工资在4000到8000之间的员工的所有信息（包含4000和8000的)mysql&gt; select * from emp where sal&gt;=4000 and sal&lt;=8000;mysql&gt; select * from emp where sal between 4000 and 8000;查询入职时间在2001那年的员工的所有信息mysql&gt; select * from emp where hiredate&gt;=&quot;2001-01-01&quot; and hiredate&lt;=&quot;2001-12-31&quot;;mysql&gt; select * from emp where hiredate like &quot;2001%&quot;;mysql&gt; select * from emp where year(hiredate)=2001;mysql&gt; select * from emp where substr(hiredate,1,4)=2001;mysql&gt; select * from emp where hiredate regexp &apos;2001.*&apos;; 排序1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 # 最大工资，最小工资 mysql&gt; select * from emp order by sal; # 以工资排序，默认升序排序 mysql&gt; select * from emp order by sal asc; # 加不加asc都是升序（ascend) mysql&gt; select * from emp order by sal desc; # desc表示降序排序(descend) mysql&gt; select * from emp order by sex,sal; # 先按性别排，再按工资排。结果是女的都在一起，以工资从小到大排。男的都在一起，以工资从小到大排。 mysql&gt; select * from emp order by sex desc,sal desc; # 找出工资最低的三个人的姓名和工资 mysql&gt; select * from emp order by sal limit 3; # 找出工资最高的三个人的姓名和工资 mysql&gt; select * from emp order by sal desc limit 3; 找出工资最低的女员工的姓名和工资 mysql&gt; select ename,sal from emp where sex=&apos;f&apos; order by sal limit 1; #where和order by一起使用时，where在前，order by在后 # 找出工资从高到低第三到第五的人的姓名和工资 mysql&gt; select ename,sal from emp order by sal desc limit 2,3; # 从0开始，2是第三，3是三个人 ``` - 聚合和分组操作 ```mysql # 统计记录条数 mysql&gt; select count(*) from emp; mysql&gt; select count(distinct deptno) from emp; # 别名 mysql&gt; select count(distinct deptno) deptcount from emp; # 统计每个部门的人数 mysql&gt; select deptno,count(*) from emp group by deptno; # 统计男，女员工各有多少人 mysql&gt; select sex,count(*) from emp group by sex; # 统计每个部门里男女员工各有多少个 mysql&gt; select deptno,sex,count(*) from emp group by deptno,sex; # 查找部门人数大于2的部门号和人数 mysql&gt; select deptno,count(*) from emp group by deptno having count(*) &gt;2; # 求每个部门的工资总额，最大工资，最小工资，平均工资 mysql&gt; select deptno,sum(sal),max(sal),min(sal),avg(sal) from emp group by deptno; 表链接（多表查询)123# 查出员工姓名和其对应的工资，部门名，部门所在地，并显示mysql&gt; select ename,sal,deptname,location from emp,dept where emp.deptno=dept.deptno; join连接123456789101112INNER JOIN（内连接）：取得两个表中存在连接匹配关系的记录。mysql&gt; select a.ename,a.sal,b.deptname,b.location from emp a INNER JOIN dept b on a.deptno=b.deptno;为了看到【左连接】和【右连接】的效果，插入两条数据：mysql&gt; insert into dept(deptno, deptname, location) values (5,&apos;Administration&apos;,&apos;beijing&apos;); # 加一个行政部mysql&gt; insert into dept(deptno, deptname, location) values (6,&apos;technology&apos;,&apos;shenzhen&apos;); # 加一个技术部LEFT JOIN（左连接）：取得左表（table1）完全记录，即是右表（table2）并无对应匹配记录mysql&gt; select * from emp left join dept on emp.deptno=dept.deptno;RIGHT JOIN（右连接）：与 LEFT JOIN 相反，取得右表（table2）完全记录，即是左表（table1）并无匹配对应记录mysql&gt; select * from emp right join dept on emp.deptno=dept.deptno; 子查询123# 查出比wangwu工资高的人的姓名和工资mysql&gt; select ename,sal from emp where sal&gt;(select sal from emp where ename=&apos;wangwu&apos;); 复制一个表：1234mysql&gt; create table emp1 like emp;mysql&gt; insert into emp1 select * from emp;或者mysql&gt; create table emp2 select * from emp;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL语法之DCL]]></title>
    <url>%2F2018%2F08%2F10%2Fmysql-dcl%2F</url>
    <content type="text"><![CDATA[本文主要介绍MySQL语法之DCL(data control language)操作。 1.MySQL数据控制语言用来定义数据库的访问权限和安全级别，及创建用户。包括GRANT、REVOKE等。 2.GRANT语句 12345678# 创建用户和授权mysql&gt; create user &apos;jerry&apos;@&apos;localhost&apos; identified by &apos;123456&apos;;mysql&gt; grant select,insert on db1.emp to &apos;jerry&apos;@&apos;localhost&apos;;# 直接授权mysql&gt; grant select,insert on db1.emp to &apos;jerry&apos;@&apos;localhost&apos; identified by &apos;123456&apos; with grant option;# with grant option表示允许用户将自己的权限授权给其它用户mysql&gt; flush privileges; 有哪些权限可以用于授权？ Privilege Column Context ALL Synonym for “all privileges” Server administration ALTER Alter_priv Tables ALTER ROUTINE Alter_routine_priv Stored routines CREATE Create_priv Databases, tables, or indexes CREATE ROUTINE Create_routine_priv Stored routines CREATE TABLESPACE Create_tablespace_priv Server administration CREATE TEMPORARY TABLES Create_tmp_table_priv Tables CREATE USER Create_user_priv Server administration CREATE VIEW Create_view_priv Views DELETE Delete_priv Tables DROP Drop_priv Databases, tables, or views EVENT Event_priv Databases EXECUTE Execute_priv Stored routines FILE File_priv File access on server host GRANT OPTION Grant_priv Databases, tables, or stored routines INDEX Index_priv Tables INSERT Insert_priv Tables or columns LOCK TABLES Lock_tables_priv Databases PROCESS Process_priv Server administration PROXY See proxies_priv table Server administration REFERENCES References_priv Databases or tables RELOAD Reload_priv Server administration REPLICATION CLIENT Repl_client_priv Server administration REPLICATION SLAVE Repl_slave_priv Server administration SELECT Select_priv Tables or columns SHOW DATABASES Show_db_priv Server administration SHOW VIEW Show_view_priv Views SHUTDOWN Shutdown_priv Server administration SUPER Super_priv Server administration TRIGGER Trigger_priv Tables UPDATE Update_priv Tables or columns USAGE Synonym for “no privileges” Server administration 3.REVOKE语句 123# 创建用户和授权mysql&gt; revoke select on db1.emp from &apos;jerry&apos;@&apos;localhost&apos;;mysql&gt; flush privileges; 4.查看权限 12# 查看权限mysql&gt; show grants for &apos;jerry&apos;@&apos;localhost&apos;; 5.删除用户 1mysql&gt; drop user &apos;jerry&apos;@&apos;localhost&apos;;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL语法之DML]]></title>
    <url>%2F2018%2F08%2F10%2Fmysql-dml%2F</url>
    <content type="text"><![CDATA[本文主要介绍MySQL语法之DML(data manipulate language)操作。 1.数据操纵语言DML主要是对数据库里的数据进行操作的语言。包括INSERT、UPDATE、DELETE等。 2.INSERT语句 1234567891011121314mysql&gt; create table emp (empno int ,ename varchar(20), sex char(1),birthday date , hiredate date, sal decimal(10,2), deptno tinyint(1), managerno int) engine=memory default charset=utf8;mysql&gt; create table dept (deptno tinyint(1),deptname varchar(30),location varchar(50)); mysql&gt; insert into dept values (1,&apos;manager&apos;,&apos;beijing&apos;),(2,&apos;it&apos;,&apos;shenzhen&apos;), (3,&apos;sale&apos;,&apos;shanghai&apos;), (4,&apos;services&apos;,&apos;guangzhou&apos;);# 插入单条数据mysql&gt; insert into emp values (1,&apos;boss&apos;,&apos;m&apos;,&apos;1964-08-08&apos;,&apos;1995-01-01&apos;,&apos;20000&apos;,&apos;1&apos;,&apos;1&apos;);# 插入多条数据mysql&gt;insert into emp values -&gt; (1,&apos;boss&apos;,&apos;m&apos;,&apos;1964-08-08&apos;,&apos;1995-01-01&apos;,&apos;20000&apos;,&apos;1&apos;,&apos;1&apos;), -&gt;(2,&apos;zhangsan&apos;,&apos;m&apos;,&apos;1967-04-05&apos;,&apos;1995-04-11&apos;,&apos;15000&apos;,&apos;2&apos;,&apos;1&apos;);# 还可以插入特定的列（非所有列），那么没有插入的就成了空值（空值不是0，它做任何运算结果还是空值)mysql&gt; insert into emp (ename,sex) values (&apos;lisi&apos;,&apos;m&apos;);# 从其他表中查询到数据后插入mysql&gt; insert into emp (ename,sex) select ename,sex from emp1 limit 2; 3.UPDATE语句 1234567891011121314151617181920# 把wangwu性别改成mmysql&gt; update emp set sex=&apos;m&apos; where ename=&apos;wangwu&apos;;# wangwu的工资加500mysql&gt; update emp set sal=sal+500 where ename=&apos;wangwu&apos;;# 2号部门的所有员工工资涨10%mysql&gt; update emp set sal=sal*1.1 where deptno=2;# mark由3号部门换成2号部门，同时工资加1000mysql&gt; update emp set deptno=2 and sal=sal+1000 where ename=&apos;mark&apos;; --错误写法，两个执行动作不能用andmysql&gt; update emp set deptno=2,sal=sal+1000 where ename=&apos;mark&apos;; --正确写法# 工资就john和mark涨10%,其它人不涨mysql&gt; update emp set sal=sal*1.1 where ename=&apos;john&apos; or ename=&apos;mark&apos;;mysql&gt; update emp set sal=sal*1.1 where ename in (&apos;john&apos;,&apos;mark&apos;);# 工资都涨10%，john和mark犯错误，就他们不涨mysql&gt; update emp set sal=sal*1.1 where ename!=&apos;john&apos; and ename!=&apos;mark&apos;mysql&gt; update emp set sal=sal*1.1 where ename not in (&apos;john&apos;,&apos;mark&apos;); 4.DELETE语句 1234# 指定条件删除mysql&gt; delete from emp where empno=9;# 不指定条件删除mysql&gt; delete from emp;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL语法之DDL]]></title>
    <url>%2F2018%2F08%2F10%2Fmysql-ddl%2F</url>
    <content type="text"><![CDATA[本文主要介绍MySQL语法之DDL(data define language)操作。 1.MySQL数据定义语言用于定义和管理数据对象，包括数据库、数据表等。包括CREATE、DROP、ALTER、TRUNCATE、RENAME等。 2. CREATE语句 CREATE DATABASE建库 123456# 建库语句mysql&gt; CREATE DATABASE IF NOT EXISTS db1 DEFAULT CHARACTER SET UTF8;# 其中有一部分可以省略mysql&gt; CREATE DATABASE db1;# 查看系统是如何建库的mysql&gt; SHOW CREATE DATABASE db1; CREATE TABLE建表 123456789101112# 建表语句mysql&gt; CREATE TABLE IF NOT EXISTS emp(id int) ENGINE=InnoDB DEFAULT CHARSET=utf8;mysql&gt; CREATE TABLE IF NOT EXISTS emp1(ID INT NOT NULL DEFAULT 1, NAME CHAR);mysql&gt; CREATE TABLE IF NOT EXISTS emp2(ID INT NOT NULL AUTO_INCREMENT, NAME CHAR);# 其中有一部分可以省略mysql&gt; CREATE TABLE emp(id int);# 查看系统是如何建表的mysql&gt; SHOW CREATE TABLE emp;# 使用like建表，快速建立相同表结构的表# CREATE TABLE imp LIKE emp;# DESC emp;# DESC imp; CREATE USER建用户12345678910# 创建一个用户mysql&gt; CREATE USER &apos;jeffrey&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;new_password&apos; PASSWORD EXPIRE;# 查看系统是如何创建的mysql&gt; SHOW CREATE USER &apos;jeffrey&apos;@&apos;localhost&apos;;# 创建一个用户，指定过期时间mysql&gt; CREATE USER &apos;tom&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;new_password&apos; PASSWORD EXPIRE INTERVAL 180 DAY;# 查看系统是如何创建的mysql&gt; SHOW CREATE USER &apos;tom&apos;@&apos;localhost&apos;;# 查看user.assword_last_changed 列来看对应账号密码的最近一次的修改时间mysql&gt; select user,host,password_expired,password_last_changed,password_lifetime from mysql.user; CREATE VIEW建视图视图是一个虚拟存在的表，视图的使用方式与表的使用方式一致，不需要实际上的物理存储，数据还是存储在原来的表里。视图可以只展现数据表的一部分数据，对于我们不希望让用户看到全部数据，只希望用户看到部分数据的时候，可以选择使用视图。1234567891011# 创建视图mysql&gt; create view emp_view as SELECT * from emp;# 查看视图表结构mysql&gt; desc emp_view;# 查看视图内容mysql&gt; select * from emp_view limit 1;# 修改视图msyql&gt; alter view emp_view as SELECT * FROM emp;mysql&gt; UPDATE emp_view set ename=&apos;lisi&apos; WHERE ename=&apos;zhangsan&apos;;# 删除视图mysql&gt; drop view emp_view; 3. ALTER语句 1234567891011121314151617181920212223# 建一个测试表mysql&gt; create table emp ( ename varchar(20), sex char(1), hiredate date, sal decimal(10,2), deptno tinyint(1)) engine=memory default charset=utf8; mysql&gt; SHOW COLUMNS FROM emp;# 修改存储引擎mysql&gt; ALTER TABLE emp ENGINE=MEMORY;# 修改字符集mysql&gt; ALTER TABLE emp DEFAULT CHARSET=utf8;# 增加一个列，默认增加到最后mysql&gt; alter table emp add age tinyint(1);mysql&gt; SHOW COLUMNS FROM emp;# 删除某一列mysql&gt; alter table emp drop age;在hiredate这列后面增加一列，使用after关键字mysql&gt; alter table emp add manager varchar(30) after hiredate;# 把一列加到最前面，使用first关键字mysql&gt; alter table emp add manager varchar(30) first; # 使用modify修改一列的数据类型mysql&gt; alter table emp modify manager varchar(40);# 修改列名要使用change去修改mysql&gt; alter table emp change manager boss varchar(30); --# modify和change的区别，都可以修改数据类型，但change要写原列名;只有change可以修改列名，modify不可以# 修改mysql字符集mysql&gt; alter database app_relation character set utf8; 4.其他DDL语句 TRUNCATE语句12# 截断表，清空了表内的所有数据，但是表的结构还在mysql&gt; truncate table emp; RENAME语句12# 修改表的名字mysql&gt; rename table emp to emp1; DROP语句123456# 删库mysql&gt; DROP DATABASE IF EXISTS db1;# 删表mysql&gt; DROP TABLE IF EXISTS emp;# 删视图mysql&gt; drop view emp_view;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL语法之列属性和索引]]></title>
    <url>%2F2018%2F08%2F10%2Fmysql-columns%2F</url>
    <content type="text"><![CDATA[本文主要介绍MySQL语法之列属性。 1.关于列属性 MySQL中，真正约束字段的是数据类型，但是数据类型的约束太单一，需要有一些额外的约束，来更加保证数据的合法性。 MySQL中的常用列属性有：null、not null、default、primary key、auto_increment和comment。 2.列属性 空属性两个值：NULL(默认的)/NOT NULL(不为空) 虽然默认的，数据库基本都是字段为空，但是实际上在真实开发的时候，尽可能的要保证所有的数据都不应该为空：空数据没有意义;空数据没有办法参与运算 1mysql&gt; create table user(id varchar(40) not null, name varchar(20) not null,age tinyint,address varchar(40) null,gender enum(&apos;boy&apos;,&apos;girl&apos;,&apos;secret&apos;) default &apos;secret&apos;); 列描述列描述 ：comment描述，没有实际含义：是专门用来描述字段，会根据表创建语句保存：用来给程序猿(数据库管理员)来进行了解的 12mysql&gt; create table user(id varchar(40) not null comment &apos;身份证号&apos;, name varchar(20) not null comment &apos;姓名&apos;,age tinyint comment &apos;年龄&apos;,address varchar(40) null comment &apos;地址&apos;,gender enum(&apos;boy&apos;,&apos;girl&apos;,&apos;secret&apos;) default &apos;secret&apos; comment &apos;性别&apos;);mysql&gt; show full columns from user; 默认值默认值：某一种数据会经常性的出现某个具体的值，可以在一开始就指d定好，在需要真实数据的时候，用户可以选择性的使用默认值 默认值关键字：default1mysql&gt; create table user(id varchar(40) not null comment &apos;身份证号&apos;, name varchar(20) not null comment &apos;姓名&apos;,age tinyint comment &apos;年龄&apos;,address varchar(40) null comment &apos;地址&apos;,gender enum(&apos;boy&apos;,&apos;girl&apos;,&apos;secret&apos;) default &apos;secret&apos; comment &apos;性别&apos;); 主键主键：primary key，一张表只能有一个字段可以使用对应的键,用来唯一的约束该字段里面的数据，不能重复 1mysql&gt; create table user(id varchar(40) not null primary key comment &apos;身份证号&apos;, name varchar(20) not null comment &apos;姓名&apos;,age tinyint comment &apos;年龄&apos;); 唯一键一张表往往有很多字段需要具有唯一性，数据不能重复。 123mysql&gt; create table student(id varchar(30) not null, stu_num int unique,name varchar(20));mysql&gt; alter table student add unique key(stu_num); 自动增长自动增长通常是跟主键进行搭配,一般而言,声明为自动增长属性的字段,插入数据的时候系统会自动的在当前最大值的基础上对指定的数据+1。自动增长(auto_increment)有几个必要的条件。任何一个字段要做自动增长的前提是本身是一个索引(key一栏有值)。自动增长必须是数字而且是整型。一张表只能有一个自增长,自动增长的起始默认值是1 1234567mysql&gt; create table my_auto(id int primary key auto_increment comment &apos;自动增长&apos;,name varchar(10) not null);修改自动增长的步长:mysql&gt; set auto_increment_increment=5;删除字段的自动增长的属性:mysql&gt; alter table my_auto modify id int; 3.索引 索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。更通俗的说，数据库索引好比是一本书前面的目录，能加快数据库的查询速度。上述SQL语句，在没有索引的情况下，数据库会遍历全部数据后选择符合条件的；而有了相应的索引之后，数据库会直接在索引中查找符合条件的选项。如果我们把SQL语句换成“SELECT * FROM article WHERE id=2000000”，那么你是希望数据库按照顺序读取完200万行数据以后给你结果还是直接在索引中定位呢？上面的两个图片鲜明的用时对比已经给出了答案（注：一般数据库默认都会为主键生成索引）。 索引分为聚簇索引和非聚簇索引两种，聚簇索引是按照数据存放的物理位置为顺序的，而非聚簇索引就不一样了；聚簇索引能提高多行检索的速度，而非聚簇索引对于单行的检索很快。 索引是一种数据结构，可以是B-tree, R-tree, 或者 hash 结构。其中R-tree 常用于查询比较接近的数据；B-trees适合用于查找某范围内的数据，可以很快的从当前数据找到下条数据；hash结构则适用于随机访问的场合，查找每条数据的时间几乎相同。显然，若要查找某个时间段的数据，用B-tree结构要比hash结构快好多。 普通索引这是最基本的索引，它没有任何限制。1234567891011121314151617181920212223242526mysql&gt; CREATE TABLE mytable(ID INT NOT NULL, username VARCHAR(16) NOT NULL,INDEX (username(16)));如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB和TEXT类型，必须指定 length。这个length的用处是什么?CREATE INDEX part_of_name ON customer (name(10));创建索引时，使用col_name(length)语法，对前缀编制索引。前缀包括每列值的前length个字符。使用列的一部分创建索引可以使索引文件大大减小，从而节省了大量的磁盘空间，有可能提高INSERT操作的速度。直接创建索引:mysql&gt; CREATE INDEX index_name ON table(column(length))mysql&gt; CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL );mysql&gt; create index user_index on mytable(username(16));查看索引：mysql&gt; show index from mytable;修改表结构的方式添加索引:mysql&gt; ALTER TABLE table_name ADD INDEX index_name (column(length))mysql&gt; alter table mytable add index user_index (username(16));删除索引:mysql&gt; DROP INDEX index_name ON tablemysql&gt; drop index user_index on mytable; 唯一索引与普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值（注意和主键不同）。 12345678910111213141516mysql&gt; CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, INDEX (username(16)) ); 直接创建索引:mysql&gt; CREATE INDEX index_name ON table(column(length))mysql&gt; create index user_index on mytable(username(16));修改表结构的方式添加索引:mysql&gt; ALTER TABLE table_name ADD UNIQUE indexName (column(length))mysql&gt; alter table mytable add UNIQUE user_index (username(16));删除索引:mysql&gt; DROP INDEX index_name ON tablemysql&gt; drop index user_index on mytable; 其他索引都是类似的，本文不涉及。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F07%2F19%2Flinux-live%2F</url>
    <content type="text"><![CDATA[直播 这里是直播的观看地址，可以直接观看，不需要其他播放器的支持。请允许您的浏览器支持flash插件。原来使用播放器播放的方式也是可以的。 (function () { var player = new qcVideo.Player("id_video_container", { "live_url" : "http://2117.liveplay.myqcloud.com/live/2117_332e62ae51.flv", "live_url2" : "http://2117.liveplay.myqcloud.com/live/2117_332e62ae51.m3u8", "width" : 480, "height" : 320 }); })()]]></content>
  </entry>
  <entry>
    <title><![CDATA[lftp命令详解]]></title>
    <url>%2F2018%2F07%2F12%2Flinux-lftp%2F</url>
    <content type="text"><![CDATA[本文主要介绍FTP客户端工具lftp的使用方法。 1.安装1# yum -y install lftp 2.登录登录方法： 1234# lftp ftp://ftpuser:123456@192.168.0.213:21 # ftp://可以省略，ftp协议端口是21# lftp ftp://ftpuser@192.168.0.213:21 # 密码可以单独输入# lftp sftp://ftpuser:123456@192.168.0.213:22 # sftp协议，端口是22# lftp sftp://ftpuser@192.168.0.213:22 # 密码可以单独输入 3.用法 查看或者改变目录 123cd # 进入远程目录cd .. # 进入上一级目录ls # 查看文件列表 文件下载 12345get xxx # 下载xxx文件mget *.txt # 使用通配符下载mget -c xxx # 断点续传mirror aaa/ # 将aaa目录整个的下载下来，子目录也会自动复制pget -c -n 10 file.dat # 可以多线程下载 文件上传 123put xxxmput xxx1 xxx2 xxx3mirror -R 本地目录名 # 将本地目录以迭代（包括子目录）的方式反向上传 其他 12345678910111213mkdir -p a/b/c # 创建多级目录rm -rf a/ # 删除文件或目录cat a.txt # 查看远程文件内容queue get 123.txt # 将任务加入任务列表queue put 234.txtqueue mirror aaa/queue # 查看任务列表queue start # 开始任务列表queue stop # 停止任务列表jobs # 查看后台任务列表kill all # 删除全部的jobsmv # 重命名文件open 127.0.0.1 # 连接ftp 4.脚本 上传脚本1234567891011#!/bin/bashecho "script start at `date "+%Y-%m-%d %H:%M:%S"` "lftp &lt;&lt; EOFopen ftp://ftpuser:123456@127.0.0.1:21mirror -R /root/upload/test /code/close byeEOFecho "script end at `date "+%Y-%m-%d %H:%M:%S"` "]]></content>
      <categories>
        <category>linux-basic</category>
      </categories>
      <tags>
        <tag>linux-basic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux安装vsftpd及配置详解]]></title>
    <url>%2F2018%2F07%2F02%2Fvsftpd%2F</url>
    <content type="text"><![CDATA[本文主要介绍Centos6.x安装vsftpd、配置文件、以及客户端的使用。 1.FTP服务端和客户端的安装Centos默认Yum源自带了ftp的服务端和客户端软件，直接使用Yum安装。1# yum -y install vsftpd ftp 2.FTP主动模式与FTP被动模式 主动模式 主动：默认情况下，ftp服务是开放了21端口，用来接受控制命令，服务器用20端口去发送数据（连接客户端大于1024的随机端口） 123server client21 &lt;-----------命令----------- 随机端口20 ------------数据----------&gt; 随机端口 被动模式 被动：ftp服务也是开放21端口，用来接受命令控制，进行数据传输时，客户端会告知服务端打开一个大于1024的端口，然后客户端去主动连接服务 123server client21 &lt;-----------命令----------- 随机端口随机端口 ---------数据-----------&gt; 随机端口 主动模式：建立数据链路时由sever端去主动连接客户端的大于1024的随机端口被动模式：建立数据链路时由client端去主动连服务端的随机端口 vsftpd默认使用被动模式。 3. FTP匿名登录先启动vsftpd服务端： 1# /etc/init.d/vsftpd start 使用ftp客户端连接： 12345678910111213# ftp localhostTrying ::1...ftp: connect to address ::1Connection refusedTrying 127.0.0.1...Connected to localhost (127.0.0.1).220 (vsFTPd 2.2.2)Name (localhost:root): ftp331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.ftp&gt; 匿名用户有两个： 用户名：anonymous 密码：空 用户名：ftp 密码：空 4.配置文件 默认配置文件 12345678910111213# cat /etc/vsftpd/vsftpd.conf |grep -v ^# |grep -v ^$anonymous_enable=YES #允许匿名用户登录local_enable=YES #允许本地用户登录write_enable=YES #允许本地用户登录后可写local_umask=022 #建立文件或者目录的权限掩码dirmessage_enable=YES #启用目录的说明或者欢迎信息xferlog_enable=YES #打开日志功能 （只记录文件的上传和下载信息）connect_from_port_20=YES #默认支持主动模式（两个模式都是开启的，直接使用的话是使用的被动模式）xferlog_std_format=YES #日志使用xferlog而不是vsftpd.log，改为NO的话，则相反listen=YES #默认运行在stand alone下pam_service_name=vsftpd #支持pam（可植入模块）userlist_enable=YES #打开用户列表的功能tcp_wrappers=YES #支持tcp_wrappers 匿名用户（anonymous）设置 不允许匿名用户登录 123# vim /etc/vsftpd/vsftpd.confanonymous_enable=NO #修改配置文件# /etc/init.d/vsftpd reload 匿名用户下载 匿名用户默认是可以登录，也可以下载。默认使用匿名用户登录的服务端的/var/ftp目录下。 匿名用户上传 默认是不允许匿名用户上传的 123456# vim /etc/vsftpd/vsftpd.confanonymous_enable=YES #允许匿名用户登录anon_upload_enable=YES #允许匿名用户上传文件anon_mkdir_write_enable=YES #允许匿名用户创建目录anon_other_write_enable=yes #允许匿名用户可以删除文件和重命名文件# chmod 777 /var/ftp/pub #把pub改为可写，用于上传 普通用户（local）设置 普通用户登录 配置文件中local_enable=YES，默认是允许普通用户登录的。如果要限制普通用户登录，可以通过户列表来控制。 1234# vim /etc/vsftpd/vsftpd.confuserlist_enable=yes #打开用户列表功能userlist_deny=YES #这一句可加可不加，默认就是有这一句的# vim /etc/vsftpd/user_list #加上要禁止的用户，一个用户写一行 普通用户的下载和上传 默认是允许下载和上传的。允许上传除了系统目录有写权限外，还有与服务的参数write_enable=YES有关。 所有的本地用户（非匿名用户）登录后，都统一登录到/ftpdata/目录下： 方法一：把所有的用户家目录改成/ftpdata/。但这样做会影响到系统用户登录到自己的家目录 方法二：使用下面的参数，它不影响你系统用户登录到自己的家目录local_root=/ftpdata 关于chroot环境 默认情况下，普通用户（匿名用户除外）可以登录ftp后，cd切换到/下的任何地方，只要有r权限，就可以get文件，那么显示是不安全的。 12345678910111213141516171819202122232425262728293031ftp&gt; ls /227 Entering Passive Mode (127,0,0,1,182,179).150 Here comes the directory listing.dr-xr-xr-x 2 0 0 4096 Jun 26 19:11 bindr-xr-xr-x 5 0 0 1024 Apr 10 13:58 bootdrwxr-xr-x 2 0 0 4096 Oct 04 2017 cgroupdrwxr-xr-x 3 0 0 4096 Apr 10 13:38 datadrwxr-xr-x 18 0 0 3820 Jun 04 00:52 devdrwxr-xr-x 129 0 0 12288 Jun 29 19:19 etcdrwxr-xr-x 4 0 0 4096 Jun 26 08:19 homedrwxr-xr-x 2 0 0 4096 Apr 16 07:58 ksdr-xr-xr-x 11 0 0 4096 Apr 10 16:22 libdr-xr-xr-x 10 0 0 12288 Jun 26 19:11 lib64drwx------ 2 0 0 16384 Apr 10 13:38 lost+founddrwxr-xr-x 3 0 0 4096 Jun 01 06:05 mediadrwxr-xr-x 2 0 0 0 Jun 04 00:51 miscdrwxr-xr-x 3 0 0 4096 Apr 10 16:13 mntdrwxr-xr-x 2 0 0 0 Jun 04 00:51 netdrwxr-xr-x 3 0 0 4096 Jun 26 09:25 optdr-xr-xr-x 151 0 0 0 Jun 04 00:51 procdrwxr-xr-x 3 0 0 4096 Jun 21 06:52 pydashdr-xr-x--- 38 0 0 4096 Jul 02 06:38 rootdr-xr-xr-x 2 0 0 12288 Jun 26 19:11 sbindrwxr-xr-x 2 0 0 4096 Apr 10 13:42 selinuxdrwxr-xr-x 2 0 0 4096 Sep 23 2011 srvdrwxr-xr-x 13 0 0 0 Jun 04 00:51 sysdrwxrwxrwt 8 0 0 4096 Jul 01 19:19 tmpdrwxr-xr-x 13 0 0 4096 Apr 10 13:42 usrdrwxr-xr-x 23 0 0 4096 Jun 26 08:16 vardr-xr-xr-x 7 0 0 4096 Nov 29 2013 yum226 Directory send OK. 普通用户ls /，可以看到系统的根目录，进入相应的目录就可以下载。 通过chroot将普通用户限制在它的家目录。 12345# vim /etc/vsftpd/vsftpd.confchroot_list_enable=YESchroot_list_file=/etc/vsftpd/chroot_list# vim /etc/vsftpd/chroot_list #创建这个文件，并写上要加入笼环境的用户名，一行写一个# /etc/init.d/vsftpd reload 如何把所有的普通用户（匿名用户默认就是笼环境)加入到chroot环境？ 1# chroot_local_user=YES 注意： 对于chroot_local_user与chroot_list_enable的组合效果，可以参考下表： chroot_local_user=YES chroot_local_user=NO chroot_list_enable=YES (1)所有用户都被限制在其主目录下 (2)使用chroot_list_file指定的用户列表，这些用户作为“例外”，不受限制 (1)所有用户都不被限制其主目录下 (2)使用chroot_list_file指定的用户列表，这些用户作为“例外”，受到限制 chroot_list_enable=NO (1)所有用户都被限制在其主目录下 (2)不使用chroot_list_file指定的用户列表，没有任何“例外”用户 (1)所有用户都不被限制其主目录下 (2)不使用chroot_list_file指定的用户列表，没有任何“例外”用户 被动连接模式，控制服务器数据传输端口的范围 1234567# vim /etc/vsftpd/vsftpd.confpasv_enable=YES #这一句默认不加也可以pasv_min_port=3000pasv_max_port=3005 #最小端口范围和最大端口范围可以自定义，也可以使用同一个端口# netstat -nt |grep TIME_tcp 0 0 127.0.0.1:3000 127.0.0.1:38206 TIME_WAIT 5.客户端工具的使用 ftp使用 12345678910111213141516171819202122232425# ftp 127.0.0.1ftp&gt; ls #查看远程文件ftp&gt; !ls #感叹号后面执行本地命令ftp&gt; ! #退出ftp命令行ftp&gt; append ks.cfg a.txt #把本地的ks.cfg文件的内容追加到远程的a.txtftp&gt; cd ftp #进入远程的ftp目录ftp&gt; lcd /root/ #改变本地工作目录ftp&gt; get hello.txt #复制单个远程文件到本地ftp&gt; put a.txt #复制一个本地文件到远程ftp&gt; del ftp.txt #删除远程单个文件ftp&gt; open 127.0.0.1 #连接到远程服务器ftp&gt; close #结束FTP会话并返回命令行ftp&gt; bye #结束FTP会话并退出ftp&gt; glob #开关文件名通配符（默认ON）ftp&gt; mget 1.tmp 2.tmp 3.tmp #复制一个或多个远程文件至本地 （ftp -i 127.0.0.1）ftp&gt; mdel *.php #删除远程一个或多个文件ftp&gt; mkdir tmp #创建一个远程目录ftp&gt; mput *.txt #复制一个或多个本地文件到远程ftp&gt; pwd #显示远程当前工作目录ftp&gt; recv 1.tmp #复制远程文件到本地ftp&gt; rename 1.tmp 1.tmp.bak #重命名远程文件ftp&gt; rmdir tmp #删除远程目录ftp&gt; send 1.tmp #复制一个本地文件到远程（功能同put）ftp&gt; passive #主被动模式切换]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache服务器开启webDAV模块]]></title>
    <url>%2F2018%2F06%2F26%2Fhttpd-webdav%2F</url>
    <content type="text"><![CDATA[本文主要介绍Centos6.x系统Apache服务器开启webDAV模块。 1.安装Apache12# yum -y install httpd apr apr-util httpd-devel 安装# chkconfig httpd on 开机启动 2.配置WebDAV模块12345678910111213141516171819202122# vim /etc/httpd/conf.d/webdav.conf 在Apache的子配置文件目录新建文件&lt;IfModule mod_dav.c&gt;LimitXMLRequestBody 131072Alias /webdav "/var/www/webdav"&lt;Directory /var/www/webdav&gt; Dav On Options +Indexes IndexOptions FancyIndexing AddDefaultCharset UTF-8 AuthType Basic AuthName "WebDAV Server" AuthUserFile /etc/httpd/webdav.users.pwd Require valid-user Order allow,deny Allow from all&lt;/Directory&gt;&lt;/IfModule&gt;# mkdir -p /var/www/webdav# chown apache:apache /var/www/webdav# htpasswd -c /etc/httpd/webdav.users.pwd test 根据提示输入密码，切记一定要设置密码，否则会有安全问题# service httpd restart 重启apache服务 3.测试通过浏览器访问：访问本机 , 访问远程：http://ip/webdav 4.将webdav映射成本地磁盘在windows上映射成本地磁盘，需要注意：WIN7以上版本的操作系统微软禁用了http形式的基本WebDAV验证形式（KB841215），此时我们需要修改注册表来实现。修改HKEY_LOCAL_MACHINE&gt;&gt;SYSTEM&gt;&gt;CurrentControlSet&gt;&gt;Services&gt;&gt;WebClient&gt;&gt;Parameters&gt;&gt;BasicAuthLevel把这个值从1改为2，然后进控制面板，服务，把WebClient服务重启（没有启动的就启动它）。 具体操作如下：在桌面上【我的电脑】图标上点击【右键】，选择【映射网络驱动器】，在弹出框中填入上面的地址，比如：http://192.168.0.215/webdav/ ，勾选【登录时重新连接】和【使用其他凭据连接】，然后点击【完成】。输入【账号和密码】就可以进入了。 5.将webdav挂载到linux上linux系统上有多个办法来使用webdav服务。(1) davfs2工具12345678910111213141516171819# yum install epel-release -y 安装epel源# yum install davfs2 -y 安装davfs# mkdir /mnt/webdav 创建用于挂载的目录# mount -t davfs http://192.168.0.215/webdav /mnt/webdav/ 挂载Please enter the username to authenticate with serverhttp://192.168.0.215/webdav or hit enter for none. Username: test 用户名Please enter the password to authenticate user test with serverhttp://192.168.0.215/webdav or hit enter for none. Password: 密码 # df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/VolGroup-lv_root 50G 19G 29G 40% /tmpfs 3.9G 0 3.9G 0% /dev/shm/dev/sda1 485M 39M 421M 9% /boot/dev/mapper/VolGroup-lv_home 435G 199M 413G 1% /homehttp://192.168.0.215/webdav 26G 13G 13G 50% /mnt/webdav (2) cadaver工具123456789101112131415161718# yum install cadaver -y# cadaver http://192.168.0.215/webdavAuthentication required for WebDAV Server on server `192.168.0.215':Username: testPassword: dav:/webdav/&gt; lsListing collection `/webdav/': collection is empty.dav:/webdav/&gt; helpAvailable commands: ls cd pwd put get mget mput edit less mkcol cat delete rmcol copy move lock unlock discover steal showlocks version checkin checkout uncheckout history label propnames chexec propget propdel propset search set open close echo quit unset lcd lls lpwd logout help describe about Aliases: rm=delete, mkdir=mkcol, mv=move, cp=copy, more=less, quit=exit=bye (3) curl命令1234上传：# curl -v --user test:123456 -T install.log http://192.168.0.215/webdav/下载：# curl --user test:123456 http://192.168.0.215/webdav/install.log &gt; install.txt]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Memcache安装和配置]]></title>
    <url>%2F2018%2F06%2F25%2Fmemcached-install%2F</url>
    <content type="text"><![CDATA[本文主要介绍Centos6.x系统通过YUM安装Memcache安装和配置。 1.安装1# yum search memcached 2.启停和连接1234567# memcached -h# service memcached start# service memcached stop# netstat -antp | grep memcached tcp 0 0 0.0.0.0:11211 0.0.0.0:* LISTEN 2608/memcached tcp 0 0 :::11211 :::* LISTEN 2608/memcached 3.配置文件配置文件：/etc/sysconfig/memcached123456789101112131415161718192021222324252627282930313233343536373839404142434445## Properties file with JDBC-related settings.# Applied by PropertyPlaceholderConfigurer from "applicationcontext-*.xml".# Targeted at system administrators, to avoid touching the context XML files.#memcached.servers=127.0.0.1:11211#memcached.weights=1memcached.servers=127.0.0.1:11211memcached.weights=1#初始连接数memcached.initConn=5#最小连接数memcached.minConn=5#最大连接数memcached.maxConn=250#最大处理时间(豪秒)memcached.maxIdle=21600000#主线程睡眠时间(豪秒) 连接池维护线程的睡眠时间 设置为0，维护线程不启动 维护线程主要通过log输出socket的运行状况，监测连接数目及空闲等待时间等参数以控制连接创建和关闭。memcached.maintSleep=30#是否使用Nagle算法，因为我们的通讯数据量通常都比较大（相对TCP控制数据）而且要求响应及时，因此该值需要设置为false（默认是true）memcached.nagle=false#socket连接读取超时时间(豪秒)memcached.socketTo=3000#设置socket的连接等待超时值memcached.socketConnectTo=0#是否压缩数据 默认值是turememcached.compressEnable=true#指定压缩大小(单位:K) 默认值是30Kmemcached.compressThreshold=65530#连接心跳监测开关。设为true则每次通信都要进行连接是否有效的监测，造成通信次数倍增，加大网络负载，因此该参数应该在对HA要求比较高的场合设为TRUE，默认状态是false。memcached.alivecheck=false;# 连接失败恢复开关 设置为TRUE，当宕机的服务器启动或中断的网络连接后，这个socket连接还可继续使用，否则将不再使用，默认状态是true，建议保持默认。memcached.failback=true;# 容错开关 设置为TRUE，当当前socket不可用时，程序会自动查找可用连接并返回，否则返回NULL，默认状态是true，建议保持默认。memcached.failover=true;#cache数据的原始类型是String 默认值是false 只有在确定cache的数据类型是string的情况下才设为true，这样可以加快处理速度。memcached.primitiveasstring=false;# 当primitiveAsString为true时使用的编码转化格式 默认值是utf-8 如果确认主要写入数据是中文等非ASCII编码字符，建议采用GBK等更短的编码格式memcached.defaultencoding=utf-8]]></content>
      <categories>
        <category>nosql</category>
      </categories>
      <tags>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB安装和配置]]></title>
    <url>%2F2018%2F06%2F25%2Fmongodb-install%2F</url>
    <content type="text"><![CDATA[本文主要介绍Centos6.x系统通过YUM安装MongoDB和配置。 1.安装配置YUM源：123456789# vim /etc/yum.repos.d/mongodb.repo[mongodb]name=mongodb Repositorybaseurl=http://downloads-distro.mongodb.org/repo/redhat/os/x86_64#baseurl=https://repo.mongodb.org/yum/redhat/6/mongodb-org/3.7/x86_64/enabled=1gpgcheck=0# yum install mongodb mongodb-server 2.启停和连接1234# service mongod start# netstat -atnp | grep mongodtcp 0 0 127.0.0.1:27017 0.0.0.0:* LISTEN 2021/mongod# service mongod stop 3.配置文件配置文件：/etc/mongod.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384# mongo.conf #where to log logpath=/var/log/mongo/mongod.log logappend=true #以追加方式写入日志 # fork and run in background fork = true #port = 27017 #端口 dbpath=/var/lib/mongo #数据库文件保存位置 directoryperdb=true# Enables periodic logging of CPU utilization and I/O wait #启用定期记录CPU利用率和 I/O 等待 #cpu = true # Turn on/off security. Off is currently the default # 是否以安全认证方式运行，默认是不认证的非安全方式 #noauth = true #auth = true # Verbose logging output. # 详细记录输出 #verbose = true # Inspect all client data for validity on receipt (useful for # developing drivers)用于开发驱动程序时的检查客户端接收数据的有效性 #objcheck = true # Enable db quota management 启用数据库配额管理，默认每个db可以有8个文件，可以用quotaFiles参数设置 #quota = true # 设置oplog记录等级 # Set oplogging level where n is # 0=off (default) # 1=W # 2=R # 3=both # 7=W+some reads #oplog = 0 # Diagnostic/debugging option 动态调试项 #nocursors = true # Ignore query hints 忽略查询提示 #nohints = true # 禁用http界面，默认为localhost：28017 # Disable the HTTP interface (Defaults to localhost:27018).这个端口号写的是错的 #nohttpinterface = true # 关闭服务器端脚本，这将极大的限制功能 # Turns off server-side scripting. This will result in greatly limited # functionality #noscripting = true # 关闭扫描表，任何查询将会是扫描失败 # Turns off table scans. Any query that would do a table scan fails. #notablescan = true # 关闭数据文件预分配 # Disable data file preallocation. #noprealloc = true # 为新数据库指定.ns文件的大小，单位:MB # Specify .ns file size for new databases. # nssize = &lt;size&gt; # Accout token for Mongo monitoring server. #mms-token = &lt;token&gt; # mongo监控服务器的名称 # Server name for Mongo monitoring server. #mms-name = &lt;server-name&gt; # mongo监控服务器的ping 间隔 # Ping interval for Mongo monitoring server. #mms-interval = &lt;seconds&gt; # Replication Options 复制选项 # in replicated mongo databases, specify here whether this is a slave or master 在复制中，指定当前是从属关系 #slave = true #source = master.example.com # Slave only: specify a single database to replicate #only = master.example.com # or #master = true #source = slave.example.com]]></content>
      <categories>
        <category>nosql</category>
      </categories>
      <tags>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis安装和配置]]></title>
    <url>%2F2018%2F06%2F25%2Fredis-install%2F</url>
    <content type="text"><![CDATA[本文主要介绍Centos6.x系统通过YUM安装redis安装和配置。 1.安装12# yum -y install epel-release yum添加epel源# yum -y install redis 2.启停和连接1234# service redis start# ps -ef | grep redis# redis-cli -h localhost -p 6379 进入redislocalhost:6379&gt; 3.配置文件配置文件：/etc/redis.conf12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#是否作为守护进程运行 daemonize yes #如以后台进程运行，则需指定一个pid，默认为/var/run/redis.pid #pidfile redis.pid #绑定主机IP，默认值为127.0.0.1 bind 182.92.168.171 #Redis默认监听端口 port 6379 #客户端闲置多少秒后，断开连接，默认为300（秒） timeout 300 #日志记录等级，有4个可选值，debug，verbose（默认值），notice，warning loglevel verbose #指定日志输出的文件名，默认值为stdout，也可设为/dev/null屏蔽日志 logfile stdout #可用数据库数，默认值为16，默认数据库为0 databases 16 #保存数据到disk的策略 #当有一条Keys数据被改变是，900秒刷新到disk一次 save 900 1 #当有10条Keys数据被改变时，300秒刷新到disk一次 save 300 10 #当有1w条keys数据被改变时，60秒刷新到disk一次 save 60 10000 #当dump .rdb数据库的时候是否压缩数据对象 rdbcompression yes #本地数据库文件名，默认值为dump.rdb dbfilename dump.rdb #本地数据库存放路径，默认值为 ./ dir /var/lib/redis/ ########### Replication ##################### #Redis的复制配置 # slaveof &lt;masterip&gt; &lt;masterport&gt; 当本机为从服务时，设置主服务的IP及端口 # masterauth &lt;master-password&gt; 当本机为从服务时，设置主服务的连接密码 #连接密码 # requirepass foobared #最大客户端连接数，默认不限制 # maxclients 128 #最大内存使用设置，达到最大内存设置后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理后，任到达最大内存设置，将无法再进行写入操作。 # maxmemory &lt;bytes&gt; #是否在每次更新操作后进行日志记录，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认值为no appendonly no #更新日志文件名，默认值为appendonly.aof #appendfilename #更新日志条件，共有3个可选值。no表示等操作系统进行数据缓存同步到磁盘，always表示每次更新操作后手动调用fsync()将数据写到磁盘，everysec表示每秒同步一次（默认值）。 # appendfsync always appendfsync everysec # appendfsync no ################ VIRTUAL MEMORY ########### #是否开启VM功能，默认值为no vm-enabled no # vm-enabled yes #虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享 vm-swap-file /tmp/redis.swap #将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的 (Redis的索引数据就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0。 vm-max-memory 0 vm-page-size 32 vm-pages 134217728 vm-max-threads 4 ############# ADVANCED CONFIG ############### glueoutputbuf yes hash-max-zipmap-entries 64 hash-max-zipmap-value 512 #是否重置Hash表 activerehashing yes]]></content>
      <categories>
        <category>nosql</category>
      </categories>
      <tags>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门]]></title>
    <url>%2F2018%2F06%2F25%2Fdocker-basic%2F</url>
    <content type="text"><![CDATA[本文主要介绍Centos6.x系统安装docker，以及docker的基本操作。 1.Docker概述Docker是一种虚拟化技术，即容器。容器不是模拟一个完整的操作系统，而是对进程进行隔离。对于容器里面的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离。 2.Docker安装Docker 是一个开源的商业产品，有两个版本：社区版（Community Edition，缩写为 CE）和企业版（Enterprise Edition，缩写为 EE）。下面的介绍都针对社区版。12# yum install epel-release -y 安装epel源# yum install docker-io 安装docker 安装完成后，运行下面的命令，验证是否安装成功。1# docker version 启动docker服务：12# service docker start# chkconfig docker on 3.镜像操作 列出本地镜像 12# docker images 可以看到没有镜像REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE 创建镜像 创建镜像有很多方法，用户可以从 Docker Hub 获取已有镜像，也可以利用本地文件系统创建一个。 12345# docker pull busybox# docker run busybox echo "hello world"# # docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEbusybox latest bc538d5908c7 4 weeks ago 1.146 MB 删除镜像 123# docker kill $(docker ps -a -q) 杀死所有running状态的容器# docker rm $(docker ps -a -q)# docker rmi bc538d5908c7 删除镜像 搜索镜像 1# docker search centos 下载镜像并启动 12# docker pull centos# docker run -i -t centos /bin/bash 4.docker应用 docker安装mysql服务 1234567891011121314151617# docker pull hub.c.163.com/library/mysql:5.7 拉取mysql镜像，采用网易加速地址# docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEcentos latest 88ec626ba223 2 weeks ago 199.7 MBhub.c.163.com/library/mysql 5.7 573ca163b053 14 months ago 407.1 MB# docker tag hub.c.163.com/library/mysql:5.7 mysql:5.7 重命名镜像名# mkdir /opt/mysql/datadir #用于挂载mysql数据文件# mkdir /opt/mysql/conf.d #用于挂载mysql配置文件# docker run --name mysql5.7 -p 3306:3306 -v /opt/mysql/datadir:/var/lib/mysql -v /opt/mysql/conf.d:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7参数说明：--name：容器名--p：映射宿主主机端口-v：挂载宿主目录到容器目录-e：设置环境变量，此处指定root密码-d：后台运行容器# mysql -h192.168.0.215 -p3306 -uroot -p 连接测试]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysqld_multi实现单机主从复制]]></title>
    <url>%2F2018%2F06%2F24%2Fmysql-replication%2F</url>
    <content type="text"><![CDATA[本文主要介绍mysqld_multi实现单机主从复制。 1.使用mysqld_multi配置三个实例123# mysqld_multi start# mysqld_multi report# netstat -an|grep 330 2.设置一个复制使用的账户123# mysql -uroot -p123456 -S /tmp/mysql.sock3306 主库mysql&gt; grant replication slave on *.* to 'repl'@'localhost' identified by '123';mysql&gt; grant replication slave on *.* to 'repl'@'%' identified by '123'; 3.开启BINLOG12345678910111213141516171819202122232425262728293031323334# vi /etc/my.cnf[mysqld_multi]mysqld = /usr/bin/mysqld_safemysqladmin = /usr/bin/mysqladminuser=rootpass=123456log=/usr/local/mysql/mysql_multi.log [mysqld3306]basedir=/usrdatadir=/usr/local/mysql/data3306port=3306user=mysqlsocket=/tmp/mysql.sock3306server_id=1log_bin=/usr/local/mysql/mysql-bin-3306 [mysqld3307]basedir=/usrdatadir=/usr/local/mysql/data3307port=3307user=mysqlsocket=/tmp/mysql.sock3307server_id=2log_bin=/usr/local/mysql/mysql-bin-3307 [mysqld3308]basedir=/usrdatadir=/usr/local/mysql/data3308port=3308user=mysqlsocket=/tmp/mysql.sock3308server_id=3log_bin=/usr/local/mysql/mysql-bin-3308 4.主库配置12345# mysql -uroot -p123456 -S /tmp/mysql.sock3307mysql&gt; flush tables with read lock;mysql&gt; show master status \Gmysql&gt; unlock tables;mysql&gt; start slave; 5.从库配置1234567# mysql -uroot -p123456 -S /tmp/mysql.sock3307mysql&gt; show variables like '%log_bin%';mysql&gt; stop slave;mysql&gt; change master to master_host='127.0.0.1',master_user='repl',master_password='123',master_log_file='mysql-bin.000001',master_log_pos=0;mysql&gt; start slave;mysql&gt; show slave status \Gmysql&gt; show processlist \G]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx系列教程03]]></title>
    <url>%2F2018%2F06%2F24%2Fnginx-rewrite%2F</url>
    <content type="text"><![CDATA[本文主要介绍nginx服务器的rewrite规则。 1.Nginx URL重写（rewrite）介绍rewrite功能是实现RUL地址的重定向。Nginx的rewrite功能需要PCRE软件的支持，即通过perl兼容正则表达式语句进行规则匹配的。 rewrite语法格式及参数语法： 12345678910111213rewrite &lt;regex&gt; &lt;replacement&gt; [flag]关键字 正则 替代内容 flag标记关键字：其中关键字error_log不能改变正则：perl兼容正则表达式语句进行规则匹配替代内容：将正则匹配的内容替换成replacementflag标记：rewrite支持的flag标记flag标记说明：last #本条规则匹配完成后，继续向下匹配新的location URI规则break #本条规则匹配完成即终止，不再匹配后面的任何规则redirect #返回302临时重定向，浏览器地址会显示跳转后的URL地址permanent #返回301永久重定向，浏览器地址栏会显示跳转后的URL地址 rewrite参数的标签段位置 1server,location,if regex常用正则表达式说明| 字符 | 描述 || - | :-: || \ | 转移字符，如”\n”匹配一个换行符，而”\$”则匹配”$” || ^ | 匹配输入字符串的起始位置 || $ | 匹配输入字符串的结束位置 || | 匹配前面的字符零次或多次。如”ol“能匹配”o”及”ol”、”oll” || + | 匹配前面的字符一次或多次。如“ol+”能匹配“ol”及“oll”、“oll”，但不能匹配“o” || ? | 匹配前面的字符零次或一次，例如“do(es)?”能匹配“do”或者“does”，”?”等效于”{0,1}” || . | 匹配除“\n”之外的任何单个字符 || (pattern) | 常用$0…$9属性获取小括号中的匹配内容，要匹配圆括号字符需要(Content) | 示例：123456789101112131415161718192021222324location = / &#123; #规则A &#125; location = /login &#123; #规则B &#125; location ^~ /static/ &#123; #规则C &#125; location ~ \.(gif|jpg|png|js|css)$ &#123; #规则D &#125; location ~* \.png$ &#123; #规则E &#125; location !~ \.xhtml$ &#123; #规则F &#125; location !~* \.xhtml$ &#123; #规则G &#125; location / &#123; #规则H &#125; 2.常用的变量$args ： #这个变量等于请求行中的参数，同$query_string$content_length ： 请求头中的Content-length字段。$content_type ： 请求头中的Content-Type字段。$document_root ： 当前请求在root指令中指定的值。$host ： 请求主机头字段，否则为服务器名称。$http_user_agent ： 客户端agent信息$http_cookie ： 客户端cookie信息$limit_rate ： 这个变量可以限制连接速率。$request_method ： 客户端请求的动作，通常为GET或POST。$remote_addr ： 客户端的IP地址。$remote_port ： 客户端的端口。$remote_user ： 已经经过Auth Basic Module验证的用户名。$request_filename ： 当前请求的文件路径，由root或alias指令与URI请求生成。$scheme ： HTTP方法（如http，https）。$server_protocol ： 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。$server_addr ： 服务器地址，在完成一次系统调用后可以确定这个值。$server_name ： 服务器名称。$server_port ： 请求到达服务器的端口号。$request_uri ： 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。$uri ： 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”。$document_uri ： 与$uri相同。 3.rewrite应用123456789101112131415161718192021222324if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125; //如果UA包含"MSIE"，rewrite请求到/msid/目录下if ($http_cookie ~* "id=([^;]+)(?:;|$)") &#123; set $id $1; &#125; //如果cookie匹配正则，设置变量$id等于正则引用部分if ($request_method = POST) &#123; return 405;&#125; //如果提交方法为POST，则返回状态405（Method not allowed）。return不能返回301,302if ($slow) &#123; limit_rate 10k;&#125; //限速，$slow可以通过 set 指令设置if (!-f $request_filename)&#123; break; proxy_pass http://127.0.0.1; &#125; //如果请求的文件名不存在，则反向代理到localhost 。这里的break也是停止rewrite检查if ($args ~ post=140)&#123; rewrite ^ http://mysite.com/ permanent;&#125; //如果query string中包含"post=140"，永久重定向到mysite.com 301永久定向到新域名 123456server &#123; listen 80; listen 443 ssl; server_name www.old-name.com old-name.com; return 301 $scheme://www.new-name.com;&#125; 不带www的域名301跳转到带www的域名 123456server &#123; listen 80; listen 443 ssl; server_name mysite.com; return 301 $scheme://www.mysite.com$request_uri;&#125; http站点301跳转到https站点 12345server &#123; listen 80; server_name www.mysite.com; return 301 https://www.mysite.com$request_uri;&#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx系列教程02]]></title>
    <url>%2F2018%2F06%2F24%2Fnginx-apply%2F</url>
    <content type="text"><![CDATA[本文主要介绍nginx服务器的各种应用方式。 1.静态HTTP服务器Nginx是一个HTTP服务器，可以将服务器上的静态文件（如HTML、图片）通过HTTP协议展现给客户端。配置文件：123456server &#123; listen 80; # 端口号 location / &#123; root /usr/share/nginx/html; # 静态文件路径 &#125;&#125; 2.反向代理服务器反向代理服务器原理：客户端—&gt; nginx反向代理—&gt; 应用服务器配置文件：123456server &#123; listen 80; location / &#123; proxy_pass http://192.168.0.112:8080; # 应用服务器HTTP地址 &#125;&#125; 3.负载均衡负载均衡原理： |—- 应用服务器 |客户端—&gt; nginx反向代理—–|—- 应用服务器 | |—- 应用服务器 配置文件：12345678910upstream myapp &#123; server 192.168.0.111:8080; # 应用服务器1 server 192.168.0.112:8080; # 应用服务器2&#125;server &#123; listen 80; location / &#123; proxy_pass http://myweb; &#125;&#125; 4.虚拟主机将多个网站部署在同一台服务器上。配置文件：12345678910111213141516171819server &#123; listen 80 default_server; server_name _; return 444; # 过滤其他域名的请求，返回444状态码&#125;server &#123; listen 80; server_name www.aaa.com; # www.aaa.com域名 location / &#123; proxy_pass http://localhost:8080; # 对应端口号8080 &#125;&#125;server &#123; listen 80; server_name www.bbb.com; # www.bbb.com域名 location / &#123; proxy_pass http://localhost:8081; # 对应端口号8081 &#125;&#125; 5.FastCGINginx本身不支持PHP等语言，但是它可以通过FastCGI来将请求扔给某些语言或框架处理（例如PHP、Python、Perl）。配置文件：123456789server &#123; listen 80; location ~ \.php$ &#123; include fastcgi_params; fastcgi_param SCRIPT_FILENAME /PHP文件路径$fastcgi_script_name; # PHP文件路径 fastcgi_pass 127.0.0.1:9000; # PHP-FPM地址和端口号 # 另一种方式：fastcgi_pass unix:/var/run/php5-fpm.sock; &#125;&#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx系列教程01]]></title>
    <url>%2F2018%2F06%2F24%2Fnginx-basic%2F</url>
    <content type="text"><![CDATA[本文主要介绍Centos6.x系统安装nginx和nginx基本使用。 1.Nginx下载安装可以下载ngxin源码包来安装，也可以通过nginx官网的YUM源安装。 配置YUM源 1234567# vim /etc/yum.repos.d/nginx.repo[nginx]name=nginxbaseurl=http://nginx.org/packages/centos/6/x86_64/failovermethod=priorityenabled=1gpgcheck=0 安装nginx 1# yum -y install nginx 2.Nginx配置文件 查看nginx配置文件。 12345678910111213# rpm -qc nginx/etc/logrotate.d/nginx/etc/nginx/conf.d/default.conf/etc/nginx/fastcgi_params/etc/nginx/koi-utf/etc/nginx/koi-win/etc/nginx/mime.types/etc/nginx/nginx.conf/etc/nginx/scgi_params/etc/nginx/uwsgi_params/etc/nginx/win-utf/etc/sysconfig/nginx/etc/sysconfig/nginx-debug nginx主配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# vim /etc/nginx/nginx.conf#运行用户user nginx;#工作进程：数目。worker_processes 1;# 错误日志：存放路径。error_log /var/log/nginx/error.log warn;# pid（进程标识符）：存放路径。pid /var/run/nginx.pid;# 事件配置events &#123; #每个进程可以处理的最大连接数 worker_connections 1024;&#125;# http参数http &#123; # 文件扩展名与文件类型映射表 include /etc/nginx/mime.types; # 默认文件类型 default_type application/octet-stream; #日志相关定义 log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; #连接日志的路径，指定的日志格式放在最后 access_log /var/log/nginx/access.log main; #开启高效传输模式 sendfile on; #防止网络阻塞 #tcp_nopush on; #客户端连接超时时间，单位是秒 keepalive_timeout 65; #客户端请求头读取超时时间 client_header_timeout 10; #设置客户端请求主体读取超时时间 client_body_timeout 10; #响应客户端超时时间 send_timeout 10; #开启gzip压缩输出 #gzip on; # 子配置文件 include /etc/nginx/conf.d/*.conf;&#125; 子配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# vim /etc/nginx/conf.d/default.conf# 虚拟主机定义server &#123; # 监听端口 listen 80; # 访问域名 server_name localhost; # 编码格式，若网页格式与此不同，将被自动转码 #charset koi8-r; # 虚拟主机访问日志定义 #access_log /var/log/nginx/host.access.log main; # 对URL进行匹配 location / &#123; # 访问路径，可相对也可绝对路径 root /usr/share/nginx/html; # 首页文件。以下按顺序匹配 index index.html index.htm; &#125; # 错误信息返回页面 #error_page 404 /404.html; # redirect server error pages to the static page /50x.html error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /usr/share/nginx/html; &#125; # 访问URL以.php结尾则自动转交给127.0.0.1 # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # php脚本请求全部转发给FastCGI处理 # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # 禁止访问.ht页面 （需ngx_http_access_module模块） # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\.ht &#123; # deny all; #&#125; # HTTPS虚拟主机定义 # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 其他配置 ​ Nginx状态监控 123456789101112#Nginx运行状态，StubStatus模块获取Nginx自启动的工作状态（编译时要开启对应功能）#location /NginxStatus &#123;# #启用StubStatus的工作访问状态 # stub_status on;# #指定StubStaus模块的访问日志文件# access_log logs/Nginxstatus.log;# #Nginx认证机制（需Apache的htpasswd命令生成）# #auth_basic "NginxStatus";# #用来认证的密码文件# #auth_basic_user_file ../htpasswd; #&#125;访问：http://IP/NginxStatus(测试就不加密码验证相关) ​ 反向代理 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#以下配置追加在HTTP的全局变量中#nginx跟后端服务器连接超时时间(代理连接超时)proxy_connect_timeout 5;#后端服务器数据回传时间(代理发送超时)proxy_send_timeout 5;#连接成功后，后端服务器响应时间(代理接收超时)proxy_read_timeout 60;#设置代理服务器（nginx）保存用户头信息的缓冲区大小proxy_buffer_size 16k;#proxy_buffers缓冲区，网页平均在32k以下的话，这样设置proxy_buffers 4 32k;#高负荷下缓冲大小（proxy_buffers*2）proxy_busy_buffers_size 64k;#设定缓存文件夹大小，大于这个值，将从upstream服务器传proxy_temp_file_write_size 64k;#反向代理缓存目录proxy_cache_path /data/proxy/cache levels=1:2 keys_zone=cache_one:500m inactive=1d max_size=1g;#levels=1:2 设置目录深度，第一层目录是1个字符，第2层是2个字符#keys_zone:设置web缓存名称和内存缓存空间大小#inactive:自动清除缓存文件时间。#max_size:硬盘空间最大可使用值。#指定临时缓存文件的存储路径(路径需和上面路径在同一分区)proxy_temp_path /data/proxy/temp#服务配置server &#123; #侦听的80端口 listen 80; server_name localhost; location / &#123; #反向代理缓存设置命令(proxy_cache zone|off,默认关闭所以要设置) proxy_cache cache_one; #对不同的状态码缓存不同时间 proxy_cache_valid 200 304 12h; #设置以什么样参数获取缓存文件名 proxy_cache_key $host$uri$is_args$args; #后7端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #代理设置 proxy_pass http://IP; #文件过期时间控制 expires 1d; &#125; #配置手动清楚缓存(实现此功能需第三方模块 ngx_cache_purge) #http://www.123.com/2017/0316/17.html访问 #http://www.123.com/purge/2017/0316/17.html清楚URL缓存 location ~ /purge(/.*) &#123; allow 127.0.0.1; deny all; proxy_cache_purge cache_one $host$1$is_args$args; &#125; #设置扩展名以.jsp、.php、.jspx结尾的动态应用程序不做缓存 location ~.*\.(jsp|php|jspx)?$ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://http://IP; &#125; ​ 负载均衡 12345678910111213141516171819202122#负载均衡服务器池upstream my_server_pool &#123; #调度算法 #1.轮循（默认）（weight轮循权值） #2.ip_hash：根据每个请求访问IP的hash结果分配。（会话保持） #3.fair:根据后端服务器响应时间最短请求。（upstream_fair模块） #4.url_hash:根据访问的url的hash结果分配。（需hash软件包） #参数： #down：表示不参与负载均衡 #backup:备份服务器 #max_fails:允许最大请求错误次数 #fail_timeout:请求失败后暂停服务时间。 server 192.168.1.109:80 weight=1 max_fails=2 fail_timeout=30; server 192.168.1.108:80 weight=2 max_fails=2 fail_timeout=30;&#125;#负载均衡调用server &#123; ... location / &#123; proxy_pass http://my_server_pool; &#125;&#125; ​ URL重写 1234567891011#根据不同的浏览器URL重写 if($http_user_agent ~ Firefox)&#123; rewrite ^(.*)$ /firefox/$1 break; &#125; if($http_user_agent ~ MSIE)&#123; rewrite ^(.*)$ /msie/$1 break; &#125; #实现域名跳转 location / &#123; rewrite ^/(.*)$ https://web8.example.com$1 permanent; &#125; ​ IP限制 1234567#限制IP访问location / &#123; deny 192.168.0.2； allow 192.168.0.0/24; allow 192.168.1.1; deny all;&#125; 3. Nginx启停12# /etc/init.d/nginx start# /etc/init.d/nginx stop]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之Linux单机启动多个MySQL实例(mysqld_multi)]]></title>
    <url>%2F2018%2F06%2F23%2Fmysqld-multi%2F</url>
    <content type="text"><![CDATA[本文主要介绍Centos6.x安装MySQL5.7。 1.安装MySQL5.712# rpm -ivh https://repo.mysql.com//mysql57-community-release-el6-11.noarch.rpm# yum install mysql-community-client mysql-community-server 2.创建data目录1# mkdir /usr/local/mysql/data&#123;3306,3307,3308&#125; -p 3.修改权限1# chown -R mysql:mysql /usr/local/mysql 4.初始化实例的数据库123456789101112131415生成 3306 的数据目录# mysqld --no-defaults --initialize-insecure --basedir=/usr --datadir=/usr/local/mysql/data3306 --user=mysql --explicit_defaults_for_timestamp生成 3307 的数据目录# mysqld --no-defaults --initialize-insecure --basedir=/usr --datadir=/usr/local/mysql/data3307 --user=mysql --explicit_defaults_for_timestamp生成 3307 的数据目录# mysqld --no-defaults --initialize-insecure --basedir=/usr --datadir=/usr/local/mysql/data3308 --user=mysql --explicit_defaults_for_timestamp--no-defaults 不读取默认的 /etc/my.cnf 全局配置文件 否则可能存在一些冲突问题--initialize-insecure 初始化且不需要生成密码--basedir mysql 的安装目录--datadir 本实例的数据目录--user 这样生成的文件用户为 mysql--explicit_defaults_for_timestamp timestamp 已经 deprecated 了 5.修改/etc/my.cnf···bash[mysqld_multi]mysqld = /usr/bin/mysqld_safemysqladmin = /usr/bin/mysqladminuser=rootlog=/usr/local/mysql/mysql_multi.log [mysqld3306]basedir=/usrdatadir=/usr/local/mysql/data3306port=3306user=mysqlsocket=/tmp/mysql.sock3306server_id=1log_bin=mysql-bin [mysqld3307]basedir=/usrdatadir=/usr/local/mysql/data3307port=3307user=mysqlsocket=/tmp/mysql.sock3307server_id=2 [mysqld3308]basedir=/usrdatadir=/usr/local/mysql/data3308port=3308user=mysqlsocket=/tmp/mysql.sock3308server_id=3··· 6.启动多实例1234567891011121314# mysqld_multi start# /usr/local/mysql/bin/mysqld_multi start 3306# /usr/local/mysql/bin/mysqld_multi start 3307# /usr/local/mysql/bin/mysqld_multi start 3308# mysqld_multi reportReporting MySQL serversMySQL server from group: mysqld3306 is runningMySQL server from group: mysqld3307 is runningMySQL server from group: mysqld3308 is running# netstat -tln|grep 330*tcp 0 0 :::3307 :::* LISTEN tcp 0 0 :::3308 :::* LISTEN tcp 0 0 :::3306 :::* LISTEN 7.初始化密码123# mysqladmin -u root password '123456' -S /tmp/mysql.sock3306# mysqladmin -u root password '123456' -S /tmp/mysql.sock3307# mysqladmin -u root password '123456' -S /tmp/mysql.sock3308 8.登录123# mysql -uroot -p123456 -S /tmp/mysql.sock3306# mysql -uroot -p123456 -S /tmp/mysql.sock3307# mysql -uroot -p123456 -S /tmp/mysql.sock3308]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos6.x通过YUM安装MySQL5.7]]></title>
    <url>%2F2018%2F06%2F23%2Fmysql5.7-install%2F</url>
    <content type="text"><![CDATA[本文主要介绍Centos6.x安装MySQL5.7。 1.下载repo仓库文件1# wget https://repo.mysql.com//mysql57-community-release-el6-11.noarch.rpm 2.安装到本地yum源1# yum localinstall mysql57-community-release-el6-11.noarch.rpm 3.安装MySQL1# yum install mysql-server mysql 4.启动mysql-server1# /etc/init.d/mysqld start 5.登录MySQL12# cat /var/log/mysqld.log | grep "password" 查找密码# mysql -uroot -p 登录 6.修改密码123456mysql&gt; ALTER USER USER() IDENTIFIED BY '12345678'; 密码太简单通过不了ERROR 1819 (HY000): Your password does not satisfy the current policy requirementsmysql&gt; set global validate_password_policy=0;mysql&gt; select @@validate_password_length;mysql&gt; set global validate_password_length=1;mysql&gt; ALTER USER USER() IDENTIFIED BY '12345678'; 再次就可以修改了]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python标准库04]]></title>
    <url>%2F2018%2F06%2F22%2Fpython-stdmod04%2F</url>
    <content type="text"><![CDATA[本文主要介绍Python标准库。 1.subprocess模块12345678910111213141516171819202122232425262728&gt;&gt;&gt; import subprocess&gt;&gt;&gt; retcode = subprocess.call(["ls", "-l"])#和shell中命令ls -a显示结果一样&gt;&gt;&gt; print retcode&gt;&gt;&gt; retcode = subprocess.call("ls -l",shell=True)&gt;&gt;&gt; child = subprocess.Popen(['ping','-c','4','blog.linuxeye.com'])&gt;&gt;&gt; print 'parent process'------------------------------华丽的分割线-----------------------------&gt;&gt;&gt; import subprocess&gt;&gt;&gt; child = subprocess.Popen('ping -c4 blog.linuxeye.com',shell=True)&gt;&gt;&gt; child.wait()&gt;&gt;&gt; print 'parent process'------------------------------华丽的分割线-----------------------------&gt;&gt;&gt; import subprocess&gt;&gt;&gt; child1 = subprocess.Popen(["ls","-l"], stdout=subprocess.PIPE)&gt;&gt;&gt; print child1.stdout.read(),#或者child1.communicate()------------------------------华丽的分割线-----------------------------&gt;&gt;&gt; import subprocess&gt;&gt;&gt; child1 = subprocess.Popen(["cat","/etc/passwd"], stdout=subprocess.PIPE)&gt;&gt;&gt; child2 = subprocess.Popen(["grep","0:0"],stdin=child1.stdout, stdout=subprocess.PIPE)&gt;&gt;&gt; out = child2.communicate() 2.pyinotify模块12345678910111213141516171819202122232425262728293031323334#!/usr/bin/python# coding:utf-8 import osfrom pyinotify import WatchManager, Notifier,ProcessEvent,IN_DELETE, IN_CREATE,IN_MODIFY class EventHandler(ProcessEvent): """事件处理""" def process_IN_CREATE(self, event): print "Create file: %s " % os.path.join(event.path,event.name) def process_IN_DELETE(self, event): print "Delete file: %s " % os.path.join(event.path,event.name) def process_IN_MODIFY(self, event): print "Modify file: %s " % os.path.join(event.path,event.name) def FSMonitor(path='.'): wm = WatchManager() mask = IN_DELETE | IN_CREATE |IN_MODIFY notifier = Notifier(wm, EventHandler()) wm.add_watch(path, mask,auto_add=True,rec=True) print 'now starting monitor %s'%(path) while True: try: notifier.process_events() if notifier.check_events(): notifier.read_events() except KeyboardInterrupt: notifier.stop() break if __name__ == "__main__": FSMonitor('/root/softpython/apk_url') 3.pwd和grp模块pwd模块：pwd.getpwuid(uid):返回对应uid的用户信息pwd.getpwnam(name):返回对应name的用户信息pwd.getpwall():返回所有用户信息grp.getgrgid(gid):返回对应gid的组信息grp.getgrname(name):返回对应group name的组信息grp.getgrall():返回所有组信息123456789101112131415import pwd def get_user(): all_user = &#123;&#125; for user in pwd.getpwall(): all_user[user[0]] = all_user[user[2]] = user return all_user def userinfo(uid): return get_user()[uid] print userinfo(0)pwd.struct_passwd(pw_name='root', pw_passwd='x', pw_uid=0, pw_gid=0, pw_gecos='root', pw_dir='/root', pw_shell='/bin/bash')print userinfo('root')pwd.struct_passwd(pw_name='root', pw_passwd='x', pw_uid=0, pw_gid=0, pw_gecos='root', pw_dir='/root', pw_shell='/bin/bash') 4.pickle模块 使用pickle模块将数据对象保存到文件 12345678910111213141516171819202122#!/usr/bin/env python# coding:utf-8import pickledata1 = &#123;'a': [1, 2.0, 3, 4+6j], 'b': ('string', u'Unicode string'), 'c': None&#125;selfref_list = [1, 2, 3]selfref_list.append(selfref_list)output = open('data.pkl', 'wb')#pickle.dump(obj, file, [,protocol])#注解：将对象obj保存到文件file中去。#protocol为序列化使用的协议版本#0：ASCII协议#1：老式的二进制协议#2：2.3版本引入的新二进制协议，较以前的更高效。pickle.dump(data1, output)pickle.dump(selfref_list, output, 2)output.close() 使用pickle模块从文件中重构python对象 1234567891011#!/usr/bin/env python# coding:utf-8import pprint, picklepkl_file = open('data.pkl', 'rb')data1 = pickle.load(pkl_file)pprint.pprint(data1)data2 = pickle.load(pkl_file)pprint.pprint(data2)pkl_file.close() 5.yaml模块 写入yaml文件： 123456789#!/usr/bin/env python# coding:utf-8import yamlyaml_file = open('test.yaml','w')data = &#123;'user_info':&#123;'name':A, 'age':17&#125;&#125;yaml.dump(data,yaml_file)#yaml_file.truncate //清空yaml文件yaml_file.close() 读取yaml文件： 1234567#!/usr/bin/env python# coding:utf-8import yamlyaml_file = open('test.yaml','r')yaml.load(yaml_file)yaml_file.close() 6.optparser模块12345678910111213141516#!/usr/bin/env python# coding:utf-8from optparse import OptionParserusage = "myprog[ -f &lt;filename&gt;][-s &lt;xyz&gt;] arg1[,arg2..]"optParser = OptionParser(usage)optParser.add_option("-f","--file",action = "store",type="string",dest = "fileName")ooptParser.add_option("-v","--vison", action="store_false", dest="verbose",default='None', help="make lots of noise [default]")fakeArgs = ['-f','file.txt','-v','good luck to you', 'arg2', 'arge'] options, args = optParser.parse_args(fakeArgs)print options.fileNameprint options.verboseprint optionsprint argsprint optParser.print_help()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python标准库03]]></title>
    <url>%2F2018%2F06%2F22%2Fpython-stdmod03%2F</url>
    <content type="text"><![CDATA[本文主要介绍Python标准库。 1.shelve模块写：1234567891011#!/usr/bin/env pythonimport shelvezhangsan = dict(zip(['name','age'],['zhangsan',24]))lisi = dict(zip(['name','age'],['lisi',25]))db = shelve.open('shelveDict')db['zhangsan'] = zhangsandb['lisi'] = lisidb.close() 读：12345678910111213141516171819#!/usr/bin/env pythonimport shelvedb = shelve.open('shelveDict')print db['zhangsan']print db['lisi']db.close()修改：#!/usr/bin/env pythonimport shelvedb = shelve.open('shelveDict')zhangsan = db['zhangsan']zhangsan['name'] = 'zhangsanfeng'db['zhangsan'] = zhangsanprint db['zhangsan']db.close() 2.httplib模块GET请求:123456789101112131415161718import httplibclass HttpRequestGETTest(object): def __init__(self): #self.body='&#123;"UserName":"Admin","Password":"693aa8d0806c532115637809a863b1a3","sessionID":""&#125;' self.headers = &#123; "Referer": '192.168.1.1', "Accept-Encoding": "gzip, deflate,sdch", "Connection":"Keep-Alive"&#125; def http_get(self): conn=httplib.HTTPConnection(host='192.168.1.1', port=80, strict=False, timeout=30) conn.request(method='GET',url='/cgi-bin/GetLoginStatus?sessionID=undefined', body=None, headers=self.headers) a = conn.getresponse().read() print alianxi=HttpRequestGETTest()lianxi.http_get() POST请求:123456789101112131415161718import httplibclass HttpRequestPOSTTest(object): def __init__(self): self.body='&#123;"UserName":"Admin","Password":"693aa8d0806c532115637809a863b1a3","sessionID":""&#125;' self.headers = &#123; "Referer": '192.168.1.1', "Accept-Encoding": "gzip, deflate,sdch", "Connection":"Keep-Alive"&#125; def http_post(self): conn=httplib.HTTPConnection(host='192.168.1.1', port=80, strict=False, timeout=120) conn.request(method='POST',url='/cgi-bin/Login', body=self.body, headers=self.headers) self.session_id = conn.getresponse().read() print self.session_idlianxi=HttpRequestPOSTTest()lianxi.http_post() 3.ftplib模块123456789101112131415161718192021222324252627282930313233343536#coding: utf-8from ftplib import FTPimport timeimport tarfile#!/usr/bin/python#-*- coding: utf-8 -*-from ftplib import FTPdef ftpconnect(host, username, password): ftp = FTP() #ftp.set_debuglevel(2) #打开调试级别2，显示详细信息 ftp.connect(host, 21) #连接 ftp.login(username, password) #登录，如果匿名登录则用空串代替即可 return ftp def downloadfile(ftp, remotepath, localpath): bufsize = 1024 #设置缓冲块大小 fp = open(localpath,'wb') #以写模式在本地打开文件 ftp.retrbinary('RETR ' + remotepath, fp.write, bufsize) #接收服务器上文件并写入本地文件 ftp.set_debuglevel(0) #关闭调试 fp.close() #关闭文件def uploadfile(ftp, remotepath, localpath): bufsize = 1024 fp = open(localpath, 'rb') ftp.storbinary('STOR '+ remotepath , fp, bufsize) #上传文件 ftp.set_debuglevel(0) fp.close() if __name__ == "__main__": ftp = ftpconnect("******", "***", "***") downloadfile(ftp, "***", "***") uploadfile(ftp, "***", "***") ftp.quit() 4.urllib模块1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&gt;&gt;&gt; import urllib&gt;&gt;&gt; f = urllib.urlopen('http://www.qq.com')&gt;&gt;&gt; f.getcode()200&gt;&gt;&gt; f.geturl()'http://www.qq.com'&gt;&gt;&gt; f.headers------------------------------华丽的分割线-----------------------------&gt;&gt;&gt; filename = urllib.urlretrieve('http://www.google.com.hk/')&gt;&gt;&gt; type(filename)&lt;type 'tuple'&gt;&gt;&gt;&gt; filename[0]'/tmp/tmp8eVLjq'&gt;&gt;&gt; filename[1]&lt;httplib.HTTPMessage instance at 0xb6a363ec&gt;&gt;&gt;&gt; urllib.urlcleanup()------------------------------华丽的分割线-----------------------------&gt;&gt;&gt;filename=urllib.urlretrieve('http://www.qq.com',filename='./google.html')&gt;&gt;&gt; type(filename)&lt;type 'tuple'&gt;&gt;&gt;&gt; filename[0]'/home/dzhwen/python\xe6\x96\x87\xe4\xbb\xb6/Homework/urllib/google.html'&gt;&gt;&gt; filename[1]&lt;httplib.HTTPMessage instance at 0xb6e2c38c&gt;------------------------------华丽的分割线-----------------------------&gt;&gt;&gt; urllib.quote('http://www.baidu.com')'http%3A//www.baidu.com'&gt;&gt;&gt; urllib.quote_plus('http://www.baidu.com')'http%3A%2F%2Fwww.baidu.com'------------------------------华丽的分割线-----------------------------GET方法：&gt;&gt;&gt; import urllib&gt;&gt;&gt; params=urllib.urlencode(&#123;'spam':1,'eggs':2,'bacon':0&#125;)&gt;&gt;&gt; params'eggs=2&amp;bacon=0&amp;spam=1'&gt;&gt;&gt; f=urllib.urlopen("http://python.org/query?%s" % params)&gt;&gt;&gt; print f.read()POST方法：&gt;&gt;&gt; import urllib&gt;&gt;&gt; parmas = urllib.urlencode(&#123;'spam':1,'eggs':2,'bacon':0&#125;)&gt;&gt;&gt; f=urllib.urlopen("http://python.org/query",parmas)&gt;&gt;&gt; f.read() 5.hashlib模块12345678#!/usr/bin/env python# coding:utf-8import hashlibrb = open('/root/test.txt','rb')rb_md5 = hashlib.md5()rb_md5.update(rb.read())rb_md5.hexdigest() 6.tarfile模块 使用tarfile压缩 12345678910111213#!/usr/bin/env python# coding:utf-8import tarfile #创建压缩包名tar = tarfile.open("/tmp/tartest.tar.gz","w:gz")#创建压缩包for root,dir,files in os.walk("/tmp/tartest"): for file in files: fullpath = os.path.join(root,file) tar.add(fullpath)tar.close() 使用tarfile解压 1234567#!/usr/bin/env python# coding:utf-8 import tarfile tar = tarfile.open("sample.tar.gz") tar.extractall() tar.close()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python标准库02]]></title>
    <url>%2F2018%2F06%2F22%2Fpython-stdmod02%2F</url>
    <content type="text"><![CDATA[本文主要介绍Python标准库。 1.re模块re模块中常用功能函数①compile()编译正则表达式模式，返回一个对象的模式。（可以把那些常用的正则表达式编译成正则表达式对象，这样可以提高一点效率。）格式：re.compile(pattern,flags=0)pattern: 编译时用的表达式字符串。flags 编译标志位，用于修改正则表达式的匹配方式，如：是否区分大小写，多行匹配等。常用的flags有：|标志|含义||:-|:-||re.S(DOTALL)|使.匹配包括换行在内的所有字符|re.I(IGNORECASE)|使匹配对大小写不敏感|re.L(LOCALE)|做本地化识别（locale-aware)匹配，法语等|re.M(MULTILINE)|多行匹配，影响^和$|re.X(VERBOSE)|该标志通过给予更灵活的格式以便将正则表达式写得更易于理解|re.U|根据Unicode字符集解析字符，这个标志影响\w,\W,\b,\B 123456import rett = "Tina is a good girl, she is cool, clever, and so on..."rr = re.compile(r'\w*oo\w*')print(rr.findall(tt)) #查找所有包含'oo'的单词执行结果如下：['good', 'cool'] ② match()决定RE是否在字符串刚开始的位置匹配。//注：这个方法并不是完全匹配。当pattern结束时若string还有剩余字符，仍然视为成功。想要完全匹配，可以在表达式末尾加上边界匹配符’$’格式：re.match(pattern, string, flags=0)print(re.match(‘com’,’comwww.runcomoob&#39;).group())print(re.match(‘com’,’Comwww.runcomoob&#39;,re.I).group())执行结果如下：comcom ③ search()格式：re.search(pattern, string, flags=0)re.search函数会在字符串内查找模式匹配,只要找到第一个匹配然后返回，如果字符串没有匹配，则返回None。 print(re.search(‘\dcom’,’www.4comrunoob.5com&#39;).group()) 执行结果如下： 4com注：match和search一旦匹配成功，就是一个match object对象，而match object对象有以下方法：group() 返回被 RE 匹配的字符串start() 返回匹配开始的位置end() 返回匹配结束的位置span() 返回一个元组包含匹配 (开始,结束) 的位置group() 返回re整体匹配的字符串，可以一次输入多个组号，对应组号匹配的字符串。group()返回re整体匹配的字符串， b. group (n,m) 返回组号为n，m所匹配的字符串，如果组号不存在，则返回indexError异常 c.groups() groups()方法返回一个包含正则表达式中所有小组字符串的元组，从 1 到所含的小组号，通常groups()不需要参数，返回一个元组，元组中的元就是正则表达式中定义的组。import rea = “123abc456” print(re.search(“([0-9])([a-z])([0-9])”,a).group(0)) #123abc456,返回整体 print(re.search(“([0-9])([a-z])([0-9])”,a).group(1)) #123 print(re.search(“([0-9])([a-z])([0-9])”,a).group(2)) #abc print(re.search(“([0-9])([a-z])([0-9]*)”,a).group(3)) #456 ###group(1) 列出第一个括号匹配部分，group(2) 列出第二个括号匹配部分，group(3) 列出第三个括号匹配部分。###④ findall()re.findall遍历匹配，可以获取字符串中所有匹配的字符串，返回一个列表。格式：re.findall(pattern, string, flags=0)p = re.compile(r’\d+’)print(p.findall(‘o1n2m3k4’))执行结果如下：[‘1’, ‘2’, ‘3’, ‘4’]import rett = “Tina is a good girl, she is cool, clever, and so on…”rr = re.compile(r’\woo\w‘)print(rr.findall(tt))print(re.findall(r’(\w)*oo(\w)’,tt))#()表示子表达式执行结果如下：[‘good’, ‘cool’][(‘g’, ‘d’), (‘c’, ‘l’)]⑤ finditer()搜索string，返回一个顺序访问每一个匹配结果（Match对象）的迭代器。找到 RE 匹配的所有子串，并把它们作为一个迭代器返回。格式：re.finditer(pattern, string, flags=0)iter = re.finditer(r’\d+’,’12 drumm44ers drumming, 11 … 10 …’)for i in iter: print(i) print(i.group()) print(i.span())执行结果如下： &lt;_sre.SRE_Match object; span=(0, 2), match=’12’&gt;(0, 2) &lt;_sre.SRE_Match object; span=(8, 10), match=’44’&gt;(8, 10) &lt;_sre.SRE_Match object; span=(24, 26), match=’11’&gt;(24, 26) &lt;_sre.SRE_Match object; span=(31, 33), match=’10’&gt;(31, 33)⑥ split()按照能够匹配的子串将string分割后返回列表。可以使用re.split来分割字符串，如：re.split(r’\s+’, text)；将字符串按空格分割成一个单词列表。格式：re.split(pattern, string[, maxsplit])maxsplit用于指定最大分割次数，不指定将全部分割。 print(re.split(‘\d+’,’one1two2three3four4five5’))执行结果如下：[‘one’, ‘two’, ‘three’, ‘four’, ‘five’, ‘’]⑦ sub()使用re替换string中每一个匹配的子串后返回替换后的字符串。格式：re.sub(pattern, repl, string, count)import retext = “JGood is a handsome boy, he is cool, clever, and so on…”print(re.sub(r’\s+’, ‘-‘, text))执行结果如下：JGood-is-a-handsome-boy,-he-is-cool,-clever,-and-so-on…其中第二个函数是替换后的字符串；本例中为’-‘第四个参数指替换个数。默认为0，表示每个匹配项都替换。re.sub还允许使用函数对匹配项的替换进行复杂的处理。如：re.sub(r’\s’, lambda m: ‘[‘ + m.group(0) + ‘]’, text, 0)；将字符串中的空格’ ‘替换为’[ ]’。import retext = “JGood is a handsome boy, he is cool, clever, and so on…”print(re.sub(r’\s+’, lambda m:’[‘+m.group(0)+’]’, text,0))执行结果如下：JGood[ ]is[ ]a[ ]handsome[ ]boy,[ ]he[ ]is[ ]cool,[ ]clever,[ ]and[ ]so[ ]on…⑧ subn()返回替换次数格式：subn(pattern, repl, string, count=0, flags=0)print(re.subn(‘[1-2]’,’A’,’123456abcdef’))print(re.sub(“g.t”,”have”,’I get A, I got B ,I gut C’))print(re.subn(“g.t”,”have”,’I get A, I got B ,I gut C’))执行结果如下：(‘AA3456abcdef’, 2)I have A, I have B ,I have C(‘I have A, I have B ,I have C’, 3) 2.time模块在Python中，通常有这几种方式来表示时间：1）时间戳 2）格式化的时间字符串 3）元组（struct_time）共九个元素。12345&gt;&gt;&gt; time.time() //返回unix时间戳&gt;&gt;&gt; time.localtime() //用一个元组装起来的9组数字处理时间&gt;&gt;&gt; time.sleep(5) //延时函数&gt;&gt;&gt; time.asctime( time.localtime() ) //获取可读的时间模式&gt;&gt;&gt; print time.strftime("%Y-%m-%d %H:%M:%S",time.localtime()) 3.random模块1234567891011121314151617&gt;&gt;&gt; import random //生成一个0到1的随机符点数: 0 &lt;= n &lt; 1.0&gt;&gt;&gt; random.random()&gt;&gt;&gt; random.uniform(10,20) //生成的随机数n: a &lt;= n &lt;= b&gt;&gt;&gt; random.randint(1,20) //生成的随机数n: a &lt;= n &lt;= b&gt;&gt;&gt; random.randrange(1,10,2)&gt;&gt;&gt; random.choice(["JGood","is", "a","handsome", "boy"])&gt;&gt;&gt; p = ["Python","is", "powerful","simple", "and so on..."]&gt;&gt;&gt; random.shuffle(p) //打乱&gt;&gt;&gt; print p['simple', 'and so on...', 'is', 'powerful', 'Python']&gt;&gt;&gt; list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]&gt;&gt;&gt; slice = random.sample(list, 5) &gt;&gt;&gt; print slice[1, 6, 7, 4, 3]&gt;&gt;&gt; print list[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 4.csv模块读csv文件：语法：reader(csvfile, dialect=’excel’, **fmtparams) import csvreader=csv.reader(open(‘foo.csv’,’rb’))for item in reader:… print item写csv文件：import csvwriter=csv.writer(open(‘foo.csv’,’wb+’))writer.writerow([‘tianqi’,’26’,’79’])字典方式读写： 读 import csvwith open(‘names.csv’) as csvfile:… reader = csv.DictReader(csvfile)… for row in reader:… print(row[‘first_name’], row[‘last_name’])…Baked BeansLovely SpamWonderful Spam 写import csvwith open(‘names.csv’, ‘w’) as csvfile: fieldnames = [‘first_name’, ‘last_name’] writer = csv.DictWriter(csvfile, fieldnames=fieldnames) writer.writeheader() writer.writerow({&apos;first_name&apos;: &apos;Baked&apos;, &apos;last_name&apos;: &apos;Beans&apos;}) writer.writerow({&apos;first_name&apos;: &apos;Lovely&apos;, &apos;last_name&apos;: &apos;Spam&apos;}) writer.writerow({&apos;first_name&apos;: &apos;Wonderful&apos;, &apos;last_name&apos;: &apos;Spam&apos;})]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python标准库01]]></title>
    <url>%2F2018%2F06%2F22%2Fpython-stdmod01%2F</url>
    <content type="text"><![CDATA[本文主要介绍Python标准库。 1.os模块 操作文件以下内容在shell终端操作123456# touch 1.txt //创建文件# ls1.txt# echo "os module" &gt; 1.txt //写入内容# cat 1.txt os module 以下是python终端中操作12345678# python //进入python命令行&gt;&gt;&gt; import os //导入os模块&gt;&gt;&gt; dir(os) //获得os模块的帮助&gt;&gt;&gt; os.rename('1.txt','2.txt') //将1.txt重命名为2.txt&gt;&gt;&gt; os.remove('2.txt') //删除2.txt文件&gt;&gt;&gt; os.mknod('test.txt') //创建一个空文件&gt;&gt;&gt; os.stat('test.txt') //获取文件属性&gt;&gt;&gt; os.chmod('test.txt',0666) //修改文件权限 操作目录 1234567891011121314151617181920212223242526272829&gt;&gt;&gt; os.getcwd() //获取当前目录'/python'&gt;&gt;&gt; os.listdir('/python') //列出文件和目录['test.txt']&gt;&gt;&gt; os.mkdir('foo') //创建目录&gt;&gt;&gt; os.listdir('.')['test.txt', 'foo']&gt;&gt;&gt; os.rmdir('foo') //删除目录&gt;&gt;&gt; os.mkdir('foo') //重新创建目录&gt;&gt;&gt; os.chdir('foo') //进入foo目录&gt;&gt;&gt; os.getcwd() //获取当前目录'/python/foo'&gt;&gt;&gt; os.makedirs('a/b/c') //创建多级目录&gt;&gt;&gt; os.removedirs('a/b/c') //删除多级目录&gt;&gt;&gt; os.getcwd() //当前目录'/python'&gt;&gt;&gt; os.listdir('.') //当前目录文件列表['test.txt', 'foo']&gt;&gt;&gt; os.chdir('foo') //进入foo目录&gt;&gt;&gt; os.mknod('1.txt') //创建文件，此时foo目录不为空&gt;&gt;&gt; os.chdir('..') //返回上一级目录&gt;&gt;&gt; os.getcwd()'/python'&gt;&gt;&gt; os.rmdir('foo') //使用rmdir删除会报错，怎么删除？&gt;&gt;&gt; import shutil&gt;&gt;&gt; shutil.rmtree('foo') //删除非空目录 系统相关 12345678910111213&gt;&gt;&gt; os.sep //操作系统特定的路径分隔符'/'&gt;&gt;&gt; os.name //正在使用的工作平台，Windows是'nt'，Linux/Unix是'posix'。'posix'&gt;&gt;&gt; os.getenv('PATH') //读取和设置环境变量:os.getenv() 与os.putenv()'/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin'&gt;&gt;&gt; os.linesep //当前平台使用的行终止符'\n'&gt;&gt;&gt; os.system('ls -l') //调用系统命令&gt;&gt;&gt; os.pathsep':'&gt;&gt;&gt; os.extsep'.' os.path模块 12345678910111213141516171819202122232425262728# ls -ldrwxr-xr-x 2 root root 4096 Oct 23 16:30 foo-rw-rw-rw- 1 root root 0 Oct 23 13:15 test.txt//当前目录下一个目录和一个文件# python //进入python终端&gt;&gt;&gt; import os&gt;&gt;&gt; os.path.isfile('test.txt') //判断是不是文件True&gt;&gt;&gt; os.path.isdir('foo') //判断是不是目录True&gt;&gt;&gt; os.path.isdir('test.txt')False&gt;&gt;&gt; os.path.split('/python/foo') //返回路径的目录和文件名('/python', 'foo')&gt;&gt;&gt; os.path.split('/python/foo/')('/python/foo', '')&gt;&gt;&gt; os.path.getsize('test.txt') //返回文件大小，如果为目录，返回01551&gt;&gt;&gt; os.path.abspath('.') //获得绝对路径'/python'&gt;&gt;&gt; os.path.join('/python','test.txt') //连接目录和文件名'/python/test.txt'&gt;&gt;&gt; os.path.basename('/usr/bin/env') //返回文件名'env'&gt;&gt;&gt; os.path.dirname('/usr/bin/env') //返回文件路径'/usr/bin'&gt;&gt;&gt; os.path.splitext('test.txt') //分离文件名和扩展名('test', '.txt') 2.shutil模块1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&gt;&gt;&gt; shutil.copyfile('/root/nginx.conf','./nginx.conf') //复制文件&gt;&gt;&gt; shutil.copy('/root/nginx.conf','./test.txt') //复制数据&gt;&gt;&gt; shutil.copytree('/opt/bar','/python/bar') //递归复制文件夹&gt;&gt;&gt; shutil.move('/python/bar','/root/') //移动目录&gt;&gt;&gt; shutil.rmtree('/root/bar') //删除目录# ls -ldrwxr-xr-x 2 root root 4096 Oct 23 16:30 foo-rw-rw-rw- 1 root root 1258 Oct 23 16:51 nginx.conf-rw-r--r-- 1 root root 1258 Oct 23 16:52 test.txt&gt;&gt;&gt; import shutil&gt;&gt;&gt; shutil.copymode('nginx.conf','test.txt') //复制权限# ls -ldrwxr-xr-x 2 root root 4096 Oct 23 16:30 foo-rw-rw-rw- 1 root root 1258 Oct 23 16:51 nginx.conf-rw-rw-rw- 1 root root 1258 Oct 23 16:52 test.txt&gt;&gt;&gt; shutil.copystat('nginx.conf','test.txt') //复制属性&gt;&gt;&gt; shutil.copy2('nginx.conf','test.txt') //先copyfile后copystatmake_archive(base_name, format, root_dir=None, base_dir=None, verbose=0,dry_run=0, owner=None, group=None, logger=None) #压缩打包base_name： 压缩打包后的文件名或者路径名format： 压缩或者打包格式 "zip", "tar", "bztar"or "gztar"root_dir : 将哪个目录或者文件打包（也就是源文件）&gt;&gt;&gt; shutil.make_archive('python','gztar',root_dir='/python/') '/python/python.tar.gz'shutil 对压缩包的处理是调用 ZipFile 和 TarFile 两个模块来进行的，详细：import zipfile# 压缩z = zipfile.ZipFile('laxi.zip', 'w')z.write('a.log')z.write('data.data')z.close()# 解压z = zipfile.ZipFile('laxi.zip', 'r')z.extractall()z.close()import tarfile# 压缩tar = tarfile.open('your.tar','w')tar.add('/Users/wupeiqi/PycharmProjects/bbs2.log', arcname='bbs2.log')tar.add('/Users/wupeiqi/PycharmProjects/cmdb.log', arcname='cmdb.log')tar.close()# 解压tar = tarfile.open('your.tar','r')tar.extractall() # 可设置解压地址tar.close() 3.sys模块sys.argv功能：在外部向程序内部传递参数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# cat argv.py #!/usr/bin/env pythonimport sysprint sys.argv[0]print sys.argv[1]# python argv.py aa argv.pyaa# cat argv.py#!/usr/bin/env python#coding:utf-8import sysif len(sys.argv)&gt;1: print "传递了",len(sys.argv)-1,"个参数"for arg in sys.argv[1:]: print argelse: print "没有传参"# python argv.py 没有传参# python argv.py 11 22 33 aa bb cc传递了 6 个参数112233aabbccsys.exit(n)功能：解释器自动退出&gt;&gt;&gt; import sys&gt;&gt;&gt; sys.exit(0)&gt;&gt;&gt; sys.getdefaultencoding() //获取系统当前编码'ascii'&gt;&gt;&gt; sys.getfilesystemencoding() //获取文件系统使用编码方式'UTF-8'&gt;&gt;&gt; sys.path //获取指定模块搜索路径的集合&gt;&gt;&gt; sys.platform //获取当前系统平台'linux2'sys.stdin,sys.stdout,sys.stderr //标准I/O 4.platform模块12345678&gt;&gt;&gt; import platform&gt;&gt;&gt; platform.platform() //获取操作系统名称及版本号&gt;&gt;&gt; platform.version() //获取操作系统版本号&gt;&gt;&gt; platform.architecture() //获取操作系统的位数&gt;&gt;&gt; platform.machine() //计算机类型&gt;&gt;&gt; platform.node() //计算机的网络名称&gt;&gt;&gt; platform.processor() //计算机处理器信息&gt;&gt;&gt; platform.uname() //包含上面所有的信息汇总]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python自动化运维03]]></title>
    <url>%2F2018%2F06%2F22%2Fpython-devops03%2F</url>
    <content type="text"><![CDATA[本文主要介绍Python自动化运维的常用模块，比如：paramiko、Fabric等。 1. paramiko模块 基于用户名和密码的 sshclient 方式登录 123456789101112131415161718#!/usr/bin/env python# coding:utf-8import paramikohost='123.20.62.15'port=22username='root'password='your pass'if __name__ == '__main__': paramiko.util.log_to_file('paramiko.log') ssh=paramiko.SSHClient() ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) ssh.connect(host,port,username,password) stdin,stdout,stderr=ssh.exec_command('ifconfig') print stdout.read() ssh.close() 基于用户名和密码的 transport 方式登录示例1： 12345678910111213141516171819#!/usr/bin/env python# coding:utf-8import paramikohost='123.20.62.15'port=22username='root'password='your pass'if __name__ == '__main__': trans=paramiko.Transport(host,port) trans.connect(username=username,password=password) ssh=paramiko.SSHClient() ssh._transport=trans stdin, stdout, stderr = ssh.exec_command('df -hl') print(stdout.read().decode()) trans.close() 示例2：123456789101112131415161718192021222324#!/usr/bin/env python# coding:utf-8import paramikoimport oshost='123.20.62.15'port=22username='root'password='your pass'dir_path='/root/'if __name__ == '__main__': trans=paramiko.Transport(host,port) trans.connect(username=username,password=password) sftp=paramiko.SFTPClient.from_transport(trans) files=sftp.listdir(dir_path) for f in files: print f sftp.get(os.path.join(dir_path,f),f) trans.close() 基于公钥密钥的 SSHClient 方式登录 1234567891011121314151617181920#!/usr/bin/env python# coding:utf-8import paramiko# 指定本地的RSA私钥文件,如果建立密钥对时设置的有密码，password为设定的密码，如无不用指定password参数pkey = paramiko.RSAKey.from_private_key_file('/home/super/.ssh/id_rsa', password='12345')# 建立连接ssh = paramiko.SSHClient()ssh.connect(hostname='192.168.2.129', port=22, username='super', pkey=pkey)# 执行命令stdin, stdout, stderr = ssh.exec_command('df -hl')# 结果放到stdout中，如果有错误将放到stderr中print(stdout.read().decode())# 关闭连接ssh.close() 基于密钥的 Transport 方式登录 12345678910111213141516171819202122232425262728293031323334353637383940#!/usr/bin/env python# coding:utf-8import paramiko# 指定本地的RSA私钥文件,如果建立密钥对时设置的有密码，password为设定的密码，如无不用指定password参数pkey = paramiko.RSAKey.from_private_key_file('/home/super/.ssh/id_rsa', password='12345')# 建立连接trans = paramiko.Transport(('192.168.2.129', 22))trans.connect(username='super', pkey=pkey)# 将sshclient的对象的transport指定为以上的transssh = paramiko.SSHClient()ssh._transport = trans# 执行命令，和传统方法一样stdin, stdout, stderr = ssh.exec_command('df -hl')print(stdout.read().decode())# 关闭连接trans.close()#################### 传文件 SFTP ###################!/usr/bin/env python# coding:utf-8import paramiko# 实例化一个trans对象# 实例化一个transport对象trans = paramiko.Transport(('192.168.2.129', 22))# 建立连接trans.connect(username='super', password='super')# 实例化一个 sftp对象,指定连接的通道sftp = paramiko.SFTPClient.from_transport(trans)# 发送文件sftp.put(localpath='/tmp/11.txt', remotepath='/tmp/22.txt')# 下载文件# sftp.get(remotepath, localpath)trans.close() 实现输入命令立马返回结果的功能 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#!/usr/bin/env python# coding:utf-8import paramikoimport osimport selectimport sys# 建立一个sockettrans = paramiko.Transport(('192.168.2.129', 22))# 启动一个客户端trans.start_client()# 如果使用rsa密钥登录的话'''default_key_file = os.path.join(os.environ['HOME'], '.ssh', 'id_rsa')prikey = paramiko.RSAKey.from_private_key_file(default_key_file)trans.auth_publickey(username='super', key=prikey)'''# 如果使用用户名和密码登录trans.auth_password(username='super', password='super')# 打开一个通道channel = trans.open_session()# 获取终端channel.get_pty()# 激活终端，这样就可以登录到终端了，就和我们用类似于xshell登录系统一样channel.invoke_shell()# 下面就可以执行你所有的操作，用select实现# 对输入终端sys.stdin和 通道进行监控,# 当用户在终端输入命令后，将命令交给channel通道，这个时候sys.stdin就发生变化，select就可以感知# channel的发送命令、获取结果过程其实就是一个socket的发送和接受信息的过程while True: readlist, writelist, errlist = select.select([channel, sys.stdin,], [], []) # 如果是用户输入命令了,sys.stdin发生变化 if sys.stdin in readlist: # 获取输入的内容 input_cmd = sys.stdin.read(1) # 将命令发送给服务器 channel.sendall(input_cmd) # 服务器返回了结果,channel通道接受到结果,发生变化 select感知到 if channel in readlist: # 获取结果 result = channel.recv(1024) # 断开连接后退出 if len(result) == 0: print("\r\n**** EOF **** \r\n") break # 输出到屏幕 sys.stdout.write(result.decode()) sys.stdout.flush()# 关闭通道channel.close()# 关闭链接trans.close() 2. Python运维管理组件Fabric123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/usr/bin/env python# -*- coding: utf-8 -*-from datetime import datetimefrom fabric.api import *# 登录用户和主机名：env.user = 'root'env.password='xxxxx'env.hosts = ['192.168.0.1','192.168.0.2'] # 如果有多个主机，fabric会自动依次部署def pack(): ' 定义一个pack任务 ' # 打一个tar包： tar_files = ['*.py', 'static/*', 'templates/*', 'favicon.ico'] local('rm -f example.tar.gz') local('tar -czvf example.tar.gz --exclude=\'*.tar.gz\' --exclude=\'fabfile.py\' %s' % ' '.join(tar_files))def deploy(): ' 定义一个部署任务 ' # 远程服务器的临时文件： remote_tmp_tar = '/tmp/example.tar.gz' tag = datetime.now().strftime('%y.%m.%d_%H.%M.%S') run('rm -f %s' % remote_tmp_tar) # 上传tar文件至远程服务器： put('shici.tar.gz', remote_tmp_tar) # 解压： remote_dist_dir = '/srv/www.example.com@%s' % tag remote_dist_link = '/srv/www.example.com' run('mkdir %s' % remote_dist_dir) with cd(remote_dist_dir): run('tar -xzvf %s' % remote_tmp_tar) # 设定新目录的www-data权限: run('chown -R www-data:www-data %s' % remote_dist_dir) # 删除旧的软链接： run('rm -f %s' % remote_dist_link) # 创建新的软链接指向新部署的目录： run('ln -s %s %s' % (remote_dist_dir, remote_dist_link)) run('chown -R www-data:www-data %s' % remote_dist_link) # 重启服务： fcgi = '/etc/init.d/py-fastcgi' with settings(warn_only=True): run('%s stop' % fcgi) run('%s start' % fcgi)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python自动化运维02]]></title>
    <url>%2F2018%2F06%2F22%2Fpython-devops02%2F</url>
    <content type="text"><![CDATA[本文主要介绍Python自动化运维的常用模块，比如：XlsxWriter、rrdtool等。 1. 用XlsxWriter模块创建报表 安装xlsxwriter模块 1# pip install xlsxwriter 推荐使用pip安装 xlsxwriter模块使用 1234567891011#!/usr/bin/env python# -*- coding:utf-8 -*-import xlsxwriterworkbook = xlsxwriter.Workbook('hello.xlsx')worksheet = workbook.add_worksheet()worksheet.write('A1', 'Hello world')worksheet.write('A2', 'Hello world')worksheet.write('B1', 'Hello world')worksheet.write('B2', 'Hello world')workbook.close() 2. 绘图大师rrdtool rrdtool绘图 创建rrd123456789101112#!/usr/bin/pythonimport rrdtool rrdb=rrdtool.create('rest.rrd','--step','60','--start','1369982786', 'DS:input:GAUGE:120:U:U', 'DS:output:GAUGE:120:U:U', 'RRA:LAST:0.5:1:600', 'RRA:AVERAGE:0.5:5:600', 'RRA:MAX:0.5:5:600', 'RRA:MIN:0.5:5:600')if rrdb: print rrdtool.error() rrd插入数据1234567891011#!/usr/bin/pythonimport timeimport psutilimport rrdtool for keys in psutil.network_io_counters(pernic=True): if keys == 'em1': sent=psutil.network_io_counters(pernic=True)[keys][0] recv=psutil.network_io_counters(pernic=True)[keys][1] up=rrdtool.updatev('rest.rrd','N:%d:%d' % (sent,recv)) print up 根据rrd绘图12345678910111213141516#!/usr/bin/pythonimport rrdtool rrdtool.graph('rest.png','--start','1369983960', '--title','my rrd graph test', '--vertical-label','bits', 'DEF:input=rest.rrd:input:LAST', 'DEF:output=rest.rrd:output:LAST', 'LINE1:input#0000FF:In traffic', 'LINE1:output#00FF00:Out traffic\\r', 'CDEF:bytes_in=input,8,*', 'CDEF:bytes_out=output,8,*', 'COMMENT:\\n', 'GPRINT:bytes_in:LAST:LAST in traffic\: %6.2lf %Sbps', 'COMMENT: ', 'GPRINT:bytes_out:LAST:LAST out traffic\: %6.2lf %Sbps') 3. 利用Python-nmap实现高效端口扫描12345678910111213141516171819202122232425262728293031323334353637383940414243#!/usr/bin/env python# -*- coding: utf-8 -*-import sysimport nmapscan_row=[]input_data = raw_input('Please input host and port:')scan_row = input_data.split(" ")if len(scan_row) != 2: print "Input error!" sys.exit(1)hosts = scan_row[0]port = scan_row[1]try: nm = nmap.PortScanner()except namp.PortScannerError: print "Namp not found",sys.exc_info()[0] sys.exit[2]except: print "Unexpected error:",sys.exc_info()[0] sys.exit[3]try: nm.scan(hosts=hosts,arguments=' -v -sS -p'+port)except Exception as e: print "Scan error:"+str(e)for host in nm.all_hosts(): print '------------------------------------------------' print 'Host: %s (%s)' % host,nm[host].hostname() print 'State: %s' % nm[host].state() for proto in nm[host].all_protocols(): print '--------------' print 'protocol: %s' % proto lport = nm[host][proto].keys() lport.sort() for port in lport: print 'port: %s\tstate: %s' % port,nm[host][proto][port]['state']]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python自动化运维01]]></title>
    <url>%2F2018%2F06%2F22%2Fpython-devops01%2F</url>
    <content type="text"><![CDATA[本文主要介绍Python自动化运维的常用模块，比如：psutil、Dnspython、smtplib等。 1. psutil模块 安装psutil模块 1# pip install psutil 推荐使用pip安装 获取系统信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#!/usr/bin/env python# -*- coding:utf-8 -*-import psutil# cpu信息print("CPU逻辑数量: %s" % psutil.cpu_count())print ("CPU物理核心: %s" % psutil.cpu_count(logical=False))# 内存信息mem = psutil.virtual_memory()print("系统总内存: %s" % mem.total)print("已用内存: %s" % mem.used)print("空闲内存: %s" % mem.free)# 磁盘信息disk_part = psutil.disk_partitions()for item in disk_part: print item.devicefor item in disk_part: print item.mountpoint print psutil.disk_usage(item.mountpoint)#print psutil.disk_io_counters() # 网络信息#print psutil.net_io_counters()net_ifaddrs = psutil.net_if_addrs()print net_ifaddrs["lo"][0].addressprint net_ifaddrs["eth0"][0].addressfor item in psutil.net_connections(): print item# 进程信息for item in psutil.pids(): print psutil.Process(item).name() # 进程名称 print psutil.Process(item).exe() # 进程exe路径 print psutil.Process(item).cwd() # 进程工作目录 print psutil.Process(item).cmdline() # 进程启动的命令行 print psutil.Process(item).ppid() # 父进程ID print psutil.Process(item).parent() # 父进程 print psutil.Process(item).children() # 子进程列表 print psutil.Process(item).status() # 进程状态 print psutil.Process(item).username() # 进程用户名 print psutil.Process(item).create_time() # 进程创建时间 print psutil.Process(item).terminal() # 进程终端 print psutil.Process(item).cpu_times() # 进程使用的CPU时间 print psutil.Process(item).memory_info() # 进程使用的内存 print psutil.Process(item).open_files() # 进程打开的文件 print psutil.Process(item).connections() # 进程相关网络连接 print psutil.Process(item).num_threads() # 进程的线程数量 print psutil.Process(item).threads() # 所有线程信息 print psutil.Process(item).environ() # 进程环境变量 print "======================================================" 2. dnspython模块 安装IPy模块 1# pip install dnspython 使用dnspython模块 12345678910111213#!/usr/bin/env python#-*-coding:utf8-*-import dns.resolverdomain = raw_input('请输入一个域名：')ans = dns.resolver.query(domain, "A")# ans = dns.resolver.query(domain, "CNAME")# ans = dns.resolver.query(domain, "NS")for i in ans.response.answer: print i.to_text() 3. smtplib模块smtplib模块发送邮件 123456789101112131415161718#!/usr/bin/env python#-*-coding:utf8-*-import smtplibimport stringHOST="smtp.126.com" # smtp主机SUBJECT="Test email from Python"TO="1730004882@qq.com" # 接收邮件的邮箱地址FROM="xxx@126.com" # 发送邮件的邮箱地址text="python rules them all!" # 邮件内容BODY=string.join(("From: %s" % FROM,"To: %s" % TO,"Subject: %s" % SUBJECT,"",text),"\r\n")server=smtplib.SMTP()server.connect(HOST,"25")server.starttls()server.login("xxx@126.com","password") # 发送邮件的邮箱地址和密码server.sendmail(FROM,[TO],BODY)server.quit() 4. difflib模块文件内容差异比对方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#### 比较2个字符串#!/usr/bin/env python#-*- coding:utf8 -*-import difflibtext1 = """This module provides classesand funcitions for comparing sequences 1"""text1_lines = text1.splitlines()text2 = """This module provides classesand funcitions for comparing sequences 2"""text2_lines = text2.splitlines()#d = difflib.Differ()#diff = d.compare(text1,text2)#print '\n'.join(list(diff))d = difflib.HtmlDiff()print d.make_file(text1_lines,text2_lines)### 对比配置文件差异#!/usr/bin/env pythonimport difflibimport systry: textfile1 = sys.argv[1] textfile2 = sys.argv[2]except Exception,e: print "Error:"+str(e) print "Usage: diffile.py filename1 filename2" sys.exit()def readfile(filename): try: fileHandle = open(filename,'rb') text = fileHandle.read().splitlines() fileHandle.close() return text except IOError as error: print('Read file Error:'+str(error)) sys.exit()if textfile1 == "" or textfile2 == "": print "Usage: diffile.py filename1 filename2" sys.exit()text1_lines = readfile(textfile1)text2_lines = readfile(textfile2)d = difflib.HtmlDiff()print d.make_file(text1_lines,text2_lines) 单个文件比较： 语法：filecmp.cmp(f1.f2[,shallow]) 比较f1和f2，相同返回true，不同返回false，shallow默认为true，会根据os.stat()比较，不会比较文件内容；反之则会比较内容。 12345&gt;&gt;&gt; import filecmp&gt;&gt;&gt; filecmp.cmp("/etc/passwd","/etc/passwd")True&gt;&gt;&gt; filecmp.cmp("/etc/passwd","/etc/shadow")False 5. pycurl模块pycurl模块是一个用C语言编写的libcurl P python实现，功能非常强大，支持的协议有FTP、HTTP、HTTPS、TELNET等，可以理解成linux下curl命令功能的python封装。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#!/usr/bin/env python# -*- coding:utf8 -*-import os,sysimport timeimport sysimport pycurlURL="http://www.baidu.com"c = pycurl.Curl()c.setopt(pycurl.URL,URL)c.setopt(pycurl.CONNECTTIMEOUT,5)c.setopt(pycurl.TIMEOUT,5)c.setopt(pycurl.NOPROGRESS,1)c.setopt(pycurl.FORBID_REUSE,1)c.setopt(pycurl.MAXREDIRS,1)c.setopt(pycurl.DNS_CACHE_TIMEOUT,30)indexfile = open(os.path.dirname(os.path.realpath(__file__))+"/content.html","wb")c.setopt(pycurl.WRITEHEADER,indexfile)c.setopt(pycurl.WRITEDATA,indexfile)try: c.perform()except Exception,e: print "connection error:"+str(e) indexfile.close() c.close() sys.exit()NAMELOOKUP_TIME = c.getinfo(c.NAMELOOKUP_TIME)CONNECT_TIME = c.getinfo(c.CONNECT_TIME)PRETRANSFER_TIME = c.getinfo(c.PRETRANSFER_TIME)STARTTRANSFER_TIME = c.getinfo(c.STARTTRANSFER_TIME)TOTAL_TIME = c.getinfo(c.TOTAL_TIME)HTTP_CODE = c.getinfo(c.HTTP_CODE)SIZE_DOWNLOAD = c.getinfo(c.SIZE_DOWNLOAD)HEADER_SIZE = c.getinfo(c.HEADER_SIZE)SPEED_DOWNLOAD = c.getinfo(c.SPEED_DOWNLOAD)print "HTTP状态码：%s" %(HTTP_CODE)print "DNS解析时间：%.2f ms" %(NAMELOOKUP_TIME*1000)print "建立连接时间：%.2f ms" %(CONNECT_TIME*1000)print "准备传输时间：%.2f ms" %(PRETRANSFER_TIME*1000)print "传输开始时间：%.2f ms" %(STARTTRANSFER_TIME*1000)print "传输结束总时间：%.2f ms" %(TOTAL_TIME*1000)print "下载数据包大小：%d bytes/s" %(SIZE_DOWNLOAD)print "HTTP头部大小：%d byte" %(HEADER_SIZE)print "平均下载速度：%d bytes/s" %(SPEED_DOWNLOAD)indexfile.close()c.close()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS6.x机器安装Python2.7]]></title>
    <url>%2F2018%2F06%2F21%2Fpython-update%2F</url>
    <content type="text"><![CDATA[本文主要介绍Centos6.x系统安装Python2.7。CentOS6.x默认的python版本为2.6.6，有些软件需要python2.7的环境。安装Python2.7有两种方式：源码安装或者YUM安装。 1.源码方式安装123456# wget https://www.python.org/ftp/python/2.7.12/Python-2.7.12.tgz# tar xf Python-2.7.12.tgz# cd Python-2.7.12# ./configure --prefix=/usr/local/python27# make# make install 2.YUM方式安装1234567891011121314# yum install centos-release-SCL 添加新的yum源# yum install scl-utils-build# yum --disablerepo="*" --enablerepo="centos-sclo-rh" list# yum install python27 -y# find / -name libpython2.7.so.1.0/opt/rh/python27/root/usr/lib64/libpython2.7.so.1.0# echo '/opt/rh/python27/root/usr/lib64/' &gt; /etc/ld.so.conf.d/python27.conf# /sbin/ldconfig# /sbin/ldconfig –v# mv /usr/bin/python /usr/bin/python.bak# ln -s /opt/rh/python27/root/usr/bin/python2.7 /usr/bin/python# python -V# vim /usr/bin/yum将第一行的内容改成：#!/usr/bin/python2.6]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL--避开登录时的[Warning]]]></title>
    <url>%2F2018%2F06%2F20%2Fmysql-warning%2F</url>
    <content type="text"><![CDATA[本文主要介绍如何避开MySQL数据库登录时，在终端中输入密码提示的warning。 在MySQL中, 如果显示的输入密码去登录的话, 就会有一个Warning显示出来, 提醒这种使用方式会不安全。在写脚本时，通过mysql命令行去执行SQL语句，获取执行的结果，这个提示会带来灾难。 1mysql: [Warning] Using a password on the command line interface can be insecure. 解决办法如下： 修改数据库配置文件 在my.cnf配置文件中，加入以下几行： 1234567[client]port=3306socket=/tmp/mysql.sockdefault-character-set=utf8mb4host=localhostuser=数据库用户password='数据库密码' 利用mysql_config_editor安全登录工具 生成加密文件： 1234567# mysql_config_editor set --login-path=local --host=192.168.1.190 --user=root --password参数说明：--login-path 标识--host 登录数据库的主机ip--user 登录数据库的用户名--password 要设置的密码# ll ~/.mylogin.cnf 使用加密文件登录： 1# mysql --login-path=local 查看当前主机上的加密文件： 1# mysql_config_editor print --all 删除某个加密登陆： 12# mysql_config_editor remove --login-path=remote# mysql_config_editor print --all 重置所有： 1# mysql_config_editor reset 利用环境变量MYSQL_PWD 12# export MYSQL_PWD=666666 密码# mysql -uroot -e 'select count(*) from mysql.user;' 不需要-p参数 将警告输出到null 1# mysql -uroot -p123456 -e 'show grants;' 2&gt;/dev/nul 2是标准出错]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux存储之LVM技术]]></title>
    <url>%2F2018%2F06%2F17%2Flinux-lvm%2F</url>
    <content type="text"><![CDATA[本文主要介绍Linux存储技术中的LVM的概念和操作方法。 1. 概述LVM全称是Logical Volume Manager，即逻辑卷管理器。它是Linux环境下对磁盘分区进行管理的一种机制；它可以将多个物理分区整合在一起，并且可以根据实际需要动态调整文件系统空间。 2. LVM的相关概念(1) 物理卷(Physical Volume) 物理卷是组成LVM的最底层的元素，即Linux上的物理分区。 (2) 卷组(Volume Group) 将各个独立的PV组合起来形成的一个存储空间就称为VG，VG的大小就是整个LVM的大小。 (3) 逻辑卷(Logical Volume) 可以被用户格式化、挂载并提供数据存储的对象就是LV。 (4) 物理扩展块(Physical Extent) PE相当于Linux分区中的block，它是LVM的最小存储单位，默认为4M。 做成lvm的优势: 可以灵活变动大小 可以自定义设备名(物理卷也可以改名，使用udev） 可以做线型(linear),条带(stripe),镜像(mirror) 可以做lvm快照 3. LVM基本操作 创建PV 12345678910111213# pvcreate /dev/md0 Physical volume "/dev/md0" successfully created# pvcreate /dev/md1 Physical volume "/dev/md1" successfully created# pvcreate /dev/md10 Physical volume "/dev/md10" successfully created查看相关信息的命令 pvscan pvdisplay pvs删除pv的命令 pvremove /dev/md10# pvpvchange pvcreate pvmove pvresize pvscanpvck pvdisplay pvremove pvs pv.sh 划分vg 12345678910111213141516171819# vgcreate vg01 /dev/md10 Volume group "vg01" successfully created # vgextend vg01 /dev/md0 Volume group "vg01" successfully extended# vgextend vg01 /dev/md1 Volume group "vg01" successfully extended补充：vgcreate -s 指定PE的大小查看相关信息的命令vgscan vgdisplay vgs# vgs VG #PV #LV #SN Attr VSize VFree vg01 3 0 0 wz--n- 4.99G 4.99G# vgreduce vg01 /dev/md0 Removed "/dev/md0" from volume group "vg01"vgreduce跟vgextend是相反的，是在vg里移除pv移除vg的命令是vgremove，它是和vgcreate相反 把vg划分为逻辑卷(线性卷linear) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081# lvcreate -L 1000M -n lv01 vg01 --L指定大小，n指定lv的名字 Logical volume "lv01" created# lvcreate -l 250 -n lv02 vg01 --l指定PE的个数，n指定lv的名字 Logical volume "lv02" created # lvcreate -L 1001M -n lv03 vg01 --指定为1001M，它会自动做成1004M，要是PE的倍数 Rounding up size to full physical extent 1004.00 MB Logical volume "lv03" created# ls /dev/vg01/ -llrwxrwxrwx 1 root root 21 May 7 14:14 lv01 -&gt; /dev/mapper/vg01-lv01lrwxrwxrwx 1 root root 21 May 7 14:15 lv02 -&gt; /dev/mapper/vg01-lv02# ls /dev/mapper/ -lbrw-rw---- 1 root disk 253, 0 May 7 14:14 vg01-lv01brw-rw---- 1 root disk 253, 1 May 7 14:15 vg01-lv02# mkfs.ext4 /dev/vg01/lv01# mkfs.ext4 /dev/vg01/lv02# mount /dev/vg01/lv01 /mnt/# mount /dev/vg01/lv02 /media/# df -h | tail -4/dev/mapper/vg01-lv01 985M 18M 918M 2% /mnt/dev/mapper/vg01-lv02 985M 18M 918M 2% /media# echo '12345' &gt; /mnt/1# echo '678910' &gt; /media/2 查看的相关参数为lvscan lvdisplay# lvscan ACTIVE '/dev/vg01/lv01' [1000.00 MB] inherit ACTIVE '/dev/vg01/lv02' [1000.00 MB] inherit移除lv使用lvremove完全删除lvm，就要先lvremove,再vgremove，最后pvremove# vgs VG #PV #LV #SN Attr VSize VFree vg01 3 2 0 wz--n- 4.99G 3.04G# lvcreate -l 50%VG -n lv03 vg01 --创建lv03，大小为vg01的一半# lvcreate -l 100%FREE -n lv04 vg01 --把剩下的所有空间都分配给新创建的lv04# lvs --使用lvs验证 LV VG Attr LSize Origin Snap% Move Log Copy% Convert lv01 vg01 -wi-ao 1000.00M lv02 vg01 -wi-ao 1000.00M lv03 vg01 -wi-a- 2.49G lv04 vg01 -wi-a- 556.00M使用lvremove把上面的四个卷给移除，再来创建条状卷# lvremove vg01 --移除四个卷 Do you really want to remove active logical volume lv01? [y/n]: y Logical volume "lv01" successfully removedDo you really want to remove active logical volume lv02? [y/n]: y Logical volume "lv02" successfully removedDo you really want to remove active logical volume lv03? [y/n]: y Logical volume "lv03" successfully removedDo you really want to remove active logical volume lv04? [y/n]: y Logical volume "lv04" successfully removed Volume group "lv01" not found当您创建条状逻辑卷时，请使用 lvcreate 命令的 -i 参数指定条带的数目。这取决于逻辑卷要进行条带化的物理卷数目。条带的数目不能超过卷组中物理卷的数目（除非使用 --alloc anywhere 参数）如果构成逻辑卷的基本物理设备的大小不同，条状卷的最大容量由最小的基本设备决定。例如，在有两个分支条状卷中，其容量最大为较小设备的两倍。在有三个分支的条状卷中，其容量是最小设备的三倍条带卷的大小由最小的PV和创建命令的-i参数(条带数)来决定以这个为例 PV VG Fmt Attr PSize PFree /dev/md0 vg01 lvm2 a-- 2.00g 2.00g /dev/md1 vg01 lvm2 a-- 1020.00m 1020.00m /dev/md10 vg01 lvm2 a-- 2.00g 2.00g因为有三个PV,所以用-i 3实现三个条带;那么最大大小为1020*3=3060M 创建条带卷 1234# lvcreate -L 3060M -i3 -n stripe_lv_01 vg01 Logical volume "stripe_lv_01" created 可以对其格式化，再用dd和iostat来做测试(但测试的结果比较复杂,因为我是几种不同的raid做的条带卷) 镜像卷 当您创建一个镜像卷时，您可使用 lvcreate 命令的 -m 参数来指定数据的备份数目。指定 -m1 生成一个镜像，也就是生成两个文件系统副本：一个线性逻辑卷加上一个副本。同样的，指定 -m2 会生成两个镜像，也就是生成三个文件系统副本。 镜像卷的大小由最小的PV和副本数（也就是-m后接的数字)来决定 以这个为例 PV VG Fmt Attr PSize PFree /dev/md0 vg01 lvm2 a– 2.00g 2.00g /dev/md1 vg01 lvm2 a– 1020.00m 1020.00m /dev/md10 vg01 lvm2 a– 2.00g 2.00g 如果-m 1，那么他会选md0和md10这两个来做镜像，所以最大大小为2G 如果-m 2,那么他会选这三个一起来做，最大大小为1020M 不能-m 3或者更大;因为我这里只有三个PV 12345678910111213141516171819202122232425262728293031323334353637383940414243以下面的为例# pvs PV VG Fmt Attr PSize PFree /dev/sdb13 vg01 lvm2 a- 964.00M 964.00M /dev/sdb14 vg01 lvm2 a- 964.00M 964.00M /dev/sdb15 vg01 lvm2 a- 964.00M 964.00M# vgs VG #PV #LV #SN Attr VSize VFree vg01 3 0 0 wz--n- 2.82G 2.82G再次创建镜像卷，成功创建# lvcreate -n lv_mirror -L 300M -m 1 vg01 Logical volume "lv_mirror" created# ls /dev/mapper/control vg01-lv_mirror_mimage_0 vg01-lv_mirror_mlogvg01-lv_mirror vg01-lv_mirror_mimage_1格式化这个镜像卷，并挂载# mkfs.ext3 /dev/mapper/vg01-lv_mirror# mount /dev/mapper/vg01-lv_mirror /media/# df -h/dev/mapper/vg01-lv_mirror 291M 11M 266M 4% /media 测试镜像卷可用性# echo 123 &gt; /media/123# cat /media/123123破坏其中一个物理卷。 # dd if=/dev/zero of=/dev/sdb13 或者 # mkfs.ext3 /dev/sdb13pvs 检测出有物理卷被损坏,找不到uuid但数据仍然可以正常访问# cat /media/123123可以对其格式化，再用dd和iostat来做测试(但测试的结果比较复杂,因为我是几种不同的raid做的条带卷) 关于三种卷之间的转换: 12345678把线性卷转化成镜像卷# lvconvert -m 1 vg01/lv_linear --速度较慢 把镜像卷转化成线性卷# lvconvert -m 0 vg01/lv_mirror --速度较快实现总结：(1) 如果物理做了raid10，那么就可以不做条带和镜像卷了，只有线性卷就可以了(2) 如果物理没做raid，那么你希望提高IO性能或高可用，则可以使用条带或镜像卷 4. LVM扩容先考虑vg是否还有空间去扩容，如果没有，那么要先扩容vg,使用vgextend 12345678910111213141516171819202122# lvextend -L 1.5g /dev/vg01/lv01 Extending logical volume lv01 to 1.50 GB Logical volume lv01 successfully resized下面两种写法也可以# lvextend -L +500M /dev/vg01/lv01# lvextend -l +125 /dev/vg01/lv01# df -h/dev/mapper/vg01-lv01985M 18M 918M 2% /mnt 查看已经挂载的大小，没有变化# resize2fs /dev/vg01/lv01 再使用这个命令去在线同步resize2fs 1.39 (29-May-2006)Filesystem at /dev/vg01/lv01 is mounted on /mnt; on-line resizing requiredPerforming an on-line resize of /dev/vg01/lv01 to 393216 (4k) blocks.The filesystem on /dev/vg01/lv01 is now 393216 blocks long.# df -h/dev/mapper/vg01-lv011.5G 18M 1.4G 2% /mnt 再次查看,已经挂载的lv扩大了，并且数据没有影响 5. LVM缩小做缩小操作之前，都要去验证查看一下数据的大小，缩小时不要缩到比已经存在的数据量还要小(数据库内的表空间缩小也是一样要先查看已有数据大小） 1234567891011121314151617181920212223242526272829303132333435363738394041424344# resize2fs /dev/vg01/lv01 1g --这样去缩小的话，报错已经mount了resize2fs 1.39 (29-May-2006)Filesystem at /dev/vg01/lv01 is mounted on /mnt; on-line resizing requiredOn-line shrinking from 393216 to 262144 not supported.# umount /mnt/# resize2fs /dev/vg01/lv01 1g --umount后再使用resize2fs命令，要求先去e2fsck检测resize2fs 1.39 (29-May-2006)Please run 'e2fsck -f /dev/vg01/lv01' first.# e2fsck -f /dev/vg01/lv01 e2fsck 1.39 (29-May-2006)Pass 1: Checking inodes, blocks, and sizesPass 2: Checking directory structurePass 3: Checking directory connectivityPass 4: Checking reference countsPass 5: Checking group summary information/dev/vg01/lv01: 12/192000 files (8.3% non-contiguous), 10517/393216 blocks# resize2fs /dev/vg01/lv01 1g 检测后再使用resize2fs命令缩小，并挂载查看大小是否缩小resize2fs 1.39 (29-May-2006)Resizing the filesystem on /dev/vg01/lv01 to 262144 (4k) blocks.The filesystem on /dev/vg01/lv01 is now 262144 blocks long.# lvscan ACTIVE '/dev/vg01/lv01' [1.50 GB] inherit 但这里查看的还是1.5g ACTIVE '/dev/vg01/lv02' [1000.00 MB] inherit# lvreduce -L 1g /dev/vg01/lv01 所以lvreduce也要做 WARNING: Reducing active logical volume to 1.00 GB THIS MAY DESTROY YOUR DATA (filesystem etc.)Do you really want to reduce lv01? [y/n]: y Reducing logical volume lv01 to 1.00 GB Logical volume lv01 successfully resized# lvscan ACTIVE '/dev/vg01/lv01' [1.00 GB] inherit --OK ACTIVE '/dev/vg01/lv02' [1000.00 MB] inherit# mount /dev/vg01/lv01 /mnt/# df -h/dev/mapper/vg01-lv02985M 18M 918M 2% /media 缩小了 6. lvm 快照功能(1) 快照创建的速度非常快，不需要停止生产环境 (2) 快照的大小是存储差异数据，或是快照时间点的状态，不需要和lv同大小 (3) 它可以用于一些特殊的情况，比如数据库备份，或者批量复制虚拟机（不关闭虚拟机的情况下，克隆是需要关闭或暂停虚拟机的),虚拟机做快照等 123456789101112131415161718192021222324252627282930313233343536373839404142434445# dd if=/dev/zero of=/media/10m bs=1M count=10# dd if=/dev/zero of=/media/20m bs=1M count=20# dd if=/dev/zero of=/media/30m bs=1M count=30# ls /media/ -ltotal 61532-rw-r--r-- 1 root root 10485760 May 7 15:18 10m-rw-r--r-- 1 root root 20971520 May 7 15:18 20m-rw-r--r-- 1 root root 31457280 May 7 15:18 30mdrwx------ 2 root root 16384 May 7 14:17 lost+found# lvcreate -s -L 100m -n snap01 /dev/vg01/lv02 --L参数指定的大小不是快照大小，它类似于一个快照存活的时间（由源的改变来定义存活时间的长短。源增加多少，这个100M‘时间‘就会被使用多少，源删除，这个100M时间只会被增加一点点，因为删除只记录它的一个innode失效。但注意，快照的内容不会跟着改变。 Logical volume "snap01" created# ls /dev/vg01/snap01 /dev/vg01/snap01# mkdir /snap# mount /dev/vg01/snap01 /snap/# ls /snap/ --快照的内容10m 20m 30m lost+found# dd if=/dev/zero of=/media/50m bs=1M count=50--在源目录加一个50M的文件# ls /snap/ --快照的内容不会跟着变10m 20m 30m lost+found# lvs LV VG Attr LSize Origin Snap% Move Log Copy% Convert lv01 vg01 -wi-ao 1.00G lv02 vg01 owi-ao 1000.00M snap01 vg01 swi-ao 100.00M lv02 50.48 --但是这个snap%会发现由几乎为0变化到50%下面再可以继续做试验：1，在源删除一个文件，再使用lvs查看 %snap只会增加一点点2，当%snap用完了100%，则快照失效。umount和mount快照都会出问题3, 快照的内容不会跟着源改变# lvremove /dev/vg01/snap01 --快照的移除Do you really want to remove active logical volume snap01? [y/n]: y Logical volume "snap01" successfully removed]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux存储之RAID技术]]></title>
    <url>%2F2018%2F06%2F17%2Flinux-raid%2F</url>
    <content type="text"><![CDATA[本文主要介绍Linux存储技术中的RAID的概念和操作方法。 1. RAID概念 RAID（Redundant Array of Inexpensive Disks）称为廉价磁盘冗余阵列。RAID的基本想法是把多个便宜的小磁盘组合到一起，成为一个磁盘组，使性能达到或超过一个容量巨大、价格昂贵的磁盘。 目前 RAID技术大致分为两种：基于硬件的RAID技术和基于软件的RAID技术。 本文介绍的是软RAID。 2. RAID级别raid 0 读写性能佳，坏了其中一块，数据挂掉，可靠性低（stripe条带化），磁盘利用率100％ ​ A B ​ 1 2 ​ 3 4 raid 1 镜像备份（mirror)，同一份资料完整的保存在多个磁盘上，写的性能不佳，可靠性高，读的性能还行，磁盘利用率50% ​ A B ​ 1 1 ​ 2 2 ​ 3 3 ​ 4 4 raid 5 由多块磁盘做raid 5，磁盘利用率为n-1/n, 其中一块放校验数据，允许坏一块盘，数据可以利用校验值来恢复 ​ disk 1 disk 2 disk 3 ​ 数据 数据 校验 ​ 检验 数据 数据 ​ 数据 检验 数据 raid 10 先做raid1，再做raid0 raid01 先做raid0，再做raid1 3. 软RAID实现使用vmware或者kvm直接在线加8个1G大小的硬盘 linear 线型 stripe 条带 mirror 镜像 创建raid 0 12# mdadm --create /dev/md0 --level=0 --raid-devices=2 /dev/sdb /dev/sdcmdadm: array /dev/md0 started. 创建过程中可以用另一终端cat /proc/mdstat去查看正在创建的状态信息 1234# mkfs.ext4 /dev/md0# mount /dev/md0 /mnt/# df -h |grep mnt# cat /proc/mdstat 创建raid 1 1234# mdadm --create /dev/md1 --level=1 --raid-devices=2 /dev/sdd /dev/sde# mkfs.ext4 /dev/md1# mount /dev/md1 /media/# df -h |grep md 对上面的raid0和raid1的一个写性能使用dd命令进行测试，下面命令可以多测几次 12# dd if=/dev/zero of=/mnt/aaa bs=1M count=1000# dd if=/dev/zero of=/media/bbb bs=1M count=1000 测试的结果是raid0写性能比raid1要好 1# yum install sysstat -y 验证raid0，在做raid0的两个盘上查看io情况 终端1：iostat 2 两秒一次查看所有的盘上的IO情况 终端2: dd if=/dev/zero of=/mnt/aaa bs=1M count=1000 可以看到两个盘上都有写的io,并且/dev/sdb和/dev/sdc的IO一样,总和才等于/dev/md0的IO;验证了raid0的功能(条带) 验证raid1，在做raid1的两个盘上查看io情况 终端1：iostat 2 两秒一次查看所有的盘上的IO情况 终端2: dd if=/dev/zero of=/media/aaa bs=1M count=1000 可以看到两个盘上都有写的io,并且/dev/sdd和/dev/sde的IO一样,并且也等于/dev/md1的IO;验证了raid1的功能(镜像) 创建raid5 12345678910# mdadm --create /dev/md5 --level=5 --raid-devices=4 /dev/sdf /dev/sdg /dev/sdh /dev/sdimdadm: array /dev/md5 started.# watch cat /proc/mdstat --这里监控一下它们盘之间的数据同步；等它们同步完毕再进行下面的格式化# mkfs.ext4 /dev/md5# mount /dev/md5 /misc/# df -h |grep md/dev/md0 2.0G 36M 1.9G 2% /mnt --raid 0利用率为100%/dev/md1 1008M 18M 940M 2% /media --raid 1利用率为50%/dev/md5 3.0G 69M 2.8G 3% /misc --raid 5利用率为n-1/n,在这里就是3/4# cat /proc/mdstat 验证raid5，在做raid5的四个盘上查看io情况 终端1：iostat 2 两秒一次查看所有的盘上的IO情况 终端2: dd if=/dev/zero of=/misc/aaa bs=1M count=1000 4. RAID启停123456789# vim /etc/mdadm.conf 手动编写raid的配置文件，此文件不存在，要手动建立，并写上DEVICES /dev/sdb /dev/sdc /dev/sdd /dev/sde /dev/sdf /dev/sdg /dev/sdh /dev/sdi 把做了raid的分区写上来。或者写成DEVICES /dev/sd[bcdefghi]。但不能写成DEVICES /dev/sd&#123;b,c,d,e,f,g,h,i&#125;# mdadm --detail --scan &gt;&gt; /etc/mdadm.conf 扫描当前raid的信息，并追加到配置文件里# cat /etc/mdadm.conf DEVICES /dev/sdb /dev/sdc /dev/sdd /dev/sde /dev/sdf /dev/sdg /dev/sdh /dev/sdiARRAY /dev/md0 level=raid0 num-devices=2 metadata=0.90 UUID=84209045:9c03c4cb:7f755b8d:cc471294ARRAY /dev/md1 level=raid1 num-devices=2 metadata=0.90 UUID=4e62fdc1:6c2a652f:fb72c05d:356d5c76ARRAY /dev/md5 level=raid5 num-devices=4 metadata=0.90 UUID=c3c1f37b:9fba8a89:a711dc6c:01a5ddb3 停止raid设备 123456789101112先umount 已经挂载的raid设备# umount /mnt/# umount /media/# umount /misc/然后使用命令停止# mdadm --stop /dev/md0mdadm: stopped /dev/md0# mdadm --stop /dev/md1mdadm: stopped /dev/md1# mdadm --stop /dev/md5mdadm: stopped /dev/md5 启动raid设备” 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162(1) 有/etc/mdadm.conf配置文件的情况下# mdadm -A /dev/md0 mdadm: /dev/md0 has been started with 2 drives.# mdadm -A /dev/md1mdadm: /dev/md1 has been started with 2 drives.# mdadm -A /dev/md5mdadm: /dev/md5 has been started with 4 drives.# cat /proc/mdstat --再查看，就有信息了，并且raid里的数据还在(2) 没有配置文件的情况下，手动把设备名写上就可以了# mdadm -A /dev/md0 /dev/sd&#123;b,c&#125;mdadm: /dev/md0 has been started with 2 drives.# mdadm -A /dev/md1 /dev/sd&#123;d,e&#125;mdadm: /dev/md1 has been started with 2 drives.# mdadm -A /dev/md5 /dev/sd&#123;f,g,h,i&#125;mdadm: /dev/md5 has been started with 4 drives.(3) 如果连设备名都不知道，可以去查看每个设备的raid信息，使用uuid把raid设备重新组合# mdadm -E /dev/sdf/dev/sdf: Magic : a92b4efc Version : 0.90.00 UUID : b091e16b:f8df9671:465755db:c640595b --UUID,同一个raid里每个磁盘查看的都是这个值 Creation Time : Sat May 7 11:23:52 2011 Raid Level : raid5 Used Dev Size : 1048512 (1024.11 MiB 1073.68 MB) Array Size : 3145536 (3.00 GiB 3.22 GB) Raid Devices : 4 Total Devices : 4Preferred Minor : 5 Update Time : Sat May 7 11:42:09 2011 State : clean Active Devices : 4Working Devices : 4 Failed Devices : 0 Spare Devices : 0 Checksum : facef367 - correct Events : 2 Layout : left-symmetric Chunk Size : 64K Number Major Minor RaidDevice Statethis 0 8 80 0 active sync /dev/sdf 0 0 8 80 0 active sync /dev/sdf 1 1 8 96 1 active sync /dev/sdg 2 2 8 112 2 active sync /dev/sdh 3 3 8 128 3 active sync /dev/sdi# mdadm -A --uuid=b091e16b:f8df9671:465755db:c640595b /dev/md5 mdadm: /dev/md5 has been started with 4 drives.上面组合后的名字可以随意写，甚至是不存在的一个名字，相当于是重新组合 5. 软raid的热插拔实验模拟raid中其中一块盘故障 123456789101112131415161718192021222324252627282930313233343536# mdadm /dev/md5 --fail /dev/sdfmdadm: set /dev/sdf faulty in /dev/md5--使用--fail对raid中其中一块盘打一个fail标记# cat /proc/mdstat Personalities : [raid0] [raid1] [raid6] [raid5] [raid4] md5 : active raid5 sdf[4](F) sdi[3] sdh[2] sdg[1]--有个F标记 3145536 blocks level 5, 64k chunk, algorithm 2 [4/3] [_UUU] md1 : active raid1 sdd[0] sde[1] 1048512 blocks [2/2] [UU] md0 : active raid0 sdb[0] sdc[1] 2097024 blocks 64k chunks# mdadm /dev/md5 --remove /dev/sdfmdadm: hot removed /dev/sdf热移除故障磁盘# mdadm /dev/md5 --add /dev/sdj --增加一块新的磁盘上去mdadm: re-added /dev/sdj--刚增加完后，机器负载较高，因为现在它在对新盘同步数据# cat /proc/mdstat Personalities : [raid0] [raid1] [raid6] [raid5] [raid4] md5 : active raid5 sdj[4] sdi[3] sdh[2] sdg[1] 3145536 blocks level 5, 64k chunk, algorithm 2 [4/3] [_UUU] [=====&gt;...............] recovery = 29.2% (307840/1048512) finish=0.0min speed=153920K/sec --这里可以看到在同步中 md1 : active raid1 sdd[0] sde[1] 1048512 blocks [2/2] [UU] md0 : active raid0 sdb[0] sdc[1] 2097024 blocks 64k chunks 同步完成后，查看数据还在； 6. 删除raid123456789101112131415161718192021222324(1) 第一步# umount(2) 第二步# mdadm /dev/md5 --fail /dev/sdf --remove /dev/sdfmdadm: set /dev/sdf faulty in /dev/md5mdadm: hot removed /dev/sdf# mdadm /dev/md5 --fail /dev/sdg --remove /dev/sdgmdadm: set /dev/sdg faulty in /dev/md5mdadm: hot removed /dev/sdg# mdadm /dev/md5 --fail /dev/sdh --remove /dev/sdhmdadm: set /dev/sdh faulty in /dev/md5mdadm: hot removed /dev/sdh# mdadm /dev/md5 --fail /dev/sdi --remove /dev/sdimdadm: set /dev/sdi faulty in /dev/md5mdadm: hot removed /dev/sdi(3) 第三步# mdadm --stop /dev/md5mdadm: stopped /dev/md5(4) 第四步直接用fdisk删除分区，或者用下面命令擦除superblock# mdadm --misc --zero-superblock /dev/sdf# mdadm --misc --zero-superblock /dev/sdg# mdadm --misc --zero-superblock /dev/sdh# mdadm --misc --zero-superblock /dev/sdi]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下自动批量部署操作系统]]></title>
    <url>%2F2018%2F06%2F15%2Flinux-ks%2F</url>
    <content type="text"><![CDATA[本文主要介绍Linux下使用kickstart进行自动批量安装系统。 1. kickstart简介Kickstart是一种无人值守的安装方式。它的工作原理是在安装过程中记录典型的需要人工干预填写的各种参数，这些参数都记录在ks.cfg的文件中， 安装程序按照预先设置好的参数进行部署操作系统。等安装完毕，安装程序会根据ks.cfg中的设置重启系统，并结束安装。 kickstart是基于pxe(preboot execute environment)技术，pxe是intel公司的技术，工作server/client的网络模式，支持客户端从服务端下载软件，再使用tftp(trival file tranfer protocol) 协议下载一个启动软件包到客户端内存中执行。 要求的技术和服务： (1) http服务器或者用nfs,ftp三种协议之一 共享安装光盘目录文件(2) tftp服务器 共享启动引导文件(3) dhcp服务器 客户端获取IP，网关，DNS指向，主机名，NIS域，NTP(4) kickstart程序生成的ks.cfg配置文件 2. 实践 第一步，搭建安装源 1234# yum install httpd -y 安装httpd# mkdir /var/www/html/iso 创建一个目录# mount /opt/packs/CentOS-6.5-x86_64-bin-DVD1.iso /var/www/html/iso -o loop 将光盘挂载# service httpd start 要保证可以通过http方式获取光盘里的内容 第二步，配置tftp服务器 1234567891011121314151617# yum install tftp-server 安装tftp# vim /etc/xinetd.d/tftpservice tftp&#123; socket_type = dgram protocol = udp wait = yes user = root server = /usr/sbin/in.tftpd server_args = -t -s -v /var/lib/tftpboot 启动参数改为-t -s -v disable = no yes改为no per_source = 11 cps = 100 2 flags = IPv4&#125;# service xinetd start# netstat -ntlup |grep :69 确认tftp启动了 第三步，配置pxe启动文件 12345678910111213# yum install syslinux -y# cp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/# cp /var/www/html/iso/isolinux/* /var/lib/tftpboot/ # mkdir /var/lib/tftpboot/pxelinux.cfg# cp /var/www/html/iso/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default# vim /var/lib/tftpboot/pxelinux.cfg/defaultdefault linux-rzxprompt 1timeout 3label linux-rzx kernel vmlinuz append initrd=initrd.img ks=http://192.168.1.99/ks/ks.cfg 第四步，搭建DHCP服务器 1234567891011121314151617181920# yum install dhcp -y# cp /usr/share/doc/dhcp-4.1.1/dhcpd.conf.sample /etc/dhcp/dhcpd.conf# vim /etc/dhcp/dhcpd.conflog-facility local7;next-server 192.168.1.99;filename "/var/lib/tftpboot/pxelinux.0";allow bootp;allow booting;subnet 192.168.1.0 netmask 255.255.255.0 &#123; range 192.168.1.50 192.168.1.100; option domain-name-servers 192.168.1.1; option routers 192.168.1.1; option broadcast-address 192.168.1.255; default-lease-time 600; max-lease-time 7200;&#125;# /etc/init.d/dhcpd restart 第五步，配置kickstart 12# yum install system-config-kickstart 安装kickstart的图形配置工具# system-config-kickstart 运行该命令生成ks.cfg文件 这里说明一点：如果系统中没有安装图形，是不能运行system-config-kickstart的。 生成ks.cfg文件之后，将其放到Apache的数据目录，以便在安装系统时，可以下载到。 12# mkdir /var/www/html/ks/# ks.cfg /var/www/html/ks/ 第六步，安装 服务器启动时，选择网络启动方式优先。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下远程拷贝时无需输入密码]]></title>
    <url>%2F2018%2F06%2F13%2Flinux-nopass-copy%2F</url>
    <content type="text"><![CDATA[本文主要介绍Linux系统中，远程拷贝文件时无需输入密码来拷贝的一种简单办法。我们在远程拷贝文件时，尤其是不同地区的服务器之间拷贝数据，一般是使用scp或者rsync来拷贝。这两个命令都需要输入密码。一般来说，有三种办法来实现无密码拷贝。(1)SSH等效性建立信任关系(2)使用expect脚本来自动输入密码(3)使用sshpass工具来自动输入密码本文重点介绍sshpass工具来实现，这个工具比较简单。 1. sshpass命令如果系统中没有sshpass命令，则通过如下命令可以安装：1# yum -y install sshpass sshpass命令的使用方法：12# sshpass -p 123456 ssh 192.168.1.100 -p参数是服务器192.168.1.100的密码，这样就可以直接登录了# sshpass -f password.txt ssh 192.168.1.100 -f参数是file，密码文件，默认读取文件的第一行作为密码 2. sshpass实现远程拷贝123# sshpass -f password.txt scp -r /opt/packs/xxx.iso root@192.168.1.100:/root/packs/# sshpass -f password.txt rsync -a /opt/packs/xxx.iso root@192.168.1.100:/root/packs/# nohup sshpass -f password.txt rsync -a /opt/packs/xxx.iso root@192.168.1.100:/root/packs/ &amp; 也可以使用nohup在后台跑 这里建议使用sshpass的-f参数来存放密码，然后执行1# chmod 600 password.txt 这样只有root才可以读写，保证了安全性。-p直接在命令行输入密码不安全。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统备份与还原]]></title>
    <url>%2F2018%2F06%2F12%2Flinux-system-backup%2F</url>
    <content type="text"><![CDATA[本文主要介绍centos系统的备份和还原。我们在使用Windows时，可以使用ghost工具对系统进行备份，那么Linux系统是如何备份的呢 1. 备份系统在linux系统中，有一句话叫做一切都是文件，既然是文件，我们就可以通过打包的方式来备份。 使用root身份登录系统，进行打包操作。 12345678# tar cvpzf /backup.tgz –exclude=/proc –exclude=/lost+found –exclude=/backup.tgz –exclude=/mnt –exclude=/sys –exclude=/sys /参数说明：c 按照man手册，直译创建一个新的存档，意思是打包文件backup.tgz不存在，需要创建v 显示打包过程和细节p 保留文件的权限z gzip格式压缩，和windows上的rar格式或zip格式差不多f 文件，cf一起的意思是创建文件exclude 是排除那些文件不打包进去 上面的命令将/下的所有东西打成一个包，有些系统上动态的文件可以不用打包，排除出去，比如：/proc，/sys。也可以把不用备份的文件排除出去。 2. 系统还原在进行恢复系统的操作时一定要小心！如果你不清楚自己在做什么，那么你有可能把重要的数据弄丢，请务必小心！ 切换到root用户，并把文件“backup.tgz”拷贝到分区的根目录下。 1# tar xvpfz /backup.tgz -C / 恢复命令结束时，你的工作还没完成，别忘了重新创建那些在备份时被排除在外的目录： 1234# mkdir proc# mkdir lost+found# mkdir mnt# mkdir sys 保险起见，最好是执行一下如下命令： 1# restorecon -Rv / restorecon命令是用来恢复文件的SELinux配置信息的。 最后重启服务器，重新启动时观察一下，有没有服务没有起来。 3. 还原到其他的Linux中有时候会出现这种情况，备份的Linux系统已经损坏，比如硬盘坏了，上面的备份文件还有，那么是否可以恢复呢，答案是肯定的。 重新准备一台服务器，最好是分区、系统版本和损坏的服务器是一致的，安装好相同版本的Linux系统。将备份文件backup.tgz拷贝到新的服务器中。 12# mkdir /mnt/backup/# awk 'BEGIN &#123; cmd="cp -ari /mnt/backup/* /"; print "n" |cmd; &#125;' 上面的命令是”cp -ari /mnt/backup/* /“，意思是拷贝所有的备份文件，将/下的目录进行覆盖。print “n”的意思是同名文件不覆盖。这样做就是将老系统中的文件复制到新系统，不覆盖已经存在的文件。 那么为什么不能覆盖呢？每个Linux系统中有一些唯一的信息不能覆盖，否则系统会坏掉。比如： 1234567# blkid/dev/sda5: UUID="5d938847-6503-40cf-845d-a85777d4d1e1" TYPE="ext4" /dev/sda1: UUID="86215e74-789c-4a32-ad2a-7d2a1a06a587" TYPE="ext4" /dev/sda2: UUID="1031afbe-2bf8-474c-9d3f-93a77d5751df" TYPE="ext4" /dev/sda3: UUID="83898300-4d9d-41de-951a-62896cde5025" TYPE="ext4" /dev/sda6: UUID="381b6c24-de6a-4d01-8382-9b3bb3a9ecc3" TYPE="ext4" /dev/sda7: UUID="c0793320-2302-4018-8482-130fbc4dca06" TYPE="swap" 每个系统的分区都有一个UUID，这个是唯一的，覆盖之后就会出问题。 123456789101112131415161718# cat /etc/fstab ## /etc/fstab# Created by anaconda on Tue Dec 22 15:16:37 2015## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#UUID=5d938847-6503-40cf-845d-a85777d4d1e1 / ext4 defaults 1 1UUID=1031afbe-2bf8-474c-9d3f-93a77d5751df /appslog ext4 defaults 1 2UUID=86215e74-789c-4a32-ad2a-7d2a1a06a587 /boot ext4 defaults 1 2UUID=83898300-4d9d-41de-951a-62896cde5025 /opt ext4 defaults 1 2UUID=381b6c24-de6a-4d01-8382-9b3bb3a9ecc3 /usr ext4 defaults 1 2UUID=c0793320-2302-4018-8482-130fbc4dca06 swap swap defaults 0 0tmpfs /dev/shm tmpfs defaults 0 0devpts /dev/pts devpts gid=5,mode=620 0 0sysfs /sys sysfs defaults 0 0proc /proc proc defaults 0 0 系统中的fstab中用到了UUID，覆盖了文件会导致系统启动不了。 然后执行： 1# restorecon -Rv / 这一步是必须的，否则重启系统会报错。 最后就是观察重启系统时，是否有服务没启动，需要手动将其启动。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux网络工具]]></title>
    <url>%2F2018%2F06%2F10%2Flinux-net-tools%2F</url>
    <content type="text"><![CDATA[本文主要介绍Linux系统中常用的网络工具。 1. curl命令curl 命令行访问URL的工具 12345678910111213141516171819202122# curl http://www.baidu.com 直接将百度网页的源码输出到屏幕上# curl http://www.baidu.com –o baidu.html 将百度网页的源码保存起来# curl -O http://www.linux.com/hello.sh 将hello.sh文件下载下来# curl -# -O http://www.linux.com/dodo1.JPG 显示下载进度条# curl -C -O http://www.linux.com/dodo1.JPG 断点续传# curl -o /dev/null -s -w %&#123;http_code&#125; www.baidu.com 测试网页返回值，非常有用# curl -o /dev/null -s -w %&#123;http_code&#125;:%&#123;http_connect&#125;:%&#123;content_type&#125;:%&#123;time_namelookup&#125;:%&#123;time_redirect&#125;:%&#123;time_pretransfer&#125;:%&#123;time_connect&#125;:%&#123;time_starttransfer&#125;:%&#123;time_total&#125;:%&#123;speed_download&#125; digdeeply.org# curl -x 192.168.100.100:1080 http://www.linux.com -x参数是设置代理的# curl -I http://static.futunn.com/passport/images/global/logo_futunn-b9fab8d8f683775e9c3c5ade78e822ec.png -x 211.162.36.175:80# curl -I www.sina.com.cn -x 124.42.245.30:80# curl -I 124.42.245.30# curl -I 124.42.245.30 -H 'host:www.sina.com.cn'# curl -s -D header.txt http://www.linux.com -o /dev/null 保存访问网站的header信息# curl -I http://www.linux.com 在屏幕上显示header信息# curl -c cookie.txt http://www.linux.com 保存访问网站的cookie信息# curl -A "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.0)" http://www.linux.com 模仿浏览器# curl -e "www.abc.com" http://mail.linux.com 伪造referer# curl -T dodo1.JPG -u 用户名:密码 ftp://www.linux.com/img/ 上传文件# curl ip.cn# curl myip.ipip.net# curl ip.cip.cc 2. nmap命令Nmap 是一款开放源代码的 网络探测和安全审核的工具。 它的设计目标是快速地扫描大型网络 。 123456789101112131415161718192021# nmap -sP 192.168.1.0/24 使用ping检测192.168.1.0/24这个网段# nmap --iflist# nmap -e eth0 192.168.1.5 扫描ip开放的端口# nmap 192.168.1.1 -p 1-500 自定义扫描端口# nmap -sn 192.168.1.0/2 只进行主机发现，不进行端口扫描# nmap 192.168.1.1 -P0 端口扫描(Pn)# nmap 192.168.1.1-100 多个ip# nmap -F 192.168.1.* 多个ip，-F 快速扫描# nmap -sS 192.168.1.153 Tcp SYN Scan (sS)# nmap -sT 192.168.1.153 Tcp connect() scan(sT)# nmap -sU 192.168.1.153 Udp scan(sU)# nmap -sF 192.168.1.153 FINscan(sF)# nmap -sV 192.168.1.153 版本检测(sV)# nmap 192.168.1.153 -p U:22,80,T:21-25,80,139,8080 TCP、UDP端口扫描# nmap --traceroute www.baidu.com 路由跟踪# nmap -O 192.168.1.153 操作系统# nmap -A 192.168.1.153 激进方式扫描，扫描端口和os# nmap -sV -p 22 -oG grep-output.txt 192.168.1.0/24 输出格式，可检索的# nmap -sV -p 22 -oA grep-output.txt 192.168.1.0/24 输出格式，-oA所有，可检索的、常规的和XML文件# nmap -sV -p 22 -oX grep-output.txt 192.168.1.0/24 输出格式，XML# nmap -sV -p 22 -oN grep-output.txt 192.168.1.0/24 输出格式，常规格式 3. nc命令 (1) 安装 1# yum install -y nc (2) 远程拷贝文件 1234server1：# nc -l 1234 &gt; test.txtserver2：# nc 192.168.1.3 &lt; test.txt (3) 传输目录 1234server1：# nc -l 1234 | tar xzv-server2：# tar czv- nginx | nc 192.168.48.47 1234 (4) 简单聊天工具 1234在192.168.1.2上： # nc -l 1234在192.168.1.3上： # nc 192.168.1.2 1234 (5) 端口扫描 1# nc -v -w 2 192.168.2.34 -z 21-24 (6) 克隆硬盘或分区 12# nc -l -p 1234 | dd of=/dev/sda# dd if=/dev/sda | nc 192.168.228.222 1234 4. wget命令wget是一个下载文件的工具 。 命令格式： wget [参数] [URL地址 ] wget下载单个文件 1# wget http://ftp.gnu.org/gnu/wget/wget-1.16.2.tar.gz 下载并以不同的文件名保存 1# wget http://ftp.gnu.org/gnu/wget/wget-1.16.2.tar.gz -o wget.tgz 限速下载 1# wget --limit-rate=300k http://ftp.gnu.org/gnu/wget/wget-1.16.2.tar.gz 断点续传 1# wget -c http://ftp.gnu.org/gnu/wget/wget-1.16.2.tar.gz 后台下载 1# wget -b http://ftp.gnu.org/gnu/wget/wget-1.16.2.tar.gz 测试下载链接 1# wget --spider http://ftp.gnu.org/gnu/wget/wget-1.16.2.tar.gz 复制整个网站（镜像） 1# wget --mirror --convert-links http://exampledomain.com 访问需要认证的HTTP或FTP页面 1# wget --user username --password pass URL 指定目录下载 1# wget -P /home/download http://ftp.gnu.org/gnu/wget/wget-1.16.2.tar.gz 下载目录中的所有文件 12345678910# wget -r -np -nd http://mirrors.163.com/centos/6/isos/x86_64/# wget -r -p -np -k http://mirrors.163.com/centos/6/isos/x86_64/参数说明：-r, --recursive 递归下载-k, --convert-links 让下载得到的 HTML 或 CSS 中的链接指向本地文件-m, --mirror -N -r -l inf --no-remove-listing 的缩写形式-np, --no-parent 不追溯至父目录-nd, --no-directories 不创建目录-l, --level=NUMBER 最大递归深度 (inf 或 0 代表无限制，即全部下载)-c, --continue 断点续传下载文件 https协议 12# wget https://centos6.iuscommunity.org/ius-release.rpm# wget https://centos6.iuscommunity.org/ius-release.rpm --no-check-certificate]]></content>
      <categories>
        <category>linux-basic</category>
      </categories>
      <tags>
        <tag>linux-basic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统相关命令]]></title>
    <url>%2F2018%2F06%2F10%2Flinux-system%2F</url>
    <content type="text"><![CDATA[本文主要介绍Linux系统相关命令，比如关机，查看硬件信息等。 1. 关机命令12345678# shutdown -h now 关机# init 0 关机# telinit 0 关机# # shutdown -h hours:minutes &amp; 按预定时间关机# shutdown -c 取消按预定时间关闭系统# shutdown -r now 重启 # reboot 重启 # logout 注销 2. 硬件相关12345# dmidecode -q 硬件相关信息 # hdparm -tT /dev/sda 在磁盘上执行测试性读取操作 # lscpu 查看CPU# lspci 查看主板# lsblk 查看磁盘分区 3. 网络命令 ifconfig命令 12345678# ifconfig 显示一个以太网卡的配置，常用选项：# ifconfig eth0# ifconfig eth0 down# ifconfig eth0 up# ifconfig eth0 192.168.1.99 broadcast 192.168.1.255 netmask 255.255.255.0# ifconfig eth0:0 192.168.1.100 netmask 255.255.255.0 添加虚拟网卡# ifup eth0 启用一个 'eth0' 网络设备 # ifdown eth0 禁用一个 'eth0' 网络设备 ip命令 12345678910# ip 网络配置工具，常用选项：# ip a# ip addr show# ip addr show dev eth0 查看服务器ip地址# ip -s link list# ip -s link ls eth0 查看接口统计(ethtool -S eth0)# ip route list 查看路由表# ip neigh list 查看邻居表（arp -an）# ip addr add 192.168.0.215/24 label eth0:1 dev eth0 添加虚拟网卡# ip addr del 192.168.0.215/24 label eth0:1 dev eth0 删除虚拟网卡 netstat命令 12345# netstat -an | grep LISTEN -a 显示所有socket，包括正在监听的, -n 以网络IP地址代替名称# netstat -ntlup 查看系统网络的状态信息，t=tcp，u=udp，p=程序名称，l=监听# netstat -s 按照各个协议分别显示其统计数据# netstat -i 显示网卡接口信息# netstat –r 显示关于路由表的信息(rount -n) 4. 系统监控和性能分析命令 iostat命令 12345# iostat 直接运行，显示所有设备负载情况# iostat 2 3 每2秒显示一次，总共显示3次# iostat -c 查看cpu# iostat -d 查看磁盘# iostat -d -x 1 x参数是详细信息 vmstat命令 123# vmstat 虚拟内存统计# vmstat 2 2 每2秒显示一次，总共显示2次# vmstat 2 2 -S m -S参数是单位，可以是k、m等 free命令 123# free 查看内存# free -m -m是单位# free -m -s 2 -s是时间，每2秒查看一次 dstat命令 12345# dstat 信息统计工具# dstat -n n是net# dstat -d d是disk# dstat -m m是memory# dstat -l l是load average 显示系统负载情况]]></content>
      <categories>
        <category>linux-basic</category>
      </categories>
      <tags>
        <tag>linux-basic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux进程管理]]></title>
    <url>%2F2018%2F06%2F10%2Flinux-process%2F</url>
    <content type="text"><![CDATA[本文主要介绍Linux进程相关的命令，ps、kill、top等。 1. ps命令ps常规用法 12345678910111213141516# ps aux 查看所有进程# ps -ef 查看所有进程# ps -f -u apache 查看某个用户的进程# ps -f -C httpd 通过进程名显示进程# ps -f -p 3150,7298,6544 通过进程id显示进程# ps aux --sort=-pcpu,+pmem 以cpu使用量排序，如果cpu使用量相同，则以内存使用量排序# ps -f --forest -C httpd 显示ASCII进程树# ps -o pid,uname,comm -C httpd 显示父进程的子进程# ps -o pid,uname,comm --ppid 3438 # ps -e -o pid,comm,etime 显示进程已运行的时间# watch -n 1 'ps -e -o pid,uname,cmd,pmem,pcpu --sort=-pmem,-pcpu | head -15'还有一个pstree命令# pstree# pstree -a# pstree -p apache 2. top相关命令 top命令 123# top# top -b -n 1# top -b -n 1 -p 1 htop命令 123456# yum install htop -y 没有htop命令就安装# htop# htop -d 2 2秒刷新一次# htop -C 没有颜色# htop -u apache u=user# htop -p xxx，xxx p=pid dstat 命令 12345# dstat 直接运行# dstat -n n是net# dstat -d d是disk# dstat -m m是memory# dstat -l l是load average 显示系统负载情况 glances命令 123456789# yum install epel-release -y# yum install glances -y 没有glances命令就安装# glances# glances -t 2 刷新频率2秒，默认是1秒# yum install python-jinja2 -y# glances -o csv -f glances.csv 输出为csv格式# glances -o HTML -f /var/www/html/ 输出为html格式# glances -s -B 192.168.1.153 -p 4000 -P123 在服务器端启动# glances -c 192.168.1.153 -p 4000 -P123 再客户端连接 3. kill命令发送指定的信号到相应进程。 12# kill -l 查看有那些信号# kill -9 xxx 给xxx进程发生9号信号 查找进程PID的命令 12345# ps -ef | grep httpd# pstree -p apache# pidof httpd# pgrep httpd# lsof /usr/sbin/httpd 杀死进程的命令 1234# kill -9 pid# killall httpd# pkill httpd# skill httpd lsof命令12345678910lsof 打开文件列表lsof /usr/sbin/httpd 查找某个文件相关的进程lsof -c mysql 查找某个程序进程所打开的文件信息lsof -c mysql -c apache 多个lsof -p 1 通过某个进程号显示该进行打开的文件lsof -p 1,2,3 多个lsof -i 列出所有的网络连接lsof -i tcp 列出所有的tcp连接lsof -i udp 列出所有的udp连接lsof -i :3306 列出谁在使用某个端口 4 . 前台进程和后台进程(1)command &amp;让进程在后台运行(2) jobs –l 查看后台运行的进程(3)fg %n 让后台运行的进程n到前台来(4)bg %n 让进程n到后台去 123456# glances -s -B 127.0.0.1 &amp;# glances -s -B 127.0.0.1 暂停程序运行CTRL+Z# jobs -l 查看暂停的程序# bg %1 切换程序至后台# fg %1 切换程序至前台# kill %1 终止后台程序]]></content>
      <categories>
        <category>linux-basic</category>
      </categories>
      <tags>
        <tag>linux-basic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文本文件处理(4)]]></title>
    <url>%2F2018%2F06%2F10%2Flinux-sed%2F</url>
    <content type="text"><![CDATA[本文主要介绍sed命令的用法。 1. sed简介Sed：Stream Editor 流式编辑器 又称行编辑器，每次只编辑一行。 2. 基本用法1# sed [OPTION]... &#123;script-only-if-no-other-script&#125; [input-file]... 选项与参数：-n：只显示sed匹配到的行。其余行不显示。-i：可以直接操作原文件。默认情况下sed不会改变原文件，但是-i选项可以修改原文件，此选项应慎用。-r：可以使用标准正则表达式。默认情况下sed只支持基本正则表达式，但是加上-r选项后则支持扩展正则表达式-e：可以同时执行多个命令常用格式：(1)Sed [options] ‘script’ input_file……(2)Sed [options] -f script_file input_file……(3)Sed [options] ‘ADDR1,ADDR2command’ input_file……(4)Sed [options] ‘/PATTERN/command’ input_file……(5)Sed ‘/PATTERN1/,/PATTERN2/command’ input_file…… 常用命令(command)如下： 打印p 123456789101112131415161718192021222324252627282930# sed -n '3p' /etc/passwd --打印第3行# sed -n '1,3p' /etc/passwd --打印第1到第3行# sed -n '1,$p' /etc/passwd# nl /etc/passwd | sed -n '5,7p' --打印第5到第7行# head -5 /etc/passwd |sed -ne '1p;4p' --打印第1行和第4行# nl /etc/passwd | sed -n '/root/p' --查找包含root的行# cat /etc/passwd | sed -n '/^root/p'# ifconfig eth1 | sed -n '2p' | awk -F: '&#123;print $2&#125;' | awk '&#123;print $1&#125;' --截取ip# head -5 /etc/passwd |sed -ne '/^[[:upper:]]/p;/^[a-z]/p' --分别打印大写字母开头的行和小写字母开头的行# head -5 /etc/passwd |sed -ne '/^[[:upper:]]/,/^[a-z]/p' --用正则表达式实现范围打印# head -5 /etc/passwd |sed -ne '/^[[:upper:]]/,/nologin$/p'# head -5 /etc/passwd |sed -n '/^[^[:blank:]]/p' --打印非空格开头的行下面三条都是把有Accepted关键字的行打印出来# awk '$0~"Accepted" &#123;print $0&#125;' /var/log/ssh.log # sed -n '/Accepted/p' /var/log/ssh.log # cat /var/log/ssh.log | grep Accepted比较awk# head -5 /etc/passwd |cat -n | sed -n '1,4p'# head -5 /etc/passwd |cat -n | awk 'NR&lt;5 &#123;print $0&#125;'# head -5 /etc/passwd |cat -n | sed -n '1p;3p;5p'# head -5 /etc/passwd |cat -n | awk 'NR==1 || NR==3 || NR==5 &#123;print $0&#125;'# head -5 /etc/passwd |cat -n | sed -n '/root/p;/daemon/p;/lp/p'# head -5 /etc/passwd |cat -n | awk '$0~"root" || $0~"daemon" || $0~"lp" &#123;print $0&#125;' 删除dsed删除语法：sed ‘范围d’ file以行为单位删除，如果不指定范围，默认范围是整个文件。 123456789101112131415161718# sed '1d' /etc/passwd 删除第一行，第二行2d，第三行3d，以此类推，最后一行$d# sed '1,3d' /etc/passwd 删除第1行到第3行，中间是逗号# sed '1d;3d' /etc/passwd 删除第1行和第3行，中间是分号# sed -e '1d' -e '3d' /etc/passwd 删除第1行和第3行# sed --expression='1d' --expression='3d' /etc/passwd# sed '/^root/d' /etc/passwd 使用正则表达式，要加双斜杠# sed '/root/,/sync/d' /etc/passwd 删除包含root到sync的行# sed '/root/!d' /etc/passwd !表示后面的命令对所有没有被选定的行发生作用 # head -n 5 /etc/passwd |cat -n |sed '2d' 指定删除第二行# head -n 5 /etc/passwd |cat -n |sed '2,3d' 删除第二行到第三行，中间为逗号，表示范围# head -n 5 /etc/passwd |cat -n |sed '1d;5d' 删除第一行和第五行，中间为分号，表示单独操作# head -n 5 /etc/passwd |cat -n |sed '1d;5d;3d'# head -n 5 /etc/passwd |cat -n |sed '1,3d;5d'# head -5 /etc/passwd |sed '/daemon/d'删除vsftpd.conf里所有的注释和空行# sed '/^#/d;/^$/d' /etc/vsftpd/vsftpd.conf 替换sed替换语法：sed ‘范围 s/老字符/新字符/标记’ filesed ‘范围 s#老字符#新字符#标记’ file如果不指定范围，默认范围是整个文件。sed ‘y/老字符/新字符/‘ 12345678# head -5 /etc/passwd | nl |sed '1,4s/nologin/NOLOGIN/g'# sed 's#nologin#NOLOGIN#g' /etc/passwd g是标记，表示全部，也可以使用数字，1,2,3等进行替换，#号只有替换的时候才能用# sed 's/nologin/NOLOGIN/g' /etc/passwd# sed '1s/root/--&amp;--/2' /etc/passwd 老字符支持正则表达式，新字符不支持正则表达式，除了"\n\&amp;"，这里的"&amp;"表示前面的关键字# sed '1&#123;s/root/ROOT/;s/bin/BIN/&#125;' /etc/passwd 多次替换使用花括号和分号# sed 'y/abc/xyz/' file y也是替换，a-&gt;x b-&gt;y c-&gt;z# cat /etc/sysconfig/network-scripts/ifcfg-eth0 | sed '/^onboot/c\onboot=yes' 将onboot开头的行替换成onboot=yes，行替换# cat /etc/sysconfig/network-scripts/ifcfg-eth0 | sed 's/ONBOOT="no"/ONBOOT="yes"/' 修改之后保存 1# sed -i '/^root/a\the first line' file --修改源文件的操作要谨慎]]></content>
      <categories>
        <category>linux-basic</category>
      </categories>
      <tags>
        <tag>linux-basic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文本文件处理(3)]]></title>
    <url>%2F2018%2F06%2F09%2Flinux-awk%2F</url>
    <content type="text"><![CDATA[本文主要介绍awk命令的用法。 1. awk简介awk有3个不同版本: awk、nawk和gawk，未作特别说明，一般指gawk。awk名字来源于三位创造者Aho、Weinberger和Kernighan统称。awk擅长处理文本数据。 2. 基本用法awk [-Ffs] [-v var=value] [program | -f progfile …] [file …]选项与参数：-F 指定域分隔符，例如：-F “|”，即以|作为域分隔符，默认分隔符为一个或多个空格或TAB，即”[[:space:]][[:space:]]*”。-v 定义变量，从shell给awk传递变量，如-vDATE=$DATE，即将shell中$DATE变量值传递给awk变量DATE。-f 指定脚本文件，例如-f progfile。program 操作模块 示例： 123456# awk -F ":" '&#123;print $1,$2&#125;' /etc/passwd -F 分隔符 $1是第一列 $2是第二列# awk '&#123;print $0&#125;' /etc/passwd 打印所有列# awk -F: '&#123;print $1&#125;' /etc/passwd 打印第一列# awk -F: '&#123;print $1"\thaha\t"$3&#125;' /etc/passwd 打印第一，三列# awk -F":" '&#123;print $1" 的uid是 "$3&#125;' /etc/passwd# echo "haha,hehe.heihei" |awk -F"[,.]" '&#123;print $1&#125;' 分隔符可以有多个 模式匹配格式：awk ‘/patten/ {action} ‘ filename //纯字符匹配 !//纯字符不匹配 ~//字段值匹配 !~//字段值不匹配 ~/a1|a2/字段值匹配a1或a2 123456789101112131415# awk '/mysql/' /etc/passwd# awk '/mysql/&#123;print &#125;' /etc/passwd# awk '/mysql/&#123;print $0&#125;' /etc/passwd --三条指令结果一样# awk '!/mysql/&#123;print $0&#125;' /etc/passwd --输出不匹配mysql的行# awk '/mysql|mail/&#123;print&#125;' /etc/passwd# awk '/mysql|postfix|root/' /etc/passwd# awk '!/mysql|mail/&#123;print&#125;' /etc/passwd# awk '/mail/,/mysql/&#123;print&#125;' /etc/passwd --区间匹配# awk '/^root/,/^mail/' /etc/passwd --区间匹配# awk '/[2][7][7]*/&#123;print $0&#125;' /etc/passwd --匹配包含27为数字开头的行，如27，277，2777...# awk -F: '$1~/mail/&#123;print $1&#125;' /etc/passwd --$1匹配指定内容才显示# awk -F: '$3~/^0$/&#123;print $1&#125;' /etc/passwd# awk -F: '&#123;if($1~/mail/) print $1&#125;' /etc/passwd --与上面相同# awk -F: '$1!~/mail/&#123;print $1&#125;' /etc/passwd --不匹配# awk -F: '$1!~/mail|mysql/&#123;print $1&#125;' /etc/passwd 操作模块 awk [-Ffs] ‘BEGIN {处理文件前执行的代码块} ｛处理文件过程中执行的代码块} END {处理文件后执行的代码块}’ filename BEGIN｛｝｛ ｝END｛｝ BEGIN和END只执行一次。 12345678910111213# awk -F: '&#123;print "用户名\t\tUID"&#125;&#123;print $1"\t"$3&#125;' /etc/passwd# awk -F: 'BEGIN&#123;print "用户名\t\tUID"&#125;&#123;print $1"\t"$3&#125;' /etc/passwd# head -1 /etc/passwd |awk -F: '&#123;print $7":"$6":"$5":"$4":"$3":"$2":"$1&#125;'# head -1 /etc/passwd |awk -F: 'BEGIN &#123;OFS=":"&#125;&#123;print $7,$6,$5,$4,$3,$2,$1&#125;'# head -1 /etc/passwd | awk 'BEGIN&#123;FS=":"&#125;&#123;OFS="@"; print $7,$6,$5,$4,$3,$2,$1&#125;'# head -1 /etc/passwd | awk 'BEGIN&#123;FS=":";OFS="#"&#125;&#123;print $7,$6,$5,$4,$3,$2,$1&#125;'awk可以用做小数（浮点数）的运算# echo $[1.23*2] --错误做法# echo |awk '&#123;print 1.23*2&#125;' --正确做法# echo 1.23*2 | bc --正确做法# awk 'BEGIN&#123;print 1.23*2&#125;' 内置变量 属性 说明 $0 当前记录行，代表一行记录 $1到n 当前记录的第n个字段，字段间由FS分隔 FS 输入字段分隔符，默认是空格或tab NF 当前记录中的字段个数，就是有多少列，一般取最后一列字段 NR 已经读出的记录数，就是行号，从1开始 RS 输入的记录分隔符，默认为换行符 OFS 输出字段分隔符，默是空格 ORS 输出的记录分隔符，默认为换行符 示例 1234567891011121314151617打印第五行# head -5 /etc/passwd |tail -1# awk 'NR==5 &#123;print $0&#125;' /etc/passwd# awk '&#123;if (NR==5) print $0&#125;' /etc/passwd打印第五行和第六行# awk 'NR==5 || NR==6 &#123;print $0&#125;' /etc/passwd# awk 'NR&gt;=5 &amp;&amp; NR&lt;=6 &#123;print $0&#125;' /etc/passwd打印五到十行，并在前面加上行号# awk 'NR&lt;=10 &amp;&amp; NR&gt;=5 &#123;print FNR,$0&#125;' /etc/passwd打印奇数行 (删除偶数行)# awk 'NR%2==1 &#123;print FNR,$0&#125;' /etc/passwd打印偶数行 (删除奇数行)# awk 'NR%2==0 &#123;print FNR,$0&#125;' /etc/passwd]]></content>
      <categories>
        <category>linux-basic</category>
      </categories>
      <tags>
        <tag>linux-basic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文本文件处理(2)]]></title>
    <url>%2F2018%2F06%2F09%2Flinux-grep%2F</url>
    <content type="text"><![CDATA[本文主要介绍grep命令的用法。 1. grep的简介文本搜索工具，根据用户指定的文本模式对目标文件进行逐行搜索，显示能够被模式所匹配到的行。配合正则表达式的使用可以实现强大的文本处理。 2. 基础用法1234567# grep [-cinv] [--color=auto] '搜寻字符串' filename选项与参数：-c ：计算找到 '搜寻字符串' 的次数-i ：忽略大小写的不同，所以大小写视为相同-n ：顺便输出行号-v ：反向选择，亦即显示出没有 '搜寻字符串' 内容的那一行！--color=auto ：可以将找到的关键词部分加上颜色的显示喔！ 示例： 123456789101112131415# grep root /etc/passwd# grep -n root /etc/passwd -n:输出行号# grep -c "bash" /etc/passwd -c:个数# grep -v root /etc/passwd -v:反向匹配# echo "hello world" | grep -i "HELLO" -i:忽略大小写# dmesg | grep -n --color=auto 'eth' --color颜色高亮# dmesg | grep -n -A3 -B2 --color=auto 'eth' 将匹配到的那一行的前面后面的行显示出来# cat patfile bash nologin# grep -f patfile /etc/passwd --color -f:文件# grep "root" / -r --color=auto -r:递归# grep "main()" . -r --include *.&#123;php,html&#125; --include:包含# grep "main()" . -r --exclude "README" --exclude:不包含# grep "main()" . -r --exclude-from filelist 3. 正则表达式1234567891011121314151617181920212223242526. 单个字符^ 开始$ 结尾* 匹配零个或多个先前字符[] 匹配一个指定范围内的字符[^] 匹配一个不在指定范围内的字符x\&#123;m\&#125; 重复字符x，m次，如：'0\&#123;5\&#125;'匹配包含5个o的行x\&#123;m,\&#125; 重复字符x,至少m次，如：'o\&#123;5,\&#125;'匹配至少有5个o的行w 匹配文字和数字字符，也就是[A-Za-z0-9]W w的反置形式，匹配一个或多个非单词字符，如点号句号等+ 匹配一个或多个先前的字符? 匹配零个或多个先前的字符a|b|c 匹配a或b或cx&#123;m&#125;,x&#123;m,&#125;,x&#123;m,n&#125; 作用同x\&#123;m\&#125;,x\&#123;m,\&#125;,x\&#123;m,n\&#125;[:alnum:] 文字数字字符[:alpha:] 文字字符[:digit:] 数字字符[:graph:] 非空字符（非空格、控制字符）[:lower:] 小写字符[:cntrl:] 控制字符[:print:] 非空字符（包括空格）[:punct:] 标点符号[:space:] 所有空白字符（新行，空格，制表符）[:upper:] 大写字符[:xdigit:] 十六进制数字（0-9，a-f，A-F） 示例： 1234567891011# grep -E 'r..t' /etc/passwd --color# grep -E 'r.*t' /etc/passwd --color# grep -E 'r.+t' /etc/passwd --color# cat /etc/httpd/conf/httpd.conf | grep -v '^#' | grep -v '^$'# cat /etc/httpd/conf/httpd.conf | grep -v -e '^#' -e '^$'# cat /etc/httpd/conf/httpd.conf | grep -v -E '#|^$'# grep -E '[io]n' /etc/passwd --color# grep -E '[^io]n' /etc/passwd --color# grep 'ro\&#123;2\&#125;' /etc/passwd --color 不要加-E# grep 'ro\&#123;1,\&#125;' /etc/passwd --color 贪婪模式，尽可能多的匹配# grep 'ro\&#123;1,3\&#125;' /etc/passwd --color 至少1次，最多3次]]></content>
      <categories>
        <category>linux-basic</category>
      </categories>
      <tags>
        <tag>linux-basic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文本文件处理(1)]]></title>
    <url>%2F2018%2F06%2F08%2Flinux-text%2F</url>
    <content type="text"><![CDATA[本文主要介绍Linux下文本文件的查看等操作相关的命令。 1. 文本文件查看命令cat命令 查看文件内容123cat 1.txt 查看文本文件内容cat -n 1.txt 显示行号，空行也算一行cat -nb 1.txt 显示行号，空行忽略 head命令 显示文件前十行的内容(默认)123head 1.txthead -n 20 1.txt 显示文件前20行的内容head -20 1.txt 显示文件前20行的内容 tail命令 查看文件最后十行的内容(默认)1234tail -n 5 1.txt 最后5行tail -5 1.txt 最后5行tail -f 1.txt 动态查看文件内容tailf 1.txt 动态查看文件内容 more命令 分页显示1more 1.txt less命令 分页显示1less 1.txt tac命令 文件内容的输出上下反，不影响源文件1tac 1.txt tac 反过来 cat rev命令 左右反，不影响源文件1rev 1.txt tee命令 将数据重定向到文件和标准输出12ls | tee out.txtls | tee out.txt | cat -n 2. 其他命令wc命令 字符统计123cat /etc/passwd | wc -lcat /etc/passwd | wc -ccat /etc/passwd | wc -w cut命令123who|cut -b 3-5cut -f2 -d";" test2.txt -d分隔符是":"，-f是列 cut -f2 --complement test.txt --complement 选项提取指定字段之外的列 tr命令1234567echo "HELLO WORLD" | tr 'A-Z' 'a-z' 将输入字符由大写转换为小写hello worldecho "hello 123 world 456" | tr -d '0-9' 使用tr删除字符hello world cat text | tr '\t' ' ' 将制表符转换为空格 sort命令 排序123456sort参数 -n 按照数字进行排序 -r 反向排序 -t 分隔符 -k 按照指定列进行排序sort -n -t : -k 3 /etc/passwd uniq命令 忽略文件中的重复行12sort file.txt | uniq sort -u file.txt]]></content>
      <categories>
        <category>linux-basic</category>
      </categories>
      <tags>
        <tag>linux-basic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum命令详解]]></title>
    <url>%2F2018%2F06%2F08%2Flinux-yum%2F</url>
    <content type="text"><![CDATA[本文主要介绍centos系统程序包管理软件Yum命令的详细使用方法。Yum软件包管理方式，在Red Hat,Fedora,CentOS等发行版本上运用广泛。 1. Yum的工作机制将诸多程序的包信息和头文件提取出来，放到一个集中的地方，记录其依赖关系。在下次安装的时候，均于存储的库文件查找相应的对应关系，再安装所依赖的软件程序。 2. Yum配置文件主配置文件：/etc/yum.conf12345678[main]：主名称，固定名称cachedir=/var/cache/yum/$basearch/$releasever 缓存目录keepcache=0 是否保存缓存debuglevel=2 调试级别exactarch=1 是否做精确严格的平台匹配gpgcheck=1 检查来源法性和完整性plugins=1 是否支持插件installonly_limit=4 同时安装几个 子配置文件：/etc/yum.repos.d/*.repo12345678910111213141516[repository ID] ：ID名称，即仓库名称，不可与其他ID重命name= (对ID名称的说明)baserul=URL1URL2URL3 （如果同一个源有多个镜像，可以在此我写几个，但每个URL需换行）mirrorlist= (有一台服务器在网络上，保存了多个baseurl，如果使用这项，就不使用baseurl项）enabled=&#123;1|0&#125;gpgcheck=&#123;1|0&#125;repo_gpgcheck= (检查仓库的元数据的签名信息)gpgkey=URL (gpg密钥文件）enablegroups= &#123;1|0&#125;&#125; (是否在此仓库中上使用组来指管理程序包)failovermethod= roundrobin|priority (对多个baseurl做优先级的，roundrobin为轮循，priority为优先级，默认为轮循，意为随机）keepalive= (如果对方是http 1.0是否要保持连接)username= (yum的验证用户)password= (yum的验证用户密码)cost= (默认baseurl都为1000) Yum仓库的配置文件示例12345678[epel]name=Extra Packages for Enterprise Linux 6 - $basearch#baseurl=http://download.fedoraproject.org/pub/epel/6/$basearchmirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-6&amp;arch=$basearchfailovermethod=priorityenabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 其中使用了变量$releasever:当前os的发行版本的主版本号$arch:平台$basearch:基础平台 3. 常用的国内Yum源 中科大http://mirrors.ustc.edu.cn/centos/CentOS-Base.5.mirrors.repohttp://mirrors.ustc.edu.cn/centos/6/os/x86_64/ 搜狐http://mirrors.sohu.com/help/CentOS-Base-sohu.repohttp://mirrors.sohu.com/centos/6/os/x86_64/ REMIhttp://rpms.remirepo.net/ REMI网站https://mirrors.tuna.tsinghua.edu.cn/remi/ REMI中国镜像http://rpms.remirepo.net/enterprise/http://rpms.remirepo.net/enterprise/remi-release-6.rpm 163源http://mirrors.163.com/centos/ 阿里云https://opsx.alibaba.com/mirror 中国科技大学http://centos.ustc.edu.cn/centos/ rpm包常用下载地址https://centos.pkgs.org/http://rpmfind.net/http://dl.fedoraproject.org/pub/epel/ 4. 制作Yum源上面介绍的都是网络上做好的yum源，我们也可以自己来制作yum源。 本地光盘源 123456789mkdir /media/cdrommount /dev/cdrom /media/cdrom/cd /etc/yum.repos.d/vim cdrom.repo[cdrom]name=cdrom repolistbaseurl=file:///media/cdrom/gpgcheck=0enabled=1 文件夹源 1234567891011mkdir /yumyum -y install createrepomv *.rpm /yumcreaterepo /yumcd /etc/yum.repos.d/vim cdrom.repo[local]name=local directory repolistbaseurl=file:///media/cdrom/gpgcheck=0enabled=1 网络yum源 123yum install httpd -yln -s /yum /var/www/html/service httpd start 添加新的yum源： 12yum install yum-utils -yyum-config-manager --add-repo=file:///yum/ 5. yum命令使用安装软件1yum install packagename 升级软件1yum update packagename 卸载软件1yum remove packagename 搜索已安装软件包1yum search keyword 查看软件包额外信息1yum info packagename 查看可安装的软件包1yum list | less 列出已安装软件包1yum list installed | less 显示仓库的所有程序包1yum list 查看特定文件属于哪个软件包1yum provides /etc/sysconfig/nfs 列出可获得的软件组1yum grouplist 安装某个特定软件组1yum groupinstall 升级软件组1yum groupupdate 'Graphical Internet' 卸载软件组1yum groupremove 'DNS Name Server' 列出当前yum软件源1yum repolist 查看yum安装的历史123yum historyyum history info 3yum history undo 4 安装及升级本地程序包12yum localinstall rpmfile1yum localupdate rpmfile1 6. 使用Yumdownloader下载RPM软件包及其所有依赖包如果系统中没有yumdownloader命令，可以执行如下命令安装：1yum -y install yum-utils 具体使用方法：1234# yumdownloader httpd# yumdownloader --resolve httpd# yumdownloader --resolve --destdir=/root/mypackages/ httpd# yumdownloader "@Development Tools" --resolve --destdir /root/mypackages/]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos下Yum安装PHP5.5、PHP5.6、PHP7.0]]></title>
    <url>%2F2018%2F06%2F08%2Flinux-php-version%2F</url>
    <content type="text"><![CDATA[本文主要介绍centos系统上如何升级php的版本。Centos系统默认有php，但是默认的版本太低，手动安装有一些麻烦，于是使用Yum来安装。 1. 检查当前安装的PHP包1yum list installed | grep php 如果已经安装PHP的包，先卸载掉。1yum remove php.x86_64 php-cli.x86_64 php-common.x86_64 php-gd.x86_64 php-ldap.x86_64 php-mbstring.x86_64 php-mcrypt.x86_64 php-mysql.x86_64 php-pdo.x86_64 2. 安装新的Yum源Centos 5.x1rpm -Uvh http://mirror.webtatic.com/yum/el5/latest.rpm CentOs 6.x1rpm -Uvh http://mirror.webtatic.com/yum/el6/latest.rpm CentOs 7.x12rpm -Uvh https://mirror.webtatic.com/yum/el7/epel-release.rpmrpm -Uvh https://mirror.webtatic.com/yum/el7/webtatic-release.rpm 3. 安装PHP1yum install php55w.x86_64 php55w-cli.x86_64 php55w-common.x86_64 php55w-gd.x86_64 php55w-ldap.x86_64 php55w-mbstring.x86_64 php55w-mcrypt.x86_64 php55w-mysql.x86_64 php55w-pdo.x86_64 1yum install php56w.x86_64 php56w-cli.x86_64 php56w-common.x86_64 php56w-gd.x86_64 php56w-ldap.x86_64 php56w-mbstring.x86_64 php56w-mcrypt.x86_64 php56w-mysql.x86_64 php56w-pdo.x86_64 1yum install php70w.x86_64 php70w-cli.x86_64 php70w-common.x86_64 php70w-gd.x86_64 php70w-ldap.x86_64 php70w-mbstring.x86_64 php70w-mcrypt.x86_64 php70w-mysql.x86_64 php70w-pdo.x86_64 4. 安装PHP FPM123yum install php55w-fpmyum install php56w-fpmyum install php70w-fpm]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础02篇]]></title>
    <url>%2F2018%2F06%2F08%2Flinux-basic-02%2F</url>
    <content type="text"><![CDATA[本文主要介绍文件系统、文件权限、文件打包和解包及软件包管理方面的命令。 1. 文件系统 磁盘分区磁盘分区主要使用fdisk（sfdisk）命令和parted命令。 1234# sfdisk-l# sfdisk-s# cfdisk-Ps# fdisk -l 格式化mkfs命令 12# mkfs.ext4# mfks -t ext4 /dev/sda6 挂载mount命令 123# mount /dev/sda5 /test# mount /soft/rhel-server-6.3-x86_64-dvd.iso /yum/ -o loop# mount -o remount,noexec / 查看磁盘 1234567# df –h 显示已经挂载的分区列表# df –T 显示分区列表的文件系统类型# du -sh dir1 估算目录 'dir1' 已经使用的磁盘空间# fsck 文件系统修复# dumpe2fs /dev/sda1 显示磁盘状态# findmnt 查找已经被挂载的文件系统# blkid 2. 文件权限 基本的权限-rw——- 1 root root 1112 Mar 27 03:14 anaconda-ks.cfgrw- — — 权限用九位来表示前三位代表用户u(user），中间三位代表组g(group），后三位代表o（others）基本权限有三种 r(read)读 w(write)写 x(execute)执行 a表示allr 读权限 针对目录，有r权限，就代表能对此目录有列表的功能 (就是ls列出来的功能） 针对文件，有r权限，就代表能对此文件有阅读的功能 (就是指cat一类的命令）w 写权限 针对目录，有w权限，就代表在此目录下创建文件或者子目录 (touch,mkdir等） 针对文件，有w权限，就代表能在此文件写入内容或者修改 (&gt; ,&gt;&gt;, vi 再写等）x 执行权限 针对目录，有x权限，就代表能进入此目录 （cd) 针对文件，有x权限，就代表能执行它 （命令，可执行文件等）1234567# chmod a+x 1.txt# chmod g+x 1.txt# chmod a+x 1.txt# chmod a-r 1.txt# chmod o-rwx 1.txt # chmod u-w,g+x,o+x abc --也可以一次性连写# chmod o=rwx 1.txt rw- — —110 000 000 –二进制 600 –十进制 权限用数字来表示 (r,w,x都可以用数字来表示）r 4w 2x 1 -rw-r–r– 这个以数字表示为644 修改文件所有者和组123456789101112# touch 1.txt# ll 1.txt -rw-r--r-- 1 root root 0 Aug 20 15:28 1.txt# chown user2.user2 1.txt # ll 1.txt -rw-r--r-- 1 user2 user2 0 Aug 20 15:28 1.txt# chown user3:user3 1.txt # ll 1.txt -rw-r--r-- 1 user3 user3 0 Aug 20 15:28 1.txt# chown user2:user3 1.txt # ll 1.txt -rw-r--r-- 1 user2 user3 0 Aug 20 15:28 1.txt 特殊权限s权限：一个可执行文件拥有s位时，当别的用户来执行这个可执行文件的话，使用的权限是此可执行文件属主或者属组的权限只针对前三位，中间三位。对目录可以加，但是无效，因为目录不是命令，根本不能执行它12345678910# ll /usr/bin/passwd-rwsr-xr-x. 1 root root 30768 Feb 17 2012 /usr/bin/passwd# ll /etc/shadow----------. 1 root root 1434 Jul 17 09:27 /etc/shadow``` t权限，只针对目录有效有t位的目录，任何用户在有权限的情况下是可以创建文件和目录，但是自己只能删除自己创建的目录。```markdown# ll -d /tmp/ s位和t位注意的地方：用数字表示前三位上加s 4中间三位加s 2后三位加t 1 s位和t位大小写的区别小写的话就表示 有x执行权限大写的话就表示 没有x执行权限 隐藏属性12345678# chattr +a file1 只允许以追加方式读写文件# chattr +c file1 允许这个文件能被内核自动压缩/解压# chattr +d file1 在进行文件系统备份时，dump程序将忽略这个文件# chattr +i file1 设置成不可变的文件，不能被删除、修改、重命名或者链接# chattr +s file1 允许一个文件被安全地删除# chattr +S file1 一旦应用程序对这个文件执行了写操作，使系统立刻把修改的结果写到磁盘# chattr +u file1 若文件被删除，系统会允许你在以后恢复这个被删除的文件# lsattr 显示特殊的属性 3.文件打包和解包示例：123456789101112# tar -cvf archive.tar file1 创建一个非压缩的 tarball# tar -cvf archive.tar file1 file2 dir1 创建一个包含了 'file1', 'file2' 以及 'dir1'的档案文件# tar -tf archive.tar 显示一个包中的内容# tar -xvf archive.tar 释放一个包# tar -xvf archive.tar -C /tmp 将压缩包释放到 /tmp目录下# tar -cvfj archive.tar.bz2 dir1 创建一个bzip2格式的压缩包# tar -xvfj archive.tar.bz2 解压一个bzip2格式的压缩包# tar -cvfz archive.tar.gz dir1 创建一个gzip格式的压缩包# tar -xvfz archive.tar.gz 解压一个gzip格式的压缩包# zip file1.zip file1 创建一个zip格式的压缩包# zip -r file1.zip file1 file2 dir1 将几个文件和目录同时压缩成一个zip格式的压缩包# unzip file1.zip 解压一个zip格式压缩包 4. 软件包管理 rpm包管理 1234567891011121314# rpm -ivh package.rpm 安装一个rpm包# rpm -ivh --nodeps package.rpm 安装一个rpm包而忽略依赖关系警告# rpm -U package.rpm 更新一个rpm包但不改变其配置文件# rpm -e package_name.rpm 删除一个rpm包# rpm -qa 显示系统中所有已经安装的rpm包# rpm -qa | grep httpd 显示所有名称中包含 "httpd" 字样的rpm包# rpm -qi package_name 获取一个已安装包的特殊信息# rpm -ql package_name 显示一个已经安装的rpm包提供的文件列表# rpm -qc package_name 显示一个已经安装的rpm包提供的配置文件列表# rpm -qf /etc/httpd/conf/httpd.conf 确认所给的文件由哪个rpm包所提供# rpm -qp package.rpm -l 显示由一个尚未安装的rpm包提供的文件列表# rpm --import /media/cdrom/RPM-GPG-KEY 导入公钥数字证书# rpmbuild --rebuild package_name.src.rpm 从一个rpm源码构建一个 rpm 包# yum管理工具 123456789# yum install package_name 下载并安装一个rpm包# yum localinstall package_name.rpm 将安装一个rpm包，使用你自己的软件仓库为你解决所有依赖关系# yum update package_name.rpm 更新当前系统中所有安装的rpm包# yum update package_name 更新一个rpm包# yum remove package_name 删除一个rpm包# yum list 列出当前系统中安装的所有包# yum search package_name 在rpm仓库中搜寻软件包# yum clean packages 清理rpm缓存删除下载的包# yum clean all 删除所有缓存的包]]></content>
      <categories>
        <category>linux-basic</category>
      </categories>
      <tags>
        <tag>linux-basic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础01篇]]></title>
    <url>%2F2018%2F06%2F07%2Flinux-basic-01%2F</url>
    <content type="text"><![CDATA[本文主要介绍文件和目录、文件搜素相关的命令。 1. 文件和目录 cd命令 123456789cd /进入系统根目录# cd /cd /home进入根下的home目录# cd /homecd ..进入当前目录的上一级目录# cd ..cd -进入上次所在的目录# cd - ls和pwd命令 12345ls注意ls的参数# ls -a -l -d -hpwd显示当前工作路径# pwd mkdir命令 1234mkdir /test在根目录下创建test目录# mkdir /testmkdir -p /a/b/c/d创建多级目录，-p参数是不报错的# mkdir -p /a/b/c/d cp命令 1234cp file1 file2复制一个文件# cp a.txt b.txtcp -ar dir1 dir2 复制一个目录# cp -ar /abc /test mv命令 1234mv /opt/a /root/移动文件# mv /opt/a /root/mv /opt/a /root/移动文件# mv /opt/a /root/b touch命令 1234567touch 1.txt创建文件# touch 1.txt# touch &#123;a..z&#125;# touch &#123;a..z..2&#125;# touch a&#123;1..5&#125;# touch a&#123;1..5&#125;.txt# touch &#123;1..5&#125;&#123;a..f&#125; file命令 12查看文件的类型# file /dev/sda tree命令 123显示文件和目录由根目录开始的树形结构# yum install tree# tree –L 1 2. 文件搜素 whereis和which命令 123查找二进制文件# which cat# whereis whereis find命令 按名称查找1234# find /etc/ -name grub.conf# find /etc/ -name "*.conf"# find /etc/ -name ".*"# find /test/ -iname Abc 按类型查找1234567# find / -type f# find / -type b# find / -type s# find / -type c# find / -type p# find / -type d# find / -type l 按大小查找123456# find / -size +500M# find / -size +1G# find / -size +50k# find / -size -1M# find / -size +3c# find / -size +80M -size -100M 按时间查找123456789101112131415# stat 1 |tail -3Access: 2014-07-23 11:56:42.297572398 +0800 --atime 阅读过，用cat,tail,head,more,less命令等或者vi访问过，但没有修改；执行过也会改变Modify: 2014-07-23 11:56:44.836572907 +0800--mtime 修改过内容，用vi修改过或者echo一个值重定向Change: 2014-07-23 11:56:44.856885177 +0800 —ctime 改变过内容，属主，属组，权限，创建软链接，硬链接等找出 3 天”以前”被改动过的文件(&gt; 72 小时)find /var/log/ -mtime +3 -type f找出 3 天内被改动过的文件(0 ~ 72 小时内)find /var/log/ -mtime -3 -type f找出前第 3 天被改动过的文件(72 ~ 96 小时)find /var/log/ -mtime 3 -type ffind /var/log/ -mtime +2 -mtime -4 -type f在20-50天内修改过的文件find ./ -mtime +20 -a -mtime -50 -type f在2018-04-11当天修改的文件find / -type f -newermt '2018-04-11 00:00' -a -not -newermt '2018-04-11 23:56' locate命令 速度快，通过系统带的一个数据库去查找，数据是非实时的。速度快，通过系统带的一个数据库去查找，数据是非实时的。系统每天自动更新一次，是通过时间任务执行的：/etc/cron.daily/mlocate.cron/usr/bin/updatedb主要用来更新数据库，通过crontab自动完成的/usr/bin/locate 查询文件位置/etc/updatedb.confupdatedb的配置文件/var/lib/mlocate/mlocate.db 存放文件信息的文件1# locate passwd]]></content>
      <categories>
        <category>linux-basic</category>
      </categories>
      <tags>
        <tag>linux-basic</tag>
      </tags>
  </entry>
</search>
